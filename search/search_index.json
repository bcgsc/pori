{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About \u00b6 The Platform for Oncogenomic Reporting and Interpretation (PORI) is an open source collection of software designed to support scalable precision oncology. The platform has two main components: a graph knowledge base ( GraphKB ) and an integrated pipeline reporting application ( IPR ). This site contains central documentation for the platform as well as setup and installation instructions. Click on the menu icon ( ) to see a full table of contents for this site. Citation \u00b6 Please cite Reisle, C. et al. A platform for oncogenomic reporting and interpretation. Nat. Commun. 13, 1\u201311 (2022)","title":"Home"},{"location":"#about","text":"The Platform for Oncogenomic Reporting and Interpretation (PORI) is an open source collection of software designed to support scalable precision oncology. The platform has two main components: a graph knowledge base ( GraphKB ) and an integrated pipeline reporting application ( IPR ). This site contains central documentation for the platform as well as setup and installation instructions. Click on the menu icon ( ) to see a full table of contents for this site.","title":"About"},{"location":"#citation","text":"Please cite Reisle, C. et al. A platform for oncogenomic reporting and interpretation. Nat. Commun. 13, 1\u201311 (2022)","title":"Citation"},{"location":"demo/","text":"Demo \u00b6 A live demo of the platform is found under pori-demo.bcgsc.ca . This demo was deployed via docker-compose. Some Features are Not Available in the Demo Application These include all write operations as well as the automated linking between the kb-matches page in IPR and the GraphKB statements. Data in the Demo is Limited The data provided in the demo application is a subset of what you might use in your own production application of PORI. The GraphKB data contains partial copies of various open data sets for demonstrative purposes only. This demo should not be used to annotate your own reports. Instead please see the install section for instructions on setting up and deploying your own instance of PORI. Videos \u00b6 We have recorded videos on various sections of IPR from the analysts perspective to help new users in navigating the system. Landing Page Report Summary Page Therapeutic Options Table Pathway Analysis IPR \u00b6 The demo instance of IPR is at pori-demo.bcgsc.ca/ipr . This will bring you to the login page of the IPR client application. Use the following credentials to log in to the demo application username: iprdemo password: iprdemo When you first go to the link above it will redirect you to the keycloak login page. Enter the above credentials Once you are logged in you will be brought to the main report listing page. This is a table of all the reports your user has access to in IPR. The table can be sorted and filtered. By clicking on a row in the above table you will be brought to the corresponding reports main summary page. Once in the report view, the different sections of the report can be navigated via the right-hand side bar. GraphKB \u00b6 The demo instance of IPR is at pori-demo.bcgsc.ca/graphkb . This will bring you to the login page of the GraphKB client application. The iprdemo credentials will also work with GraphKB to demonstrate single sign on. However, we also provide an admin demo account for GraphKB so that users can explore the admin-only sections of the application. The credentials for the administrative account are username: graphkb_admin password: graphkb_admin APIs \u00b6 If you are a developer looking for a demo of the APIs for GraphKB and IPR their documentation can be found here IPR OpenAPI Spec GraphKB OpenAPI Spec ( swagger version )","title":"Demo"},{"location":"demo/#demo","text":"A live demo of the platform is found under pori-demo.bcgsc.ca . This demo was deployed via docker-compose. Some Features are Not Available in the Demo Application These include all write operations as well as the automated linking between the kb-matches page in IPR and the GraphKB statements. Data in the Demo is Limited The data provided in the demo application is a subset of what you might use in your own production application of PORI. The GraphKB data contains partial copies of various open data sets for demonstrative purposes only. This demo should not be used to annotate your own reports. Instead please see the install section for instructions on setting up and deploying your own instance of PORI.","title":"Demo"},{"location":"demo/#videos","text":"We have recorded videos on various sections of IPR from the analysts perspective to help new users in navigating the system. Landing Page Report Summary Page Therapeutic Options Table Pathway Analysis","title":"Videos"},{"location":"demo/#ipr","text":"The demo instance of IPR is at pori-demo.bcgsc.ca/ipr . This will bring you to the login page of the IPR client application. Use the following credentials to log in to the demo application username: iprdemo password: iprdemo When you first go to the link above it will redirect you to the keycloak login page. Enter the above credentials Once you are logged in you will be brought to the main report listing page. This is a table of all the reports your user has access to in IPR. The table can be sorted and filtered. By clicking on a row in the above table you will be brought to the corresponding reports main summary page. Once in the report view, the different sections of the report can be navigated via the right-hand side bar.","title":"IPR"},{"location":"demo/#graphkb","text":"The demo instance of IPR is at pori-demo.bcgsc.ca/graphkb . This will bring you to the login page of the GraphKB client application. The iprdemo credentials will also work with GraphKB to demonstrate single sign on. However, we also provide an admin demo account for GraphKB so that users can explore the admin-only sections of the application. The credentials for the administrative account are username: graphkb_admin password: graphkb_admin","title":"GraphKB"},{"location":"demo/#apis","text":"If you are a developer looking for a demo of the APIs for GraphKB and IPR their documentation can be found here IPR OpenAPI Spec GraphKB OpenAPI Spec ( swagger version )","title":"APIs"},{"location":"install/","text":"Install with Docker \u00b6 Since PORI is a production-ready, institution-level, scalable platform, the simplest way to get the entire platform up and running from scratch is using docker . For simplicity the default instructions set up the platform with http. Most of the servers are auto-started together with docker-compose but the keycloak container must be started and configured on its own first. Start by cloning this repository which contains the default docker compose configs ( docker-compose.yml and docker-compose.dev.yml ) git clone https://github.com/bcgsc/pori.git cd pori For working on most of the PORI-related projects you will need to have a number of the components set up. For example, to work on the GraphKB API you will need both an OrientDB server and a Keycloak server already running. If your institution regularly works on PORI related projects then we recommend setting up a development instance of the PORI platform which your developers can point their applications to. If you do not have access to something like this, then the easiest way to get the dependencies for whatever part of the PORI platform you are working on up and running is by running the development version of the docker compose configuration found in this repository: docker-compose.dev.yml . docker-compose.dev.yml # This version of the docker-compose sets up the servers using http only for testing locally and # therefore does not require the top level apache server to configure the URLs version : '3' services : keycloak : build : context : . dockerfile : ./demo/Dockerfile.auth environment : KEYCLOAK_USER : admin KEYCLOAK_PASSWORD : admin PROXY_ADDRESS_FORWARDING : \"true\" JAVA_OPTS_APPEND : \"-Djboss.socket.binding.port-offset=808\" ports : - 8888:8888 networks : - app-network healthcheck : # test fetching public key from PORI realm test : [ \"CMD\" , \"bash\" , \"/scripts/kc_setup_keyfile.sh\" , \"http://localhost:8888/auth\" , \"admin\" , \"admin\" , \"PORI\" , \"/keys/keycloak.key\" ] interval : 45s timeout : 10s retries : 5 volumes : - source : ./keys target : /keys type : bind graphkb_db : image : orientdb:3.0 environment : # customize settings below ORIENTDB_ROOT_PASSWORD : root ports : - 2424:2424 - 2480:2480 networks : - app-network volumes : - source : ./databases/orientdb/data target : /orientdb/databases type : bind - source : ./databases/orientdb/backup target : /orientdb/backup type : bind graphkb_api : image : bcgsc/pori-graphkb-api:latest ports : - 8080:8080 environment : GKB_DB_CREATE : 1 GKB_DB_HOST : graphkb_db GKB_DB_NAME : graphkb GKB_KEYCLOAK_KEY_FILE : /keys/keycloak.key KEY_PASSPHRASE : '' # customize settings below GKB_CORS_ORIGIN : '^.*$$' GKB_DBS_PASS : root GKB_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token depends_on : - graphkb_db - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://graphkb_api:8080/api/version\" ] interval : 30s timeout : 10s retries : 5 graphkb_client : image : bcgsc/pori-graphkb-client:latest environment : KEYCLOAK_REALM : PORI KEYCLOAK_CLIENT_ID : GraphKB # customize settings below API_BASE_URL : http://localhost:8080 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 5000:80 depends_on : - graphkb_api networks : - app-network restart : always ipr_db : image : bcgsc/pori-ipr-demodb:latest restart : always environment : DATABASE_NAME : ipr_demo POSTGRES_USER : postgres READONLY_USER : ipr_ro SERVICE_USER : ipr_service PGDATA : /var/lib/postgresql/data/pgdata # customize settings below POSTGRES_PASSWORD : root READONLY_PASSWORD : root SERVICE_PASSWORD : root ports : - 5432:5432 networks : - app-network healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready\" ] interval : 10s timeout : 5s retries : 5 redis : image : redis:6.2-alpine # Set health checks to wait until redis has started healthcheck : test : redis-cli ping interval : 10s timeout : 5s retries : 5 ports : # Maps port 6379 on service container to the host - 6379:6379 networks : - app-network restart : always ipr_api : image : bcgsc/pori-ipr-api:latest command : npm start ports : - 8081:8080 environment : IPR_DATABASE_HOSTNAME : ipr_db IPR_DATABASE_NAME : ipr_demo IPR_DATABASE_USERNAME : ipr_ro IPR_GRAPHKB_USERNAME : ipr_graphkb_link IPR_KEYCLOAK_KEYFILE : /keys/keycloak.key # customize settings below IPR_DATABASE_PASSWORD : root IPR_GRAPHKB_PASSWORD : ipr_graphkb_link IPR_GRAPHKB_URI : http://graphkb_api:8080/api IPR_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token IPR_REDIS_HOST : redis IPR_REDIS_PORT : 6379 depends_on : - ipr_db - redis - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://ipr_api:8080/api/spec.json\" ] interval : 30s timeout : 10s retries : 5 ipr_client : image : bcgsc/pori-ipr-client:latest environment : KEYCLOAK_REALM : PORI # customize settings below API_BASE_URL : http://localhost:8081/api GRAPHKB_URL : http://localhost:5000 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 3000:80 depends_on : - ipr_api networks : - app-network restart : always networks : app-network : driver : bridge The demo uses a default keycloak setup with a realm \"PORI\" and two clients: \"GraphKB\" and \"IPR\". For convenience there are also a number of default users which all have the default password of \"secret\". Name Default in DB Purpose graphkb_importer GraphKB This is the default user that is created when the new GraphKB DB is created. It is an admin user that can be used to add new users or import content ipr_graphkb_link GraphKB This is the user used by IPR to pull data from GraphKB iprdemo IPR This is an admin user in the IPR demo db graphkb_admin GraphKB Admin user for managing content/users in the GraphKB web interface Run docker-compose \u00b6 The first thing you should do is create new/empty directories for the data stored by GraphKB and IPR. mkdir -p databases/ { postgres,orientdb } / { backup,data } You should also create a new directory for storing the public key from keycloak. This key will be downloaded and store so that it was be used in checking incoming tokens by the GraphKB and IPR APIs. If this directory already exists you should delete and remake it. mkdir keys Next, use docker-compose to start the DB, API, and client servers. The paths/URLs in the docker-compose.yml file should be adjusted to match your deployment. In our demo deployment we have a proxy pass set up from the configured ports to handle the https layer docker-compose -f docker-compose.dev.yml up -d This will start the following services Postgres db server for IPR with a default db dump OrientDB server for GraphKB with an empty default db GraphKB API server (nodejs) IPR API server (nodejs) GraphKB client server (nginx) IPR client server (nginx) Keycloak Authentication server Once the platform is live you can populate the new GraphKB instance with external content using the loaders. It will take a minute or two for all of the servers to start. You can check how they look with docker docker ps If any of them show \"(health: starting)\" then they are not ready yet. Viewing Log Files \u00b6 Sometimes you will need to check the logs from the various servers, this can be done with the docker logs command. First find the container ID (or name) by listing all the running containers with docker ps and then run the following docker logs <CONTAINER ID> Test Loading Data into GraphKB \u00b6 If you are running the GraphKB loader via its docker container you will need to tell it to use the host network so that it is able to find the GraphKB API. Here is an example of running the GraphKB Loader on the vocabulary terms using the docker container and the docker-compose setup described above. First download the vocabulary terms data wget https://raw.githubusercontent.com/bcgsc/pori_graphkb_loader/develop/data/vocab.json Then you can load these terms using the ontology file loader docker run --net host \\ --mount src = $( pwd ) /vocab.json,dst = /data/vocab.json,type = bind \\ bcgsc/pori-graphkb-loader:latest \\ -u graphkb_importer \\ -p secret \\ -g http://localhost:8080/api \\ file \\ ontology \\ /data/vocab.json Note Because we are running the loader by itself we need to provide the mount arguments to tell docker that we need access to a file outside of the container itself. When we run this with the snakemake pipeline this is not necessary since snakemake generally takes care of that for you Once you have tested that things have been set up correctly and loading is working you are ready to initialize the data in your newly create GraphKB instance. See the loader documentation for further instructions. Production Instances \u00b6 HTTPS \u00b6 For a production instance of PORI you will want to use HTTPS instead of HTTP. The simplest way to accomplish this is with a reverse proxy to pick up the ports. This way you can run the platform as above, with http, when initially setting up and testing. Once you have your reverse proxy set up and configured you can use the newly bound URLs in place of the http://hostname:port URLs. An example of what the HTTPs URLs using a reverse proxy may look like is included in the \"prod\" version of the docker-compose file, however you would need to replace these with your own URLs and mappings Keycloak \u00b6 In the docker-compose.dev.yml example, we are using the embedded h2 database with keycloak for simplicity, if you are using this in production you should use an external database with keycloak. Our production version does not include keycloak at all as it is run seperately since it is used for many different applications beyond PORI.","title":"Install with Docker"},{"location":"install/#install-with-docker","text":"Since PORI is a production-ready, institution-level, scalable platform, the simplest way to get the entire platform up and running from scratch is using docker . For simplicity the default instructions set up the platform with http. Most of the servers are auto-started together with docker-compose but the keycloak container must be started and configured on its own first. Start by cloning this repository which contains the default docker compose configs ( docker-compose.yml and docker-compose.dev.yml ) git clone https://github.com/bcgsc/pori.git cd pori For working on most of the PORI-related projects you will need to have a number of the components set up. For example, to work on the GraphKB API you will need both an OrientDB server and a Keycloak server already running. If your institution regularly works on PORI related projects then we recommend setting up a development instance of the PORI platform which your developers can point their applications to. If you do not have access to something like this, then the easiest way to get the dependencies for whatever part of the PORI platform you are working on up and running is by running the development version of the docker compose configuration found in this repository: docker-compose.dev.yml . docker-compose.dev.yml # This version of the docker-compose sets up the servers using http only for testing locally and # therefore does not require the top level apache server to configure the URLs version : '3' services : keycloak : build : context : . dockerfile : ./demo/Dockerfile.auth environment : KEYCLOAK_USER : admin KEYCLOAK_PASSWORD : admin PROXY_ADDRESS_FORWARDING : \"true\" JAVA_OPTS_APPEND : \"-Djboss.socket.binding.port-offset=808\" ports : - 8888:8888 networks : - app-network healthcheck : # test fetching public key from PORI realm test : [ \"CMD\" , \"bash\" , \"/scripts/kc_setup_keyfile.sh\" , \"http://localhost:8888/auth\" , \"admin\" , \"admin\" , \"PORI\" , \"/keys/keycloak.key\" ] interval : 45s timeout : 10s retries : 5 volumes : - source : ./keys target : /keys type : bind graphkb_db : image : orientdb:3.0 environment : # customize settings below ORIENTDB_ROOT_PASSWORD : root ports : - 2424:2424 - 2480:2480 networks : - app-network volumes : - source : ./databases/orientdb/data target : /orientdb/databases type : bind - source : ./databases/orientdb/backup target : /orientdb/backup type : bind graphkb_api : image : bcgsc/pori-graphkb-api:latest ports : - 8080:8080 environment : GKB_DB_CREATE : 1 GKB_DB_HOST : graphkb_db GKB_DB_NAME : graphkb GKB_KEYCLOAK_KEY_FILE : /keys/keycloak.key KEY_PASSPHRASE : '' # customize settings below GKB_CORS_ORIGIN : '^.*$$' GKB_DBS_PASS : root GKB_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token depends_on : - graphkb_db - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://graphkb_api:8080/api/version\" ] interval : 30s timeout : 10s retries : 5 graphkb_client : image : bcgsc/pori-graphkb-client:latest environment : KEYCLOAK_REALM : PORI KEYCLOAK_CLIENT_ID : GraphKB # customize settings below API_BASE_URL : http://localhost:8080 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 5000:80 depends_on : - graphkb_api networks : - app-network restart : always ipr_db : image : bcgsc/pori-ipr-demodb:latest restart : always environment : DATABASE_NAME : ipr_demo POSTGRES_USER : postgres READONLY_USER : ipr_ro SERVICE_USER : ipr_service PGDATA : /var/lib/postgresql/data/pgdata # customize settings below POSTGRES_PASSWORD : root READONLY_PASSWORD : root SERVICE_PASSWORD : root ports : - 5432:5432 networks : - app-network healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready\" ] interval : 10s timeout : 5s retries : 5 redis : image : redis:6.2-alpine # Set health checks to wait until redis has started healthcheck : test : redis-cli ping interval : 10s timeout : 5s retries : 5 ports : # Maps port 6379 on service container to the host - 6379:6379 networks : - app-network restart : always ipr_api : image : bcgsc/pori-ipr-api:latest command : npm start ports : - 8081:8080 environment : IPR_DATABASE_HOSTNAME : ipr_db IPR_DATABASE_NAME : ipr_demo IPR_DATABASE_USERNAME : ipr_ro IPR_GRAPHKB_USERNAME : ipr_graphkb_link IPR_KEYCLOAK_KEYFILE : /keys/keycloak.key # customize settings below IPR_DATABASE_PASSWORD : root IPR_GRAPHKB_PASSWORD : ipr_graphkb_link IPR_GRAPHKB_URI : http://graphkb_api:8080/api IPR_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token IPR_REDIS_HOST : redis IPR_REDIS_PORT : 6379 depends_on : - ipr_db - redis - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://ipr_api:8080/api/spec.json\" ] interval : 30s timeout : 10s retries : 5 ipr_client : image : bcgsc/pori-ipr-client:latest environment : KEYCLOAK_REALM : PORI # customize settings below API_BASE_URL : http://localhost:8081/api GRAPHKB_URL : http://localhost:5000 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 3000:80 depends_on : - ipr_api networks : - app-network restart : always networks : app-network : driver : bridge The demo uses a default keycloak setup with a realm \"PORI\" and two clients: \"GraphKB\" and \"IPR\". For convenience there are also a number of default users which all have the default password of \"secret\". Name Default in DB Purpose graphkb_importer GraphKB This is the default user that is created when the new GraphKB DB is created. It is an admin user that can be used to add new users or import content ipr_graphkb_link GraphKB This is the user used by IPR to pull data from GraphKB iprdemo IPR This is an admin user in the IPR demo db graphkb_admin GraphKB Admin user for managing content/users in the GraphKB web interface","title":"Install with Docker"},{"location":"install/#run-docker-compose","text":"The first thing you should do is create new/empty directories for the data stored by GraphKB and IPR. mkdir -p databases/ { postgres,orientdb } / { backup,data } You should also create a new directory for storing the public key from keycloak. This key will be downloaded and store so that it was be used in checking incoming tokens by the GraphKB and IPR APIs. If this directory already exists you should delete and remake it. mkdir keys Next, use docker-compose to start the DB, API, and client servers. The paths/URLs in the docker-compose.yml file should be adjusted to match your deployment. In our demo deployment we have a proxy pass set up from the configured ports to handle the https layer docker-compose -f docker-compose.dev.yml up -d This will start the following services Postgres db server for IPR with a default db dump OrientDB server for GraphKB with an empty default db GraphKB API server (nodejs) IPR API server (nodejs) GraphKB client server (nginx) IPR client server (nginx) Keycloak Authentication server Once the platform is live you can populate the new GraphKB instance with external content using the loaders. It will take a minute or two for all of the servers to start. You can check how they look with docker docker ps If any of them show \"(health: starting)\" then they are not ready yet.","title":"Run docker-compose"},{"location":"install/#viewing-log-files","text":"Sometimes you will need to check the logs from the various servers, this can be done with the docker logs command. First find the container ID (or name) by listing all the running containers with docker ps and then run the following docker logs <CONTAINER ID>","title":"Viewing Log Files"},{"location":"install/#test-loading-data-into-graphkb","text":"If you are running the GraphKB loader via its docker container you will need to tell it to use the host network so that it is able to find the GraphKB API. Here is an example of running the GraphKB Loader on the vocabulary terms using the docker container and the docker-compose setup described above. First download the vocabulary terms data wget https://raw.githubusercontent.com/bcgsc/pori_graphkb_loader/develop/data/vocab.json Then you can load these terms using the ontology file loader docker run --net host \\ --mount src = $( pwd ) /vocab.json,dst = /data/vocab.json,type = bind \\ bcgsc/pori-graphkb-loader:latest \\ -u graphkb_importer \\ -p secret \\ -g http://localhost:8080/api \\ file \\ ontology \\ /data/vocab.json Note Because we are running the loader by itself we need to provide the mount arguments to tell docker that we need access to a file outside of the container itself. When we run this with the snakemake pipeline this is not necessary since snakemake generally takes care of that for you Once you have tested that things have been set up correctly and loading is working you are ready to initialize the data in your newly create GraphKB instance. See the loader documentation for further instructions.","title":"Test Loading Data into GraphKB"},{"location":"install/#production-instances","text":"","title":"Production Instances"},{"location":"install/#https","text":"For a production instance of PORI you will want to use HTTPS instead of HTTP. The simplest way to accomplish this is with a reverse proxy to pick up the ports. This way you can run the platform as above, with http, when initially setting up and testing. Once you have your reverse proxy set up and configured you can use the newly bound URLs in place of the http://hostname:port URLs. An example of what the HTTPs URLs using a reverse proxy may look like is included in the \"prod\" version of the docker-compose file, however you would need to replace these with your own URLs and mappings","title":"HTTPS"},{"location":"install/#keycloak","text":"In the docker-compose.dev.yml example, we are using the embedded h2 database with keycloak for simplicity, if you are using this in production you should use an external database with keycloak. Our production version does not include keycloak at all as it is run seperately since it is used for many different applications beyond PORI.","title":"Keycloak"},{"location":"repos/","text":"All PORI Repositories \u00b6 The platform has two main components: a graph knowledge base ( GraphKB ), and a reporting application ( IPR ). However these are modularized across several repositories listed below. An overview of each project is given below. The projects are grouped by their type of development expertise. Front-End Web Development \u00b6 In general our web clients are written in javascript/typescript and use React , Material-UI , and webpack . There are two main web client projects as part of PORI GraphKB client \u00b6 The GraphKB client is the front-end web client for the GraphKB project. The client is used to explore and manage content within GraphKB. This is the primary way for knowledge base users to interact with GraphKB. It contains a graph-based view and support for common query operations. It also allows export of results up to 5K rows (larger exports should be done via the API). IPR client \u00b6 The IPR client is the front-end web application which consumes data from the IPR API. The primary function is the production and management of genomic reports. Case Analysts use the IPR client to curate and review reports prior to presentation to a molecular tumour board or dissemination. Back-End Web Development \u00b6 The REST APIs that are part of PORI are written in javascript and are run using NodeJS . Both are built on the popular Express framework. The database and corresponding object relational mapper (ORM) is where they differ. The IPR API uses Postgres and sequelize whereas the GraphKB API uses OrientDB and orientjs . Both APIs implement swagger/openapi documentation for developers using the APIs. GraphKB API \u00b6 GraphKB REST API and Graph Database. The GraphKB database is a graph database which is used to store variants, ontologies, and the relevance of these terms and variants. The KB uses strict controlled vocabulary to provide a parseable and machine-readable interface for other applications to build on. IPR API \u00b6 The Integrated Pipeline Reports (IPR) REST API manages data access to the IPR database. The API is responsible for storing and serving all data for reports. ETL / Data Loading \u00b6 The GraphKB project also includes a loaders package which is used to import content from external knowledge bases and ontologies into GraphKB. Writing these loaders requires a strong understanding of the knowledge graph structure of GraphKB as well as the structure of the target resource. The loaders are written in javscript to be able to leverage the parser and schema JS packages used by the API and client. They are run with NodeJS . A list of the popular supported inputs can be found in the loading data section . GraphKB Data Loaders \u00b6 GraphKB loaders is responsible for all data import into GraphKB. Automatic Import modules are provided for a variety of external ontologies and knowledge bases such as: Ensembl, Entrez Genes, RefSeq, HGNC, Disease Ontology, NCI Thesaurus, CIViC, DoCM, etc. Python Adapters \u00b6 The popularity of python in bioinformatics makes it one of the top choices for adapters. These adapters are written to help users integrate PORI into their existing bioinformatic workflows. They are published and installed via pip. pip install graphkb ipr A developer reference for these packages including the function signatures and package details can be found in the developer reference section here . GraphKB Python Adapter \u00b6 Python adapter package for querying the GraphKB API. See the related user manual for instructions on incorporating this into custom scripts. IPR Python Adapter \u00b6 Python adapter for generating reports uploaded to the IPR API. This python tool takes in variant inputs as tab-delimited files and annotates them using GraphKB. The resulting output is uploaded to IPR as a report. Additional report content such as images and metadata can be passed to be included in the report upload. PORI cBioportal \u00b6 This python adapter is intended to demonstrate creating a PORI report using data exported from a cBioportal instance. It uses the expression, copy number, fusion, and small mutation data as well as available metadata to complete the reports. Other Supporting Packages \u00b6 There are a number of packages that are split into separate projects so that they can be re-used across the other PORI projects. For example, the GraphKB parser is used by the GraphKB API, the GraphKB Client, and the GraphKB data loaders. GraphKB Parser \u00b6 A package for parsing and recreating HGVS-like variant notation used in GraphKB. This is used by both the API and client applications. Try it out online with RunKit GraphKB Schema \u00b6 The GraphKB Schema package defines the vertex and edge classes in the DB. It is used as a dependency of both the API and client applications.","title":"All PORI Repositories"},{"location":"repos/#all-pori-repositories","text":"The platform has two main components: a graph knowledge base ( GraphKB ), and a reporting application ( IPR ). However these are modularized across several repositories listed below. An overview of each project is given below. The projects are grouped by their type of development expertise.","title":"All PORI Repositories"},{"location":"repos/#front-end-web-development","text":"In general our web clients are written in javascript/typescript and use React , Material-UI , and webpack . There are two main web client projects as part of PORI","title":"Front-End Web Development"},{"location":"repos/#graphkb-client","text":"The GraphKB client is the front-end web client for the GraphKB project. The client is used to explore and manage content within GraphKB. This is the primary way for knowledge base users to interact with GraphKB. It contains a graph-based view and support for common query operations. It also allows export of results up to 5K rows (larger exports should be done via the API).","title":"GraphKB client"},{"location":"repos/#ipr-client","text":"The IPR client is the front-end web application which consumes data from the IPR API. The primary function is the production and management of genomic reports. Case Analysts use the IPR client to curate and review reports prior to presentation to a molecular tumour board or dissemination.","title":"IPR client"},{"location":"repos/#back-end-web-development","text":"The REST APIs that are part of PORI are written in javascript and are run using NodeJS . Both are built on the popular Express framework. The database and corresponding object relational mapper (ORM) is where they differ. The IPR API uses Postgres and sequelize whereas the GraphKB API uses OrientDB and orientjs . Both APIs implement swagger/openapi documentation for developers using the APIs.","title":"Back-End Web Development"},{"location":"repos/#graphkb-api","text":"GraphKB REST API and Graph Database. The GraphKB database is a graph database which is used to store variants, ontologies, and the relevance of these terms and variants. The KB uses strict controlled vocabulary to provide a parseable and machine-readable interface for other applications to build on.","title":"GraphKB API"},{"location":"repos/#ipr-api","text":"The Integrated Pipeline Reports (IPR) REST API manages data access to the IPR database. The API is responsible for storing and serving all data for reports.","title":"IPR API"},{"location":"repos/#etl-data-loading","text":"The GraphKB project also includes a loaders package which is used to import content from external knowledge bases and ontologies into GraphKB. Writing these loaders requires a strong understanding of the knowledge graph structure of GraphKB as well as the structure of the target resource. The loaders are written in javscript to be able to leverage the parser and schema JS packages used by the API and client. They are run with NodeJS . A list of the popular supported inputs can be found in the loading data section .","title":"ETL / Data Loading"},{"location":"repos/#graphkb-data-loaders","text":"GraphKB loaders is responsible for all data import into GraphKB. Automatic Import modules are provided for a variety of external ontologies and knowledge bases such as: Ensembl, Entrez Genes, RefSeq, HGNC, Disease Ontology, NCI Thesaurus, CIViC, DoCM, etc.","title":"GraphKB Data Loaders"},{"location":"repos/#python-adapters","text":"The popularity of python in bioinformatics makes it one of the top choices for adapters. These adapters are written to help users integrate PORI into their existing bioinformatic workflows. They are published and installed via pip. pip install graphkb ipr A developer reference for these packages including the function signatures and package details can be found in the developer reference section here .","title":"Python Adapters"},{"location":"repos/#graphkb-python-adapter","text":"Python adapter package for querying the GraphKB API. See the related user manual for instructions on incorporating this into custom scripts.","title":"GraphKB Python Adapter"},{"location":"repos/#ipr-python-adapter","text":"Python adapter for generating reports uploaded to the IPR API. This python tool takes in variant inputs as tab-delimited files and annotates them using GraphKB. The resulting output is uploaded to IPR as a report. Additional report content such as images and metadata can be passed to be included in the report upload.","title":"IPR Python Adapter"},{"location":"repos/#pori-cbioportal","text":"This python adapter is intended to demonstrate creating a PORI report using data exported from a cBioportal instance. It uses the expression, copy number, fusion, and small mutation data as well as available metadata to complete the reports.","title":"PORI cBioportal"},{"location":"repos/#other-supporting-packages","text":"There are a number of packages that are split into separate projects so that they can be re-used across the other PORI projects. For example, the GraphKB parser is used by the GraphKB API, the GraphKB Client, and the GraphKB data loaders.","title":"Other Supporting Packages"},{"location":"repos/#graphkb-parser","text":"A package for parsing and recreating HGVS-like variant notation used in GraphKB. This is used by both the API and client applications. Try it out online with RunKit","title":"GraphKB Parser"},{"location":"repos/#graphkb-schema","text":"The GraphKB Schema package defines the vertex and edge classes in the DB. It is used as a dependency of both the API and client applications.","title":"GraphKB Schema"},{"location":"developer_reference/","text":"About the Developer Reference \u00b6 This section contains auto-generated documentation from package implementations and docstrings generated via the python package markdown_refdocs .","title":"About the Developer Reference"},{"location":"developer_reference/#about-the-developer-reference","text":"This section contains auto-generated documentation from package implementations and docstrings generated via the python package markdown_refdocs .","title":"About the Developer Reference"},{"location":"developer_reference/contributing/","text":"Contributing Guidelines \u00b6 If you are new to PORI and would like to contribute, writing tests and documentation is a great way to familiarize yourself with the project. An overview of our developer guidelines and best practices is given below. Tests \u00b6 When new features are added, corresponding tests should be implemented as well. We use jest for both API and client testing. The client additionally uses React Testing Library . Tests for python adaptors are written using pytest . Tests for all repositories will be automatically run as a part of their GitHub Actions plan. See the next section for more details. CI / CD \u00b6 Every PORI repository has a corresponding github actions plan. These plans automate running tests, testing that documentation will build, as well as building and deploying docker containers when relevant. In general the following patterns are used. On Push \u00b6 tests are run docker containers are built to test they can build without errors linting / style-checking is performed On Release \u00b6 Python Adapters are published to PyPI Docker containers are published to DockerHub Documentation \u00b6 Documentation is critical both for the developers and the users. Docstrings / Function Documentation \u00b6 Functions should contain docstrings. The most important part here is the short description of the purpose of the function. Python \u00b6 In python these use the Google style docstrings. These will be automatically parsed to include in the developer reference section of this site by the markdown_refdocs package. Any variables that are not self explanatory (ex. input_file_path ) should include a parameter description as well. Types do not need to be included where a typing annotation has been added in the function signature. Example of a well documented function def positions_overlap ( pos_record : BasicPosition , range_start : BasicPosition , range_end : Optional [ BasicPosition ] = None ) -> bool : \"\"\" Check if 2 Position records from GraphKB indicate an overlap Note: null values indicate not-specified or any Args: pos_record: the record to compare range_start: the position record indicating the start of an uncertainty range range_end: the position record indicating the end of an uncertainty range Raises: NotImplementedError: if a cytoband type position is given Returns: True if the positions overlap \"\"\" Javascript / TypeScript \u00b6 We also use docstrings here. However in contrast to python these are immediately outside the function instead of following the function definition. These docstrings follow JSDoc syntax. If types are included (typescript) in the code then the types can be omitted from the docstring itself. An example of a well documented function is given below /** * Convert parsed breakpoints into a string representing the breakpoint range * * @param {Position} start the start of the breakpoint range * @param {Position} [end=null] the end of the breakpoint range (if the breakpoint is a range) * @param {boolean} [multiFeature=false] flag to indicate this is for multi-feature notation and should not contain brackets * * @returns {string} the string representation of a breakpoint or breakpoint range including the prefix */ const breakRepr = ( start , end = null , multiFeature = false ) => { User Documentation \u00b6 The user documentation should be updated in the central PORI documentation repository (this repository) when any changes are made which will affect the users. Furthermore all releases should contain a summary of the major and minor changes in their release tag for users who may be following the github page. Code Style \u00b6 In general we try to use automated tools to enforce code style. This helps avoid adding extra work for the developers and also makes the style choices transparent and consistent. For javascript/typescript we use ESLint to enforce compliance. For python files we use Black . These checks are generally run and included in the automated builds. Branching Model \u00b6 We use a fairly standard branching model which includes a base development branch (develop) and a stable main branch (master). Feature and bugfix branches are created off develop. Release braches are created off develop (or master for a quick/hotfix) and then a PR is made to master. image credit : A successful Git branching model . Following a release, the master branch is merged back into the development branch. Releases \u00b6 General Release Process \u00b6 In the following running example we are making the release v5.2.0 Make a release branch off develop git checkout develop git pull git checkout -b release/v5.2.0 git push --set-upstream origin release/v5.2.0 Edit the version files (see Versioning below) Set up a pull request (PR) from the Release Branch to the Master Branch The PR description should match what the upcoming release notes will be. This gives the reviewers a chance to review the release notes as part of the PR review Once approved and merged, tag a release on master (see Release Notes ) Finally, make a PR from master to develop. This should just be called something like \"master back to dev\" and does not require a description Versioning \u00b6 Each project in PORI uses semantic versioning . For python projects this should be written in the setup.py script setup ( version = 'X.X.X' , ) And for javascript/typescript projects it will be found in the package.json/package-lock.json files { \"version\" : \"X.X.X\" , } Version for both will follow the <MAJOR>.<MINOR>.<PATCH> pattern where Increment Type Types of Changes Description MAJOR Breaking Changes when you make incompatible API changes MINOR New Features or Significant Improvements when you add functionality in a backwards-compatible manner PATCH BugFixes or Minor/Trivial Improvements when you make backwards-compatible bug fixes (or other TRIVIAL changes. ex. fixing a spelling error in documentation) The tag (release) in github itself should begin with a v followed by the current version (ex. v5.2.0 ) Release Notes \u00b6 Try to group changes with Major or Breaking changes at the top, followed by new features and then bugfixes and improvements. This way the content the users are likely most interested in is at the top. Release notes should be added when the release is created via the github interface and look something like this Breaking Changes - TICKET-ID: A major breaking change New Features - TICKET-ID: Any additional functionality Improvements - TICKET-ID: Minor changes to existing functionality: ex. linting BugFixes - TICKET-ID: Any bugFixes All releases should be created off of the master branch. An example of a release should look something like this. Note the release notes have been circled in red.","title":"Contributing Guidelines"},{"location":"developer_reference/contributing/#contributing-guidelines","text":"If you are new to PORI and would like to contribute, writing tests and documentation is a great way to familiarize yourself with the project. An overview of our developer guidelines and best practices is given below.","title":"Contributing Guidelines"},{"location":"developer_reference/contributing/#tests","text":"When new features are added, corresponding tests should be implemented as well. We use jest for both API and client testing. The client additionally uses React Testing Library . Tests for python adaptors are written using pytest . Tests for all repositories will be automatically run as a part of their GitHub Actions plan. See the next section for more details.","title":"Tests"},{"location":"developer_reference/contributing/#ci-cd","text":"Every PORI repository has a corresponding github actions plan. These plans automate running tests, testing that documentation will build, as well as building and deploying docker containers when relevant. In general the following patterns are used.","title":"CI / CD"},{"location":"developer_reference/contributing/#on-push","text":"tests are run docker containers are built to test they can build without errors linting / style-checking is performed","title":"On Push"},{"location":"developer_reference/contributing/#on-release","text":"Python Adapters are published to PyPI Docker containers are published to DockerHub","title":"On Release"},{"location":"developer_reference/contributing/#documentation","text":"Documentation is critical both for the developers and the users.","title":"Documentation"},{"location":"developer_reference/contributing/#docstrings-function-documentation","text":"Functions should contain docstrings. The most important part here is the short description of the purpose of the function.","title":"Docstrings / Function Documentation"},{"location":"developer_reference/contributing/#python","text":"In python these use the Google style docstrings. These will be automatically parsed to include in the developer reference section of this site by the markdown_refdocs package. Any variables that are not self explanatory (ex. input_file_path ) should include a parameter description as well. Types do not need to be included where a typing annotation has been added in the function signature. Example of a well documented function def positions_overlap ( pos_record : BasicPosition , range_start : BasicPosition , range_end : Optional [ BasicPosition ] = None ) -> bool : \"\"\" Check if 2 Position records from GraphKB indicate an overlap Note: null values indicate not-specified or any Args: pos_record: the record to compare range_start: the position record indicating the start of an uncertainty range range_end: the position record indicating the end of an uncertainty range Raises: NotImplementedError: if a cytoband type position is given Returns: True if the positions overlap \"\"\"","title":"Python"},{"location":"developer_reference/contributing/#javascript-typescript","text":"We also use docstrings here. However in contrast to python these are immediately outside the function instead of following the function definition. These docstrings follow JSDoc syntax. If types are included (typescript) in the code then the types can be omitted from the docstring itself. An example of a well documented function is given below /** * Convert parsed breakpoints into a string representing the breakpoint range * * @param {Position} start the start of the breakpoint range * @param {Position} [end=null] the end of the breakpoint range (if the breakpoint is a range) * @param {boolean} [multiFeature=false] flag to indicate this is for multi-feature notation and should not contain brackets * * @returns {string} the string representation of a breakpoint or breakpoint range including the prefix */ const breakRepr = ( start , end = null , multiFeature = false ) => {","title":"Javascript / TypeScript"},{"location":"developer_reference/contributing/#user-documentation","text":"The user documentation should be updated in the central PORI documentation repository (this repository) when any changes are made which will affect the users. Furthermore all releases should contain a summary of the major and minor changes in their release tag for users who may be following the github page.","title":"User Documentation"},{"location":"developer_reference/contributing/#code-style","text":"In general we try to use automated tools to enforce code style. This helps avoid adding extra work for the developers and also makes the style choices transparent and consistent. For javascript/typescript we use ESLint to enforce compliance. For python files we use Black . These checks are generally run and included in the automated builds.","title":"Code Style"},{"location":"developer_reference/contributing/#branching-model","text":"We use a fairly standard branching model which includes a base development branch (develop) and a stable main branch (master). Feature and bugfix branches are created off develop. Release braches are created off develop (or master for a quick/hotfix) and then a PR is made to master. image credit : A successful Git branching model . Following a release, the master branch is merged back into the development branch.","title":"Branching Model"},{"location":"developer_reference/contributing/#releases","text":"","title":"Releases"},{"location":"developer_reference/contributing/#general-release-process","text":"In the following running example we are making the release v5.2.0 Make a release branch off develop git checkout develop git pull git checkout -b release/v5.2.0 git push --set-upstream origin release/v5.2.0 Edit the version files (see Versioning below) Set up a pull request (PR) from the Release Branch to the Master Branch The PR description should match what the upcoming release notes will be. This gives the reviewers a chance to review the release notes as part of the PR review Once approved and merged, tag a release on master (see Release Notes ) Finally, make a PR from master to develop. This should just be called something like \"master back to dev\" and does not require a description","title":"General Release Process"},{"location":"developer_reference/contributing/#versioning","text":"Each project in PORI uses semantic versioning . For python projects this should be written in the setup.py script setup ( version = 'X.X.X' , ) And for javascript/typescript projects it will be found in the package.json/package-lock.json files { \"version\" : \"X.X.X\" , } Version for both will follow the <MAJOR>.<MINOR>.<PATCH> pattern where Increment Type Types of Changes Description MAJOR Breaking Changes when you make incompatible API changes MINOR New Features or Significant Improvements when you add functionality in a backwards-compatible manner PATCH BugFixes or Minor/Trivial Improvements when you make backwards-compatible bug fixes (or other TRIVIAL changes. ex. fixing a spelling error in documentation) The tag (release) in github itself should begin with a v followed by the current version (ex. v5.2.0 )","title":"Versioning"},{"location":"developer_reference/contributing/#release-notes","text":"Try to group changes with Major or Breaking changes at the top, followed by new features and then bugfixes and improvements. This way the content the users are likely most interested in is at the top. Release notes should be added when the release is created via the github interface and look something like this Breaking Changes - TICKET-ID: A major breaking change New Features - TICKET-ID: Any additional functionality Improvements - TICKET-ID: Minor changes to existing functionality: ex. linting BugFixes - TICKET-ID: Any bugFixes All releases should be created off of the master branch. An example of a release should look something like this. Note the release notes have been circled in red.","title":"Release Notes"},{"location":"developer_reference/getting_started/","text":"Getting Started \u00b6 For working on most of the PORI-related projects you will need to have a number of the components set up. For example, to work on the GraphKB API you will need both an OrientDB server and a Keycloak server already running. If your institution regularly works on PORI related projects then we recommend setting up a development instance of the PORI platform which your developers can point their applications to. If you do not have access to something like this, then the easiest way to get the dependencies for whatever part of the PORI platform you are working on up and running is by running the development version of the docker compose configuration found in this repository: docker-compose.dev.yml . docker-compose.dev.yml # This version of the docker-compose sets up the servers using http only for testing locally and # therefore does not require the top level apache server to configure the URLs version : '3' services : keycloak : build : context : . dockerfile : ./demo/Dockerfile.auth environment : KEYCLOAK_USER : admin KEYCLOAK_PASSWORD : admin PROXY_ADDRESS_FORWARDING : \"true\" JAVA_OPTS_APPEND : \"-Djboss.socket.binding.port-offset=808\" ports : - 8888:8888 networks : - app-network healthcheck : # test fetching public key from PORI realm test : [ \"CMD\" , \"bash\" , \"/scripts/kc_setup_keyfile.sh\" , \"http://localhost:8888/auth\" , \"admin\" , \"admin\" , \"PORI\" , \"/keys/keycloak.key\" ] interval : 45s timeout : 10s retries : 5 volumes : - source : ./keys target : /keys type : bind graphkb_db : image : orientdb:3.0 environment : # customize settings below ORIENTDB_ROOT_PASSWORD : root ports : - 2424:2424 - 2480:2480 networks : - app-network volumes : - source : ./databases/orientdb/data target : /orientdb/databases type : bind - source : ./databases/orientdb/backup target : /orientdb/backup type : bind graphkb_api : image : bcgsc/pori-graphkb-api:latest ports : - 8080:8080 environment : GKB_DB_CREATE : 1 GKB_DB_HOST : graphkb_db GKB_DB_NAME : graphkb GKB_KEYCLOAK_KEY_FILE : /keys/keycloak.key KEY_PASSPHRASE : '' # customize settings below GKB_CORS_ORIGIN : '^.*$$' GKB_DBS_PASS : root GKB_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token depends_on : - graphkb_db - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://graphkb_api:8080/api/version\" ] interval : 30s timeout : 10s retries : 5 graphkb_client : image : bcgsc/pori-graphkb-client:latest environment : KEYCLOAK_REALM : PORI KEYCLOAK_CLIENT_ID : GraphKB # customize settings below API_BASE_URL : http://localhost:8080 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 5000:80 depends_on : - graphkb_api networks : - app-network restart : always ipr_db : image : bcgsc/pori-ipr-demodb:latest restart : always environment : DATABASE_NAME : ipr_demo POSTGRES_USER : postgres READONLY_USER : ipr_ro SERVICE_USER : ipr_service PGDATA : /var/lib/postgresql/data/pgdata # customize settings below POSTGRES_PASSWORD : root READONLY_PASSWORD : root SERVICE_PASSWORD : root ports : - 5432:5432 networks : - app-network healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready\" ] interval : 10s timeout : 5s retries : 5 redis : image : redis:6.2-alpine # Set health checks to wait until redis has started healthcheck : test : redis-cli ping interval : 10s timeout : 5s retries : 5 ports : # Maps port 6379 on service container to the host - 6379:6379 networks : - app-network restart : always ipr_api : image : bcgsc/pori-ipr-api:latest command : npm start ports : - 8081:8080 environment : IPR_DATABASE_HOSTNAME : ipr_db IPR_DATABASE_NAME : ipr_demo IPR_DATABASE_USERNAME : ipr_ro IPR_GRAPHKB_USERNAME : ipr_graphkb_link IPR_KEYCLOAK_KEYFILE : /keys/keycloak.key # customize settings below IPR_DATABASE_PASSWORD : root IPR_GRAPHKB_PASSWORD : ipr_graphkb_link IPR_GRAPHKB_URI : http://graphkb_api:8080/api IPR_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token IPR_REDIS_HOST : redis IPR_REDIS_PORT : 6379 depends_on : - ipr_db - redis - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://ipr_api:8080/api/spec.json\" ] interval : 30s timeout : 10s retries : 5 ipr_client : image : bcgsc/pori-ipr-client:latest environment : KEYCLOAK_REALM : PORI # customize settings below API_BASE_URL : http://localhost:8081/api GRAPHKB_URL : http://localhost:5000 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 3000:80 depends_on : - ipr_api networks : - app-network restart : always networks : app-network : driver : bridge The demo uses a default keycloak setup with a realm \"PORI\" and two clients: \"GraphKB\" and \"IPR\". For convenience there are also a number of default users which all have the default password of \"secret\". Run docker-compose \u00b6 First thing you should do is create new/empty directories for the data stored by GraphKB and IPR. mkdir -p databases/ { postgres,orientdb } / { backup,data } You should also create a new directory for storing the public key from keycloak. This key will be downloaded and stored so that it can be used in checking incoming tokens by the GraphKB and IPR APIs. If this directory already exists you should delete and remake it. mkdir keys Now you are ready to start up with the dev compose yml docker-compose -f docker-compose.dev.yml up -d It will take a minute or two for all of the servers to start. You can check how they look with docker docker ps If any of them show \"(health: starting)\" then they are not ready yet. Viewing Log Files \u00b6 Sometimes you will need to check the logs from the various servers, this can be done with the docker logs command. First find the container ID (or name) by listing all the running containers with docker ps and then run the following docker logs <CONTAINER ID> Loading Data into GraphKB \u00b6 If you are running the GraphKB loader via its docker container you will need to tell it to use the host network so that it is able to find the GraphKB API. Here is an example of running the GraphKB Loader on the vocabulary terms using the docker container and the docker-compose setup described above. First download the vocabulary terms data wget https://raw.githubusercontent.com/bcgsc/pori_graphkb_loader/develop/data/vocab.json Then you can load these terms using the ontology file loader docker run --net host bcgsc/pori-graphkb-loader:latest \\ -u graphkb_importer \\ -p secret \\ -g http://localhost:8888/api \\ file \\ ontology \\ vocab.json","title":"Getting Started"},{"location":"developer_reference/getting_started/#getting-started","text":"For working on most of the PORI-related projects you will need to have a number of the components set up. For example, to work on the GraphKB API you will need both an OrientDB server and a Keycloak server already running. If your institution regularly works on PORI related projects then we recommend setting up a development instance of the PORI platform which your developers can point their applications to. If you do not have access to something like this, then the easiest way to get the dependencies for whatever part of the PORI platform you are working on up and running is by running the development version of the docker compose configuration found in this repository: docker-compose.dev.yml . docker-compose.dev.yml # This version of the docker-compose sets up the servers using http only for testing locally and # therefore does not require the top level apache server to configure the URLs version : '3' services : keycloak : build : context : . dockerfile : ./demo/Dockerfile.auth environment : KEYCLOAK_USER : admin KEYCLOAK_PASSWORD : admin PROXY_ADDRESS_FORWARDING : \"true\" JAVA_OPTS_APPEND : \"-Djboss.socket.binding.port-offset=808\" ports : - 8888:8888 networks : - app-network healthcheck : # test fetching public key from PORI realm test : [ \"CMD\" , \"bash\" , \"/scripts/kc_setup_keyfile.sh\" , \"http://localhost:8888/auth\" , \"admin\" , \"admin\" , \"PORI\" , \"/keys/keycloak.key\" ] interval : 45s timeout : 10s retries : 5 volumes : - source : ./keys target : /keys type : bind graphkb_db : image : orientdb:3.0 environment : # customize settings below ORIENTDB_ROOT_PASSWORD : root ports : - 2424:2424 - 2480:2480 networks : - app-network volumes : - source : ./databases/orientdb/data target : /orientdb/databases type : bind - source : ./databases/orientdb/backup target : /orientdb/backup type : bind graphkb_api : image : bcgsc/pori-graphkb-api:latest ports : - 8080:8080 environment : GKB_DB_CREATE : 1 GKB_DB_HOST : graphkb_db GKB_DB_NAME : graphkb GKB_KEYCLOAK_KEY_FILE : /keys/keycloak.key KEY_PASSPHRASE : '' # customize settings below GKB_CORS_ORIGIN : '^.*$$' GKB_DBS_PASS : root GKB_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token depends_on : - graphkb_db - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://graphkb_api:8080/api/version\" ] interval : 30s timeout : 10s retries : 5 graphkb_client : image : bcgsc/pori-graphkb-client:latest environment : KEYCLOAK_REALM : PORI KEYCLOAK_CLIENT_ID : GraphKB # customize settings below API_BASE_URL : http://localhost:8080 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 5000:80 depends_on : - graphkb_api networks : - app-network restart : always ipr_db : image : bcgsc/pori-ipr-demodb:latest restart : always environment : DATABASE_NAME : ipr_demo POSTGRES_USER : postgres READONLY_USER : ipr_ro SERVICE_USER : ipr_service PGDATA : /var/lib/postgresql/data/pgdata # customize settings below POSTGRES_PASSWORD : root READONLY_PASSWORD : root SERVICE_PASSWORD : root ports : - 5432:5432 networks : - app-network healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready\" ] interval : 10s timeout : 5s retries : 5 redis : image : redis:6.2-alpine # Set health checks to wait until redis has started healthcheck : test : redis-cli ping interval : 10s timeout : 5s retries : 5 ports : # Maps port 6379 on service container to the host - 6379:6379 networks : - app-network restart : always ipr_api : image : bcgsc/pori-ipr-api:latest command : npm start ports : - 8081:8080 environment : IPR_DATABASE_HOSTNAME : ipr_db IPR_DATABASE_NAME : ipr_demo IPR_DATABASE_USERNAME : ipr_ro IPR_GRAPHKB_USERNAME : ipr_graphkb_link IPR_KEYCLOAK_KEYFILE : /keys/keycloak.key # customize settings below IPR_DATABASE_PASSWORD : root IPR_GRAPHKB_PASSWORD : ipr_graphkb_link IPR_GRAPHKB_URI : http://graphkb_api:8080/api IPR_KEYCLOAK_URI : http://keycloak:8888/auth/realms/PORI/protocol/openid-connect/token IPR_REDIS_HOST : redis IPR_REDIS_PORT : 6379 depends_on : - ipr_db - redis - keycloak networks : - app-network restart : always volumes : - source : ./keys target : /keys type : bind read_only : true healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://ipr_api:8080/api/spec.json\" ] interval : 30s timeout : 10s retries : 5 ipr_client : image : bcgsc/pori-ipr-client:latest environment : KEYCLOAK_REALM : PORI # customize settings below API_BASE_URL : http://localhost:8081/api GRAPHKB_URL : http://localhost:5000 KEYCLOAK_URL : http://localhost:8888/auth PUBLIC_PATH : / ports : - 3000:80 depends_on : - ipr_api networks : - app-network restart : always networks : app-network : driver : bridge The demo uses a default keycloak setup with a realm \"PORI\" and two clients: \"GraphKB\" and \"IPR\". For convenience there are also a number of default users which all have the default password of \"secret\".","title":"Getting Started"},{"location":"developer_reference/getting_started/#run-docker-compose","text":"First thing you should do is create new/empty directories for the data stored by GraphKB and IPR. mkdir -p databases/ { postgres,orientdb } / { backup,data } You should also create a new directory for storing the public key from keycloak. This key will be downloaded and stored so that it can be used in checking incoming tokens by the GraphKB and IPR APIs. If this directory already exists you should delete and remake it. mkdir keys Now you are ready to start up with the dev compose yml docker-compose -f docker-compose.dev.yml up -d It will take a minute or two for all of the servers to start. You can check how they look with docker docker ps If any of them show \"(health: starting)\" then they are not ready yet.","title":"Run docker-compose"},{"location":"developer_reference/getting_started/#viewing-log-files","text":"Sometimes you will need to check the logs from the various servers, this can be done with the docker logs command. First find the container ID (or name) by listing all the running containers with docker ps and then run the following docker logs <CONTAINER ID>","title":"Viewing Log Files"},{"location":"developer_reference/getting_started/#loading-data-into-graphkb","text":"If you are running the GraphKB loader via its docker container you will need to tell it to use the host network so that it is able to find the GraphKB API. Here is an example of running the GraphKB Loader on the vocabulary terms using the docker container and the docker-compose setup described above. First download the vocabulary terms data wget https://raw.githubusercontent.com/bcgsc/pori_graphkb_loader/develop/data/vocab.json Then you can load these terms using the ontology file loader docker run --net host bcgsc/pori-graphkb-loader:latest \\ -u graphkb_importer \\ -p secret \\ -g http://localhost:8888/api \\ file \\ ontology \\ vocab.json","title":"Loading Data into GraphKB"},{"location":"developer_reference/graphkb/__init__/","text":"graphkb \u00b6 DEFAULT_URL \u00b6 DEFAULT_URL = 'https://graphkb-api.bcgsc.ca/api' DEFAULT_LIMIT \u00b6 DEFAULT_LIMIT = 1000 QUERY_CACHE \u00b6 QUERY_CACHE : Dict [ Any , Any ] = {} class GraphKBConnection \u00b6 GraphKBConnection.request() \u00b6 Request wrapper to handle adding common headers and logging def request ( self , endpoint : str , method : str = 'GET' , ** kwargs ) -> Dict : Args endpoint ( str ): api endpoint, excluding the base uri method ( str ): the http method. Defaults to 'GET'. Returns Dict : the json response as a python dict GraphKBConnection.post() \u00b6 Convenience method for making post requests def post ( self , uri : str , data : Dict = {}, ** kwargs ) -> Dict : Args uri ( str ) data ( Dict ) Returns Dict GraphKBConnection.set_cache_data() \u00b6 Explicitly add a query to the cache def set_cache_data ( self , request_body : Dict , result : List [ Record ]) -> None : Args request_body ( Dict ) result (List[ Record ]) GraphKBConnection.query() \u00b6 Query GraphKB def query ( self , request_body : Dict = {}, paginate : bool = True , ignore_cache : bool = False , force_refresh : bool = False , limit : int = DEFAULT_LIMIT , ) -> List [ Record ]: Args request_body ( Dict ) paginate ( bool ) ignore_cache ( bool ) force_refresh ( bool ) limit ( int ) Returns List[ Record ] join_url() \u00b6 Join parts of a URL into a full URL def join_url ( base_url : str , * parts ) -> str : Args base_url ( str ) Returns str millis_interval() \u00b6 start and end are datetime instances def millis_interval ( start : datetime , end : datetime ) -> int : Args start ( datetime ) end ( datetime ) Returns int cache_key() \u00b6 create a cache key for a query request to GraphKB def cache_key ( request_body ): Args request_body","title":"graphkb"},{"location":"developer_reference/graphkb/__init__/#graphkb","text":"","title":"graphkb"},{"location":"developer_reference/graphkb/__init__/#default_url","text":"DEFAULT_URL = 'https://graphkb-api.bcgsc.ca/api'","title":"DEFAULT_URL"},{"location":"developer_reference/graphkb/__init__/#default_limit","text":"DEFAULT_LIMIT = 1000","title":"DEFAULT_LIMIT"},{"location":"developer_reference/graphkb/__init__/#query_cache","text":"QUERY_CACHE : Dict [ Any , Any ] = {}","title":"QUERY_CACHE"},{"location":"developer_reference/graphkb/__init__/#class-graphkbconnection","text":"","title":"class GraphKBConnection"},{"location":"developer_reference/graphkb/__init__/#graphkbconnectionrequest","text":"Request wrapper to handle adding common headers and logging def request ( self , endpoint : str , method : str = 'GET' , ** kwargs ) -> Dict : Args endpoint ( str ): api endpoint, excluding the base uri method ( str ): the http method. Defaults to 'GET'. Returns Dict : the json response as a python dict","title":"GraphKBConnection.request()"},{"location":"developer_reference/graphkb/__init__/#graphkbconnectionpost","text":"Convenience method for making post requests def post ( self , uri : str , data : Dict = {}, ** kwargs ) -> Dict : Args uri ( str ) data ( Dict ) Returns Dict","title":"GraphKBConnection.post()"},{"location":"developer_reference/graphkb/__init__/#graphkbconnectionset_cache_data","text":"Explicitly add a query to the cache def set_cache_data ( self , request_body : Dict , result : List [ Record ]) -> None : Args request_body ( Dict ) result (List[ Record ])","title":"GraphKBConnection.set_cache_data()"},{"location":"developer_reference/graphkb/__init__/#graphkbconnectionquery","text":"Query GraphKB def query ( self , request_body : Dict = {}, paginate : bool = True , ignore_cache : bool = False , force_refresh : bool = False , limit : int = DEFAULT_LIMIT , ) -> List [ Record ]: Args request_body ( Dict ) paginate ( bool ) ignore_cache ( bool ) force_refresh ( bool ) limit ( int ) Returns List[ Record ]","title":"GraphKBConnection.query()"},{"location":"developer_reference/graphkb/__init__/#join_url","text":"Join parts of a URL into a full URL def join_url ( base_url : str , * parts ) -> str : Args base_url ( str ) Returns str","title":"join_url()"},{"location":"developer_reference/graphkb/__init__/#millis_interval","text":"start and end are datetime instances def millis_interval ( start : datetime , end : datetime ) -> int : Args start ( datetime ) end ( datetime ) Returns int","title":"millis_interval()"},{"location":"developer_reference/graphkb/__init__/#cache_key","text":"create a cache key for a query request to GraphKB def cache_key ( request_body ): Args request_body","title":"cache_key()"},{"location":"developer_reference/graphkb/genes/","text":"graphkb.genes \u00b6 Methods for retrieving gene annotation lists from GraphKB ONCOKB_SOURCE_NAME \u00b6 ONCOKB_SOURCE_NAME = 'oncokb' ONCOGENE \u00b6 ONCOGENE = 'oncogenic' TUMOUR_SUPPRESSIVE \u00b6 TUMOUR_SUPPRESSIVE = 'tumour suppressive' FUSION_NAMES \u00b6 FUSION_NAMES = [ 'structural variant' , 'fusion' ] GENE_RETURN_PROPERTIES \u00b6 GENE_RETURN_PROPERTIES = [ 'name' , '@rid' , '@class' , 'sourceId' , 'sourceIdVersion' , 'source.name' , 'source.@rid' , 'displayName' , 'biotype' , 'deprecated' , ] get_oncokb_oncogenes() \u00b6 Gets the list of oncogenes stored in GraphKB derived from OncoKB def get_oncokb_oncogenes ( conn : GraphKBConnection ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object Returns List[ Ontology ]: gene (Feature) records get_oncokb_tumour_supressors() \u00b6 Gets the list of tumour supressor genes stored in GraphKB derived from OncoKB def get_oncokb_tumour_supressors ( conn : GraphKBConnection ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object Returns List[ Ontology ]: gene (Feature) records get_genes_from_variant_types() \u00b6 Retrieve a list of Genes which are found in variants on the given types def get_genes_from_variant_types ( conn : GraphKBConnection , types : List [ str ], source_record_ids : List [ str ] = [], ignore_cache : bool = False , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object types ( List[str] ): list of names of variant types source_record_ids ( List[str] ): list of sources ids to filter genes by ignore_cache ( bool ) Returns List[ Ontology ]: gene (Feature) records","title":"graphkb.genes"},{"location":"developer_reference/graphkb/genes/#graphkbgenes","text":"Methods for retrieving gene annotation lists from GraphKB","title":"graphkb.genes"},{"location":"developer_reference/graphkb/genes/#oncokb_source_name","text":"ONCOKB_SOURCE_NAME = 'oncokb'","title":"ONCOKB_SOURCE_NAME"},{"location":"developer_reference/graphkb/genes/#oncogene","text":"ONCOGENE = 'oncogenic'","title":"ONCOGENE"},{"location":"developer_reference/graphkb/genes/#tumour_suppressive","text":"TUMOUR_SUPPRESSIVE = 'tumour suppressive'","title":"TUMOUR_SUPPRESSIVE"},{"location":"developer_reference/graphkb/genes/#fusion_names","text":"FUSION_NAMES = [ 'structural variant' , 'fusion' ]","title":"FUSION_NAMES"},{"location":"developer_reference/graphkb/genes/#gene_return_properties","text":"GENE_RETURN_PROPERTIES = [ 'name' , '@rid' , '@class' , 'sourceId' , 'sourceIdVersion' , 'source.name' , 'source.@rid' , 'displayName' , 'biotype' , 'deprecated' , ]","title":"GENE_RETURN_PROPERTIES"},{"location":"developer_reference/graphkb/genes/#get_oncokb_oncogenes","text":"Gets the list of oncogenes stored in GraphKB derived from OncoKB def get_oncokb_oncogenes ( conn : GraphKBConnection ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object Returns List[ Ontology ]: gene (Feature) records","title":"get_oncokb_oncogenes()"},{"location":"developer_reference/graphkb/genes/#get_oncokb_tumour_supressors","text":"Gets the list of tumour supressor genes stored in GraphKB derived from OncoKB def get_oncokb_tumour_supressors ( conn : GraphKBConnection ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object Returns List[ Ontology ]: gene (Feature) records","title":"get_oncokb_tumour_supressors()"},{"location":"developer_reference/graphkb/genes/#get_genes_from_variant_types","text":"Retrieve a list of Genes which are found in variants on the given types def get_genes_from_variant_types ( conn : GraphKBConnection , types : List [ str ], source_record_ids : List [ str ] = [], ignore_cache : bool = False , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object types ( List[str] ): list of names of variant types source_record_ids ( List[str] ): list of sources ids to filter genes by ignore_cache ( bool ) Returns List[ Ontology ]: gene (Feature) records","title":"get_genes_from_variant_types()"},{"location":"developer_reference/graphkb/match/","text":"graphkb.match \u00b6 Functions which return Variants from GraphKB which match some input variant definition INPUT_COPY_CATEGORIES \u00b6 INPUT_COPY_CATEGORIES = IterableNamespace ( AMP = 'amplification' , ANY_GAIN = 'copy gain' , ANY_LOSS = 'copy loss' , DEEP = 'deep deletion' , GAIN = 'low level copy gain' , LOSS = 'shallow deletion' , ) INPUT_EXPRESSION_CATEGORIES \u00b6 INPUT_EXPRESSION_CATEGORIES = IterableNamespace ( UP = 'increased expression' , DOWN = 'reduced expression' ) AMBIGUOUS_AA \u00b6 AMBIGUOUS_AA = [ 'x' , '?' , 'X' ] VARIANT_RETURN_PROPERTIES \u00b6 VARIANT_RETURN_PROPERTIES = ( BASE_RETURN_PROPERTIES + [ f 'type. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'reference1. { p } ' for p in GENE_RETURN_PROPERTIES ] + [ f 'reference2. { p } ' for p in GENE_RETURN_PROPERTIES ] + [ 'zygosity' , 'germline' , 'displayName' ] POS_VARIANT_RETURN_PROPERTIES \u00b6 POS_VARIANT_RETURN_PROPERTIES = VARIANT_RETURN_PROPERTIES + [ 'break1Start' , 'break1End' , 'break2Start' , 'break2End' , 'break1Repr' , 'break2Repr' , 'refSeq' , 'untemplatedSeq' , 'untemplatedSeqSize' , 'truncation' , 'assembly' , FEATURES_CACHE \u00b6 FEATURES_CACHE : Set [ str ] = set () get_equivalent_features() \u00b6 Match an equivalent list of features given some input feature name (or ID) def get_equivalent_features ( conn : GraphKBConnection , gene_name : str , ignore_cache : bool = False , is_source_id : bool = False , source : str = '' , source_id_version : str = '' , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ) gene_name ( str ): the gene name to search features by ignore_cache ( bool ): bypass the cache to always force a new request is_source_id ( bool ): treat the gene_name as the gene ID from the source database (ex. ENSG001) source ( str ): the name of the source database the gene definition is from (ex. ensembl) source_id_version ( str ): the version of the source_id Returns List[ Ontology ]: equivalent feature records Examples get_equivalent_features ( conn , 'KRAS' ) get_equivalent_features ( conn , 'ENSG001' , source = 'ensembl' , is_source_id = True ) get_equivalent_features ( conn , 'ENSG001' , source = 'ensembl' , source_id_version = '1' ) get_equivalent_features ( conn , '#3:44' ) cache_missing_features() \u00b6 Create a cache of features that exist to avoid repeatedly querying for missing features def cache_missing_features ( conn : GraphKBConnection ) -> None : Args conn ( GraphKBConnection ) match_category_variant() \u00b6 Returns a list of variants matching the input variant def match_category_variant ( conn : GraphKBConnection , gene_name : str , category : str , root_exclude_term : str = '' , gene_source : str = '' , gene_is_source_id : bool = False , ignore_cache : bool = False , ) -> List [ Variant ]: Args conn ( GraphKBConnection ): the graphkb connection object gene_name ( str ): the name of the gene the variant is in reference to category ( str ): the variant category (ex. copy loss) root_exclude_term ( str ) gene_source ( str ): The source database the gene is defined by (ex. ensembl) gene_is_source_id ( bool ): Indicates the gene name(s) input should be treated as sourceIds not names ignore_cache ( bool ) Returns List[ Variant ]: List of variant records from GraphKB which match the input Raises FeatureNotFoundError : The gene could not be found in GraphKB match_copy_variant() \u00b6 Returns a list of variants matching the input variant def match_copy_variant ( conn : GraphKBConnection , gene_name : str , category : str , drop_homozygous : bool = False , ** kwargs ) -> List [ Variant ]: Args conn ( GraphKBConnection ): the graphkb connection object gene_name ( str ): the name of the gene the variant is in reference to category ( str ): the variant category (ex. copy loss) drop_homozygous ( bool ): Drop homozygous matches from the result when true Returns List[ Variant ]: List of variant records from GraphKB which match the input Raises ValueError : The input copy category is not recognized positions_overlap() \u00b6 Check if 2 Position records from GraphKB indicate an overlap def positions_overlap ( pos_record : BasicPosition , range_start : BasicPosition , range_end : Optional [ BasicPosition ] = None ) -> bool : Args pos_record ( BasicPosition ): the record to compare range_start ( BasicPosition ): the position record indicating the start of an uncertainty range range_end (Optional[ BasicPosition ]): the position record indicating the end of an uncertainty range Returns bool : True if the positions overlap Raises NotImplementedError : if a cytoband type position is given Note null values indicate not-specified or any compare_positional_variants() \u00b6 Compare 2 variant records from GraphKB to determine if they are equivalent def compare_positional_variants ( variant : Union [ PositionalVariant , ParsedVariant ], reference_variant : Union [ PositionalVariant , ParsedVariant ], ) -> bool : Args variant (Union[ PositionalVariant , ParsedVariant ]): the input variant reference_variant (Union[ PositionalVariant , ParsedVariant ]): the reference (matched) variant record Returns bool : True if the records are equivalent match_positional_variant() \u00b6 Given the HGVS+ representation of some positional variant, parse it and match it to annotations in GraphKB def match_positional_variant ( conn : GraphKBConnection , variant_string : str , reference1 : Optional [ str ] = None , reference2 : Optional [ str ] = None , gene_is_source_id : bool = False , gene_source : str = '' , ignore_cache : bool = False , ) -> List [ Variant ]: Args conn ( GraphKBConnection ) variant_string ( str ): the HGVS+ annotation string reference1 ( Optional[str] ): Explicitly specify the first reference link record (gene1) reference2 ( Optional[str] ): Explicitly specify the second reference link record (gene2) gene_is_source_id ( bool ): Indicates the gene name(s) input should be treated as sourceIds not names gene_source ( str ): The source database the gene is defined by (ex. ensembl) ignore_cache ( bool ) Returns List[ Variant ]: A list of matched statement records Raises NotImplementedError : thrown for uncertain position input (ranges) FeatureNotFoundError : One of the genes does not exist in GraphKB ValueError : the gene names were given both in the variant_string and explicitly Examples match_positional_variant ( conn , '(EWSR1,FLI1):fusion(e.1,e.2)' ) match_positional_variant ( conn , 'fusion(e.1,e.2)' , 'EWSR1' , 'FLI1' ) match_positional_variant ( conn , 'fusion(e.1,e.2)' , '#3:4' , '#4:5' ) match_positional_variant ( conn , 'fusion(e.1,e.2)' , '123' , '456' , gene_is_source_id = True , gene_source = 'entrez gene' ) match_positional_variant ( conn , 'KRAS:p.G12D' ) match_positional_variant ( conn , 'p.G12D' , 'KRAS' )","title":"graphkb.match"},{"location":"developer_reference/graphkb/match/#graphkbmatch","text":"Functions which return Variants from GraphKB which match some input variant definition","title":"graphkb.match"},{"location":"developer_reference/graphkb/match/#input_copy_categories","text":"INPUT_COPY_CATEGORIES = IterableNamespace ( AMP = 'amplification' , ANY_GAIN = 'copy gain' , ANY_LOSS = 'copy loss' , DEEP = 'deep deletion' , GAIN = 'low level copy gain' , LOSS = 'shallow deletion' , )","title":"INPUT_COPY_CATEGORIES"},{"location":"developer_reference/graphkb/match/#input_expression_categories","text":"INPUT_EXPRESSION_CATEGORIES = IterableNamespace ( UP = 'increased expression' , DOWN = 'reduced expression' )","title":"INPUT_EXPRESSION_CATEGORIES"},{"location":"developer_reference/graphkb/match/#ambiguous_aa","text":"AMBIGUOUS_AA = [ 'x' , '?' , 'X' ]","title":"AMBIGUOUS_AA"},{"location":"developer_reference/graphkb/match/#variant_return_properties","text":"VARIANT_RETURN_PROPERTIES = ( BASE_RETURN_PROPERTIES + [ f 'type. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'reference1. { p } ' for p in GENE_RETURN_PROPERTIES ] + [ f 'reference2. { p } ' for p in GENE_RETURN_PROPERTIES ] + [ 'zygosity' , 'germline' , 'displayName' ]","title":"VARIANT_RETURN_PROPERTIES"},{"location":"developer_reference/graphkb/match/#pos_variant_return_properties","text":"POS_VARIANT_RETURN_PROPERTIES = VARIANT_RETURN_PROPERTIES + [ 'break1Start' , 'break1End' , 'break2Start' , 'break2End' , 'break1Repr' , 'break2Repr' , 'refSeq' , 'untemplatedSeq' , 'untemplatedSeqSize' , 'truncation' , 'assembly' ,","title":"POS_VARIANT_RETURN_PROPERTIES"},{"location":"developer_reference/graphkb/match/#features_cache","text":"FEATURES_CACHE : Set [ str ] = set ()","title":"FEATURES_CACHE"},{"location":"developer_reference/graphkb/match/#get_equivalent_features","text":"Match an equivalent list of features given some input feature name (or ID) def get_equivalent_features ( conn : GraphKBConnection , gene_name : str , ignore_cache : bool = False , is_source_id : bool = False , source : str = '' , source_id_version : str = '' , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ) gene_name ( str ): the gene name to search features by ignore_cache ( bool ): bypass the cache to always force a new request is_source_id ( bool ): treat the gene_name as the gene ID from the source database (ex. ENSG001) source ( str ): the name of the source database the gene definition is from (ex. ensembl) source_id_version ( str ): the version of the source_id Returns List[ Ontology ]: equivalent feature records Examples get_equivalent_features ( conn , 'KRAS' ) get_equivalent_features ( conn , 'ENSG001' , source = 'ensembl' , is_source_id = True ) get_equivalent_features ( conn , 'ENSG001' , source = 'ensembl' , source_id_version = '1' ) get_equivalent_features ( conn , '#3:44' )","title":"get_equivalent_features()"},{"location":"developer_reference/graphkb/match/#cache_missing_features","text":"Create a cache of features that exist to avoid repeatedly querying for missing features def cache_missing_features ( conn : GraphKBConnection ) -> None : Args conn ( GraphKBConnection )","title":"cache_missing_features()"},{"location":"developer_reference/graphkb/match/#match_category_variant","text":"Returns a list of variants matching the input variant def match_category_variant ( conn : GraphKBConnection , gene_name : str , category : str , root_exclude_term : str = '' , gene_source : str = '' , gene_is_source_id : bool = False , ignore_cache : bool = False , ) -> List [ Variant ]: Args conn ( GraphKBConnection ): the graphkb connection object gene_name ( str ): the name of the gene the variant is in reference to category ( str ): the variant category (ex. copy loss) root_exclude_term ( str ) gene_source ( str ): The source database the gene is defined by (ex. ensembl) gene_is_source_id ( bool ): Indicates the gene name(s) input should be treated as sourceIds not names ignore_cache ( bool ) Returns List[ Variant ]: List of variant records from GraphKB which match the input Raises FeatureNotFoundError : The gene could not be found in GraphKB","title":"match_category_variant()"},{"location":"developer_reference/graphkb/match/#match_copy_variant","text":"Returns a list of variants matching the input variant def match_copy_variant ( conn : GraphKBConnection , gene_name : str , category : str , drop_homozygous : bool = False , ** kwargs ) -> List [ Variant ]: Args conn ( GraphKBConnection ): the graphkb connection object gene_name ( str ): the name of the gene the variant is in reference to category ( str ): the variant category (ex. copy loss) drop_homozygous ( bool ): Drop homozygous matches from the result when true Returns List[ Variant ]: List of variant records from GraphKB which match the input Raises ValueError : The input copy category is not recognized","title":"match_copy_variant()"},{"location":"developer_reference/graphkb/match/#positions_overlap","text":"Check if 2 Position records from GraphKB indicate an overlap def positions_overlap ( pos_record : BasicPosition , range_start : BasicPosition , range_end : Optional [ BasicPosition ] = None ) -> bool : Args pos_record ( BasicPosition ): the record to compare range_start ( BasicPosition ): the position record indicating the start of an uncertainty range range_end (Optional[ BasicPosition ]): the position record indicating the end of an uncertainty range Returns bool : True if the positions overlap Raises NotImplementedError : if a cytoband type position is given Note null values indicate not-specified or any","title":"positions_overlap()"},{"location":"developer_reference/graphkb/match/#compare_positional_variants","text":"Compare 2 variant records from GraphKB to determine if they are equivalent def compare_positional_variants ( variant : Union [ PositionalVariant , ParsedVariant ], reference_variant : Union [ PositionalVariant , ParsedVariant ], ) -> bool : Args variant (Union[ PositionalVariant , ParsedVariant ]): the input variant reference_variant (Union[ PositionalVariant , ParsedVariant ]): the reference (matched) variant record Returns bool : True if the records are equivalent","title":"compare_positional_variants()"},{"location":"developer_reference/graphkb/match/#match_positional_variant","text":"Given the HGVS+ representation of some positional variant, parse it and match it to annotations in GraphKB def match_positional_variant ( conn : GraphKBConnection , variant_string : str , reference1 : Optional [ str ] = None , reference2 : Optional [ str ] = None , gene_is_source_id : bool = False , gene_source : str = '' , ignore_cache : bool = False , ) -> List [ Variant ]: Args conn ( GraphKBConnection ) variant_string ( str ): the HGVS+ annotation string reference1 ( Optional[str] ): Explicitly specify the first reference link record (gene1) reference2 ( Optional[str] ): Explicitly specify the second reference link record (gene2) gene_is_source_id ( bool ): Indicates the gene name(s) input should be treated as sourceIds not names gene_source ( str ): The source database the gene is defined by (ex. ensembl) ignore_cache ( bool ) Returns List[ Variant ]: A list of matched statement records Raises NotImplementedError : thrown for uncertain position input (ranges) FeatureNotFoundError : One of the genes does not exist in GraphKB ValueError : the gene names were given both in the variant_string and explicitly Examples match_positional_variant ( conn , '(EWSR1,FLI1):fusion(e.1,e.2)' ) match_positional_variant ( conn , 'fusion(e.1,e.2)' , 'EWSR1' , 'FLI1' ) match_positional_variant ( conn , 'fusion(e.1,e.2)' , '#3:4' , '#4:5' ) match_positional_variant ( conn , 'fusion(e.1,e.2)' , '123' , '456' , gene_is_source_id = True , gene_source = 'entrez gene' ) match_positional_variant ( conn , 'KRAS:p.G12D' ) match_positional_variant ( conn , 'p.G12D' , 'KRAS' )","title":"match_positional_variant()"},{"location":"developer_reference/graphkb/statement/","text":"graphkb.statement \u00b6 categorize_relevance() \u00b6 Given the record ID of some relevance term, return the higher level categorization def categorize_relevance ( graphkb_conn : GraphKBConnection , relevance_rid : str , category_base_terms : CategoryBaseTermMapping = RELEVANCE_BASE_TERMS , ) -> str : Args graphkb_conn ( GraphKBConnection ) relevance_rid ( str ) category_base_terms ( CategoryBaseTermMapping ) Returns str","title":"graphkb.statement"},{"location":"developer_reference/graphkb/statement/#graphkbstatement","text":"","title":"graphkb.statement"},{"location":"developer_reference/graphkb/statement/#categorize_relevance","text":"Given the record ID of some relevance term, return the higher level categorization def categorize_relevance ( graphkb_conn : GraphKBConnection , relevance_rid : str , category_base_terms : CategoryBaseTermMapping = RELEVANCE_BASE_TERMS , ) -> str : Args graphkb_conn ( GraphKBConnection ) relevance_rid ( str ) category_base_terms ( CategoryBaseTermMapping ) Returns str","title":"categorize_relevance()"},{"location":"developer_reference/graphkb/types/","text":"graphkb.types \u00b6 Type annotations used for static type checking in this module Record \u00b6 Record : TypedDict = TypedDict ( 'Record' , { '@rid' : str , '@class' : str }) Attributes @rid ( str ) @class ( str ) EmbeddedRecord \u00b6 EmbeddedRecord : TypedDict = TypedDict ( 'EmbeddedRecord' , { '@class' : str }) Attributes @class ( str ) RecordLink \u00b6 RecordLink = Union [ str , Record ] OntologyLink \u00b6 OntologyLink = Union [ str , Ontology ] Position \u00b6 Position = Union [ BasicPosition , CytobandPosition ] CategoryBaseTermMapping \u00b6 CategoryBaseTermMapping = List [ Tuple [ str , List [ str ]]] class Ontology \u00b6 inherits Record Attributes sourceId ( str ) name ( str ) source ( RecordLink ) displayName ( str ) class BasicPosition \u00b6 inherits EmbeddedRecord Attributes pos ( int ) class CytobandPosition \u00b6 inherits EmbeddedRecord Attributes arm ( str ) majorBand ( str ) minorBand ( str ) class Variant \u00b6 inherits Record Attributes reference1 ( OntologyLink ) reference2 (Optional[ OntologyLink ]) type ( OntologyLink ) zygosity ( str ) germline ( bool ) displayName ( str ) class PositionalVariant \u00b6 inherits Variant Attributes break1Start (Union[ Position , CytobandPosition ]) break1End (Optional[Union[ Position , CytobandPosition ]]) break2Start (Optional[Union[ Position , CytobandPosition ]]) break2End (Optional[Union[ Position , CytobandPosition ]]) refSeq ( Optional[str] ) untemplatedSeq ( Optional[str] ) untemplatedSeqSize ( Optional[int] ) class ParsedVariant \u00b6 inherits TypedDict Attributes reference1 ( str ) reference2 ( Optional[str] ) type ( str ) zygosity ( str ) germline ( bool ) break1Start (Union[ Position , CytobandPosition ]) break1End (Optional[Union[ Position , CytobandPosition ]]) break2Start (Optional[Union[ Position , CytobandPosition ]]) break2End (Optional[Union[ Position , CytobandPosition ]]) refSeq ( Optional[str] ) untemplatedSeq ( Optional[str] ) untemplatedSeqSize ( Optional[int] ) class Statement \u00b6 inherits Record Attributes relevance ( OntologyLink ) subject ( OntologyLink ) conditions (List[ OntologyLink ]) evidence (List[ OntologyLink ]) evidenceLevel (List[ OntologyLink ]) source ( RecordLink ) sourceId ( str )","title":"graphkb.types"},{"location":"developer_reference/graphkb/types/#graphkbtypes","text":"Type annotations used for static type checking in this module","title":"graphkb.types"},{"location":"developer_reference/graphkb/types/#record","text":"Record : TypedDict = TypedDict ( 'Record' , { '@rid' : str , '@class' : str }) Attributes @rid ( str ) @class ( str )","title":"Record"},{"location":"developer_reference/graphkb/types/#embeddedrecord","text":"EmbeddedRecord : TypedDict = TypedDict ( 'EmbeddedRecord' , { '@class' : str }) Attributes @class ( str )","title":"EmbeddedRecord"},{"location":"developer_reference/graphkb/types/#recordlink","text":"RecordLink = Union [ str , Record ]","title":"RecordLink"},{"location":"developer_reference/graphkb/types/#ontologylink","text":"OntologyLink = Union [ str , Ontology ]","title":"OntologyLink"},{"location":"developer_reference/graphkb/types/#position","text":"Position = Union [ BasicPosition , CytobandPosition ]","title":"Position"},{"location":"developer_reference/graphkb/types/#categorybasetermmapping","text":"CategoryBaseTermMapping = List [ Tuple [ str , List [ str ]]]","title":"CategoryBaseTermMapping"},{"location":"developer_reference/graphkb/types/#class-ontology","text":"inherits Record Attributes sourceId ( str ) name ( str ) source ( RecordLink ) displayName ( str )","title":"class Ontology"},{"location":"developer_reference/graphkb/types/#class-basicposition","text":"inherits EmbeddedRecord Attributes pos ( int )","title":"class BasicPosition"},{"location":"developer_reference/graphkb/types/#class-cytobandposition","text":"inherits EmbeddedRecord Attributes arm ( str ) majorBand ( str ) minorBand ( str )","title":"class CytobandPosition"},{"location":"developer_reference/graphkb/types/#class-variant","text":"inherits Record Attributes reference1 ( OntologyLink ) reference2 (Optional[ OntologyLink ]) type ( OntologyLink ) zygosity ( str ) germline ( bool ) displayName ( str )","title":"class Variant"},{"location":"developer_reference/graphkb/types/#class-positionalvariant","text":"inherits Variant Attributes break1Start (Union[ Position , CytobandPosition ]) break1End (Optional[Union[ Position , CytobandPosition ]]) break2Start (Optional[Union[ Position , CytobandPosition ]]) break2End (Optional[Union[ Position , CytobandPosition ]]) refSeq ( Optional[str] ) untemplatedSeq ( Optional[str] ) untemplatedSeqSize ( Optional[int] )","title":"class PositionalVariant"},{"location":"developer_reference/graphkb/types/#class-parsedvariant","text":"inherits TypedDict Attributes reference1 ( str ) reference2 ( Optional[str] ) type ( str ) zygosity ( str ) germline ( bool ) break1Start (Union[ Position , CytobandPosition ]) break1End (Optional[Union[ Position , CytobandPosition ]]) break2Start (Optional[Union[ Position , CytobandPosition ]]) break2End (Optional[Union[ Position , CytobandPosition ]]) refSeq ( Optional[str] ) untemplatedSeq ( Optional[str] ) untemplatedSeqSize ( Optional[int] )","title":"class ParsedVariant"},{"location":"developer_reference/graphkb/types/#class-statement","text":"inherits Record Attributes relevance ( OntologyLink ) subject ( OntologyLink ) conditions (List[ OntologyLink ]) evidence (List[ OntologyLink ]) evidenceLevel (List[ OntologyLink ]) source ( RecordLink ) sourceId ( str )","title":"class Statement"},{"location":"developer_reference/graphkb/util/","text":"graphkb.util \u00b6 VERBOSE_ERROR_CODE \u00b6 VERBOSE_ERROR_CODE = ( logging . INFO + logging . DEBUG ) // 2 logger \u00b6 logger = logging . getLogger ( 'graphkb' ) LOG_LEVELS \u00b6 LOG_LEVELS = { 'info' : logging . INFO , 'debug' : logging . DEBUG , 'warn' : logging . WARN , 'error' : logging . ERROR , 'verbose' : VERBOSE_ERROR_CODE , class IterableNamespace \u00b6 inherits argparse.Namespace convert_to_rid_list() \u00b6 Given a list of records, return their record IDs def convert_to_rid_list ( records : Iterable [ Record ]) -> List [ str ]: Args records (Iterable[ Record ]) Returns List[str] looks_like_rid() \u00b6 Check if an input string looks like a GraphKB ID def looks_like_rid ( rid : str ) -> bool : Args rid ( str ) Returns bool convert_aa_3to1() \u00b6 Convert an Input string from 3 letter AA notation to 1 letter AA notation def convert_aa_3to1 ( three_letter_notation : str ) -> str : Args three_letter_notation ( str ) Returns str","title":"graphkb.util"},{"location":"developer_reference/graphkb/util/#graphkbutil","text":"","title":"graphkb.util"},{"location":"developer_reference/graphkb/util/#verbose_error_code","text":"VERBOSE_ERROR_CODE = ( logging . INFO + logging . DEBUG ) // 2","title":"VERBOSE_ERROR_CODE"},{"location":"developer_reference/graphkb/util/#logger","text":"logger = logging . getLogger ( 'graphkb' )","title":"logger"},{"location":"developer_reference/graphkb/util/#log_levels","text":"LOG_LEVELS = { 'info' : logging . INFO , 'debug' : logging . DEBUG , 'warn' : logging . WARN , 'error' : logging . ERROR , 'verbose' : VERBOSE_ERROR_CODE ,","title":"LOG_LEVELS"},{"location":"developer_reference/graphkb/util/#class-iterablenamespace","text":"inherits argparse.Namespace","title":"class IterableNamespace"},{"location":"developer_reference/graphkb/util/#convert_to_rid_list","text":"Given a list of records, return their record IDs def convert_to_rid_list ( records : Iterable [ Record ]) -> List [ str ]: Args records (Iterable[ Record ]) Returns List[str]","title":"convert_to_rid_list()"},{"location":"developer_reference/graphkb/util/#looks_like_rid","text":"Check if an input string looks like a GraphKB ID def looks_like_rid ( rid : str ) -> bool : Args rid ( str ) Returns bool","title":"looks_like_rid()"},{"location":"developer_reference/graphkb/util/#convert_aa_3to1","text":"Convert an Input string from 3 letter AA notation to 1 letter AA notation def convert_aa_3to1 ( three_letter_notation : str ) -> str : Args three_letter_notation ( str ) Returns str","title":"convert_aa_3to1()"},{"location":"developer_reference/graphkb/vocab/","text":"graphkb.vocab \u00b6 get_equivalent_terms() \u00b6 Get a list of terms equivalent to the current term up to the root term def get_equivalent_terms ( conn : GraphKBConnection , base_term_name : str , root_exclude_term : str = '' , ontology_class : str = 'Vocabulary' , ignore_cache : bool = False , build_base_query : Callable = query_by_name , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ) base_term_name ( str ): the name to get superclasses of root_exclude_term ( str ): the parent term to exlcude along with all of its parent terms ontology_class ( str ) ignore_cache ( bool ) build_base_query ( Callable ) Returns List[ Ontology ] get_term_tree() \u00b6 Get terms equivalent to the base term by traversing the subclassOf tree and expanding related alias and cross reference edges def get_term_tree ( conn : GraphKBConnection , base_term_name : str , root_exclude_term : str = '' , ontology_class : str = 'Vocabulary' , include_superclasses : bool = True , ignore_cache : bool = False , build_base_query : Callable = query_by_name , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object base_term_name ( str ): the term to use as the base of the subclass tree root_exclude_term ( str ) ontology_class ( str ): the default class to query. Defaults to 'Vocabulary' include_superclasses ( bool ): when True the query will include superclasses of the current term ignore_cache ( bool ) build_base_query ( Callable ) Returns List[ Ontology ]: GraphKB records Note: this must be done in 2 calls to avoid going up and down the tree in a single query (exclude adjacent siblings) get_term_by_name() \u00b6 Retrieve a vocaulary term by name def get_term_by_name ( conn : GraphKBConnection , name : str , ontology_class : str = 'Vocabulary' , ignore_cache : bool = False , ** kwargs , ) -> Ontology : Args conn ( GraphKBConnection ): the graphkb connection object name ( str ): the name of the Vocabulary term to retrieve ontology_class ( str ) ignore_cache ( bool ) Returns Ontology : Vocabulary record Raises AssertionError : more than one term or no terms with that name were found AssertionError : if the term was not found or more than 1 match was found (expected to be unique) get_terms_set() \u00b6 Get a set of terms of vocabulary given some base/parent term names. Returns the record IDs for the resulting terms def get_terms_set ( graphkb_conn : GraphKBConnection , base_terms : Iterable [ str ], ignore_cache : bool = False ) -> Set [ str ]: Args graphkb_conn ( GraphKBConnection ) base_terms ( Iterable[str] ) ignore_cache ( bool ) Returns Set[str]","title":"graphkb.vocab"},{"location":"developer_reference/graphkb/vocab/#graphkbvocab","text":"","title":"graphkb.vocab"},{"location":"developer_reference/graphkb/vocab/#get_equivalent_terms","text":"Get a list of terms equivalent to the current term up to the root term def get_equivalent_terms ( conn : GraphKBConnection , base_term_name : str , root_exclude_term : str = '' , ontology_class : str = 'Vocabulary' , ignore_cache : bool = False , build_base_query : Callable = query_by_name , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ) base_term_name ( str ): the name to get superclasses of root_exclude_term ( str ): the parent term to exlcude along with all of its parent terms ontology_class ( str ) ignore_cache ( bool ) build_base_query ( Callable ) Returns List[ Ontology ]","title":"get_equivalent_terms()"},{"location":"developer_reference/graphkb/vocab/#get_term_tree","text":"Get terms equivalent to the base term by traversing the subclassOf tree and expanding related alias and cross reference edges def get_term_tree ( conn : GraphKBConnection , base_term_name : str , root_exclude_term : str = '' , ontology_class : str = 'Vocabulary' , include_superclasses : bool = True , ignore_cache : bool = False , build_base_query : Callable = query_by_name , ) -> List [ Ontology ]: Args conn ( GraphKBConnection ): the graphkb connection object base_term_name ( str ): the term to use as the base of the subclass tree root_exclude_term ( str ) ontology_class ( str ): the default class to query. Defaults to 'Vocabulary' include_superclasses ( bool ): when True the query will include superclasses of the current term ignore_cache ( bool ) build_base_query ( Callable ) Returns List[ Ontology ]: GraphKB records Note: this must be done in 2 calls to avoid going up and down the tree in a single query (exclude adjacent siblings)","title":"get_term_tree()"},{"location":"developer_reference/graphkb/vocab/#get_term_by_name","text":"Retrieve a vocaulary term by name def get_term_by_name ( conn : GraphKBConnection , name : str , ontology_class : str = 'Vocabulary' , ignore_cache : bool = False , ** kwargs , ) -> Ontology : Args conn ( GraphKBConnection ): the graphkb connection object name ( str ): the name of the Vocabulary term to retrieve ontology_class ( str ) ignore_cache ( bool ) Returns Ontology : Vocabulary record Raises AssertionError : more than one term or no terms with that name were found AssertionError : if the term was not found or more than 1 match was found (expected to be unique)","title":"get_term_by_name()"},{"location":"developer_reference/graphkb/vocab/#get_terms_set","text":"Get a set of terms of vocabulary given some base/parent term names. Returns the record IDs for the resulting terms def get_terms_set ( graphkb_conn : GraphKBConnection , base_terms : Iterable [ str ], ignore_cache : bool = False ) -> Set [ str ]: Args graphkb_conn ( GraphKBConnection ) base_terms ( Iterable[str] ) ignore_cache ( bool ) Returns Set[str]","title":"get_terms_set()"},{"location":"developer_reference/ipr/annotate/","text":"ipr.annotate \u00b6 handles annotating variants with annotation information from graphkb get_gene_information() \u00b6 Create the Gene Info object for upload to IPR with the other report information def get_gene_information ( graphkb_conn : GraphKBConnection , gene_names : Iterable [ str ] ) -> List [ IprGene ]: Args graphkb_conn ( GraphKBConnection ): [description] gene_names ( Iterable[str] ): [description] Returns List[ IprGene ] get_statements_from_variants() \u00b6 Given a list of variant records from GraphKB, return all the related statements def get_statements_from_variants ( graphkb_conn : GraphKBConnection , variants : List [ Record ] ) -> List [ Statement ]: Args graphkb_conn ( GraphKBConnection ): the graphkb api connection object variants ( List[Record] ): list of variant records Returns List[Statement] : list of Statement records from graphkb get_second_pass_variants() \u00b6 Given a list of statements that have been matched. Convert these to new category variants to be used in a second-pass matching def get_second_pass_variants ( graphkb_conn : GraphKBConnection , statements : List [ Statement ] ) -> List [ Variant ]: Args graphkb_conn ( GraphKBConnection ) statements ( List[Statement] ) Returns List[Variant] get_ipr_statements_from_variants() \u00b6 Matches to GraphKB statements from the list of input variants. From these results matches again with the inferred variants. Then returns the results formatted for upload to IPR def get_ipr_statements_from_variants ( graphkb_conn : GraphKBConnection , matches : List [ Record ], disease_name : str ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ) matches ( List[Record] ) disease_name ( str ) Returns List[ KbMatch ] annotate_category_variants() \u00b6 Annotate variant calls with information from GraphKB and return these annotations in the IPR alterations format def annotate_category_variants ( graphkb_conn : GraphKBConnection , variants : List [ IprGeneVariant ], disease_name : str , copy_variant : bool = True , show_progress : bool = False , ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ): the graphkb api connection object variants (List[ IprGeneVariant ]): list of variants disease_name ( str ) copy_variant ( bool ) show_progress ( bool ) Returns List[ KbMatch ]: list of kbMatches records for IPR annotate_positional_variants() \u00b6 Annotate variant calls with information from GraphKB and return these annotations in the IPR alterations format def annotate_positional_variants ( graphkb_conn : GraphKBConnection , variants : List [ IprVariant ], disease_name : str , show_progress : bool = False , ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ): the graphkb api connection object variants (List[ IprVariant ]): list of variants. Defaults to []. disease_name ( str ) show_progress ( bool ) Returns List[ KbMatch ]: list of kbMatches records for IPR","title":"ipr.annotate"},{"location":"developer_reference/ipr/annotate/#iprannotate","text":"handles annotating variants with annotation information from graphkb","title":"ipr.annotate"},{"location":"developer_reference/ipr/annotate/#get_gene_information","text":"Create the Gene Info object for upload to IPR with the other report information def get_gene_information ( graphkb_conn : GraphKBConnection , gene_names : Iterable [ str ] ) -> List [ IprGene ]: Args graphkb_conn ( GraphKBConnection ): [description] gene_names ( Iterable[str] ): [description] Returns List[ IprGene ]","title":"get_gene_information()"},{"location":"developer_reference/ipr/annotate/#get_statements_from_variants","text":"Given a list of variant records from GraphKB, return all the related statements def get_statements_from_variants ( graphkb_conn : GraphKBConnection , variants : List [ Record ] ) -> List [ Statement ]: Args graphkb_conn ( GraphKBConnection ): the graphkb api connection object variants ( List[Record] ): list of variant records Returns List[Statement] : list of Statement records from graphkb","title":"get_statements_from_variants()"},{"location":"developer_reference/ipr/annotate/#get_second_pass_variants","text":"Given a list of statements that have been matched. Convert these to new category variants to be used in a second-pass matching def get_second_pass_variants ( graphkb_conn : GraphKBConnection , statements : List [ Statement ] ) -> List [ Variant ]: Args graphkb_conn ( GraphKBConnection ) statements ( List[Statement] ) Returns List[Variant]","title":"get_second_pass_variants()"},{"location":"developer_reference/ipr/annotate/#get_ipr_statements_from_variants","text":"Matches to GraphKB statements from the list of input variants. From these results matches again with the inferred variants. Then returns the results formatted for upload to IPR def get_ipr_statements_from_variants ( graphkb_conn : GraphKBConnection , matches : List [ Record ], disease_name : str ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ) matches ( List[Record] ) disease_name ( str ) Returns List[ KbMatch ]","title":"get_ipr_statements_from_variants()"},{"location":"developer_reference/ipr/annotate/#annotate_category_variants","text":"Annotate variant calls with information from GraphKB and return these annotations in the IPR alterations format def annotate_category_variants ( graphkb_conn : GraphKBConnection , variants : List [ IprGeneVariant ], disease_name : str , copy_variant : bool = True , show_progress : bool = False , ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ): the graphkb api connection object variants (List[ IprGeneVariant ]): list of variants disease_name ( str ) copy_variant ( bool ) show_progress ( bool ) Returns List[ KbMatch ]: list of kbMatches records for IPR","title":"annotate_category_variants()"},{"location":"developer_reference/ipr/annotate/#annotate_positional_variants","text":"Annotate variant calls with information from GraphKB and return these annotations in the IPR alterations format def annotate_positional_variants ( graphkb_conn : GraphKBConnection , variants : List [ IprVariant ], disease_name : str , show_progress : bool = False , ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ): the graphkb api connection object variants (List[ IprVariant ]): list of variants. Defaults to []. disease_name ( str ) show_progress ( bool ) Returns List[ KbMatch ]: list of kbMatches records for IPR","title":"annotate_positional_variants()"},{"location":"developer_reference/ipr/connection/","text":"ipr.connection \u00b6 IMAGE_MAX \u00b6 IMAGE_MAX = 20 # cannot upload more than 20 images at a time class IprConnection \u00b6 IprConnection.request() \u00b6 Request wrapper to handle adding common headers and logging def request ( self , endpoint : str , method : str = 'GET' , ** kwargs ) -> Dict : Args endpoint ( str ): api endpoint, excluding the base uri method ( str ): the http method. Defaults to 'GET'. Returns Dict : the json response as a python dict IprConnection.post() \u00b6 Convenience method for making post requests def post ( self , uri : str , data : Dict = {}, ** kwargs ) -> Dict : Args uri ( str ) data ( Dict ) Returns Dict IprConnection.set_analyst_comments() \u00b6 Update report comments to an existing report def set_analyst_comments ( self , report_id : str , data : Dict ) -> Dict : Args report_id ( str ) data ( Dict ) Returns Dict Todo Add to main upload. Pending: https://www.bcgsc.ca/jira/browse/DEVSU-1177 IprConnection.post_images() \u00b6 Post images to the report def post_images ( self , report_id : str , files : Dict [ str , str ], data : Dict [ str , str ] = {}) -> None : Args report_id ( str ) files ( Dict[str, str] ) data ( Dict[str, str] )","title":"ipr.connection"},{"location":"developer_reference/ipr/connection/#iprconnection","text":"","title":"ipr.connection"},{"location":"developer_reference/ipr/connection/#image_max","text":"IMAGE_MAX = 20 # cannot upload more than 20 images at a time","title":"IMAGE_MAX"},{"location":"developer_reference/ipr/connection/#class-iprconnection","text":"","title":"class IprConnection"},{"location":"developer_reference/ipr/connection/#iprconnectionrequest","text":"Request wrapper to handle adding common headers and logging def request ( self , endpoint : str , method : str = 'GET' , ** kwargs ) -> Dict : Args endpoint ( str ): api endpoint, excluding the base uri method ( str ): the http method. Defaults to 'GET'. Returns Dict : the json response as a python dict","title":"IprConnection.request()"},{"location":"developer_reference/ipr/connection/#iprconnectionpost","text":"Convenience method for making post requests def post ( self , uri : str , data : Dict = {}, ** kwargs ) -> Dict : Args uri ( str ) data ( Dict ) Returns Dict","title":"IprConnection.post()"},{"location":"developer_reference/ipr/connection/#iprconnectionset_analyst_comments","text":"Update report comments to an existing report def set_analyst_comments ( self , report_id : str , data : Dict ) -> Dict : Args report_id ( str ) data ( Dict ) Returns Dict Todo Add to main upload. Pending: https://www.bcgsc.ca/jira/browse/DEVSU-1177","title":"IprConnection.set_analyst_comments()"},{"location":"developer_reference/ipr/connection/#iprconnectionpost_images","text":"Post images to the report def post_images ( self , report_id : str , files : Dict [ str , str ], data : Dict [ str , str ] = {}) -> None : Args report_id ( str ) files ( Dict[str, str] ) data ( Dict[str, str] )","title":"IprConnection.post_images()"},{"location":"developer_reference/ipr/inputs/","text":"ipr.inputs \u00b6 Read/Validate the variant input files SPECIFICATION \u00b6 SPECIFICATION = os . path . join ( os . path . dirname ( __file__ ), 'content.spec.json' ) COPY_REQ \u00b6 COPY_REQ = [ 'gene' , 'kbCategory' ] COPY_KEY \u00b6 COPY_KEY = [ 'gene' ] COPY_OPTIONAL \u00b6 COPY_OPTIONAL = [ 'cnvState' , 'copyChange' , 'lohState' , # Loss of Heterzygosity state - informative detail to analyst 'chromosomeBand' , 'start' , 'end' , 'size' , 'log2Cna' , 'cna' , ] SMALL_MUT_REQ \u00b6 SMALL_MUT_REQ = [ 'gene' , 'proteinChange' ] SMALL_MUT_KEY \u00b6 SMALL_MUT_KEY = SMALL_MUT_REQ + [ 'altSeq' , 'chromosome' , 'endPosition' , 'refSeq' , 'startPosition' , 'transcript' , SMALL_MUT_OPTIONAL \u00b6 SMALL_MUT_OPTIONAL = [ 'altSeq' , 'chromosome' , 'endPosition' , 'germline' , 'hgvsCds' , 'hgvsGenomic' , 'hgvsProtein' , 'ncbiBuild' , 'normalAltCount' , 'normalDepth' , 'normalRefCount' , 'refSeq' , 'rnaAltCount' , 'rnaDepth' , 'rnaRefCount' , 'startPosition' , 'transcript' , 'tumourAltCount' , 'tumourDepth' , 'tumourRefCount' , 'zygosity' , ] EXP_REQ \u00b6 EXP_REQ = [ 'gene' , 'kbCategory' ] EXP_KEY \u00b6 EXP_KEY = [ 'gene' ] EXP_OPTIONAL \u00b6 EXP_OPTIONAL = [ 'biopsySiteFoldChange' , 'biopsySitePercentile' , 'biopsySiteQC' , 'biopsySiteZScore' , 'biopsySitekIQR' , 'diseaseFoldChange' , 'diseasekIQR' , 'diseasePercentile' , 'diseaseQC' , 'diseaseZScore' , 'expressionState' , 'histogramImage' , 'primarySiteFoldChange' , 'primarySitekIQR' , 'primarySitePercentile' , 'primarySiteQC' , 'primarySiteZScore' , 'rnaReads' , 'rpkm' , 'tpm' , ] SV_REQ \u00b6 SV_REQ = [ 'eventType' , 'breakpoint' , 'gene1' , # prev: nterm_hugo 'gene2' , # prev: cterm_hugo 'exon1' , # n-terminal 'exon2' , # c-terminal ] SV_KEY \u00b6 SV_KEY = SV_REQ [:] SV_OPTIONAL \u00b6 SV_OPTIONAL = [ 'ctermTranscript' , 'ntermTranscript' , 'ctermGene' , # combined hugo ensembl form 'ntermGene' , # combined hugo ensembl form 'detectedIn' , 'conventionalName' , 'svg' , 'svgTitle' , 'name' , 'frame' , 'omicSupport' , 'highQuality' , ] DefaultValidatingDraft7Validator \u00b6 DefaultValidatingDraft7Validator = extend_with_default ( jsonschema . Draft7Validator ) validate_variant_rows() \u00b6 check that the required columns are present check that a unique key can be formed for each row drop any non-defined columns def validate_variant_rows ( rows : Iterable [ Dict ], required : List [ str ], optional : List [ str ], row_to_key : Callable ) -> List [ IprVariant ]: Args rows ( Iterable[Dict] ): the input files rows required ( List[str] ) optional ( List[str] ): list of optional column names row_to_key ( Callable ): function to generate a key for a given row Returns List[ IprVariant ]: the rows from the tab file as dictionaries Raises ValueError : row keys are not unique ValueError : A required column is missing preprocess_copy_variants() \u00b6 Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_copy_variants ( rows : Iterable [ Dict ]) -> List [ IprVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprVariant ] preprocess_small_mutations() \u00b6 Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_small_mutations ( rows : Iterable [ Dict ]) -> List [ IprGeneVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprGeneVariant ] preprocess_expression_variants() \u00b6 Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_expression_variants ( rows : Iterable [ Dict ]) -> List [ IprGeneVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprGeneVariant ] create_graphkb_sv_notation() \u00b6 Generate GKB style structural variant notation from a structural variant input row def create_graphkb_sv_notation ( row : IprStructuralVariant ) -> str : Args row ( IprStructuralVariant ) Returns str preprocess_structural_variants() \u00b6 Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_structural_variants ( rows : Iterable [ Dict ]) -> List [ IprVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprVariant ] check_variant_links() \u00b6 Check matching information for any genes with variants. Warn about genes with only one experimental measure. def check_variant_links ( small_mutations : List [ IprGeneVariant ], expression_variants : List [ IprGeneVariant ], copy_variants : List [ IprGeneVariant ], structural_variants : List [ IprStructuralVariant ], ) -> Set [ str ]: Args small_mutations (List[ IprGeneVariant ]): list of small mutations expression_variants (List[ IprGeneVariant ]): list of expression variants copy_variants (List[ IprGeneVariant ]): list of copy variants structural_variants (List[ IprStructuralVariant ]): list of structural variants Returns Set[str] : set of gene names with variants (used for filtering before upload to IPR) check_comparators() \u00b6 Given the optional content dictionary, check that based on the analyses present the correct/sufficient comparators have also been specified def check_comparators ( content : Dict , expresssionVariants : Iterable [ Dict ] = []) -> None : Args content ( Dict ) expresssionVariants ( Iterable[Dict] ) validate_report_content() \u00b6 Validate a report content input JSON object against the schema specification Adds defaults as reccommended by: https://python-jsonschema.readthedocs.io/en/latest/faq/#why-doesn-t-my-schema-s-default-property-set-the-default-on-my-instance def validate_report_content ( content : Dict , schema_file : str = SPECIFICATION ) -> None : Args content ( Dict ) schema_file ( str )","title":"ipr.inputs"},{"location":"developer_reference/ipr/inputs/#iprinputs","text":"Read/Validate the variant input files","title":"ipr.inputs"},{"location":"developer_reference/ipr/inputs/#specification","text":"SPECIFICATION = os . path . join ( os . path . dirname ( __file__ ), 'content.spec.json' )","title":"SPECIFICATION"},{"location":"developer_reference/ipr/inputs/#copy_req","text":"COPY_REQ = [ 'gene' , 'kbCategory' ]","title":"COPY_REQ"},{"location":"developer_reference/ipr/inputs/#copy_key","text":"COPY_KEY = [ 'gene' ]","title":"COPY_KEY"},{"location":"developer_reference/ipr/inputs/#copy_optional","text":"COPY_OPTIONAL = [ 'cnvState' , 'copyChange' , 'lohState' , # Loss of Heterzygosity state - informative detail to analyst 'chromosomeBand' , 'start' , 'end' , 'size' , 'log2Cna' , 'cna' , ]","title":"COPY_OPTIONAL"},{"location":"developer_reference/ipr/inputs/#small_mut_req","text":"SMALL_MUT_REQ = [ 'gene' , 'proteinChange' ]","title":"SMALL_MUT_REQ"},{"location":"developer_reference/ipr/inputs/#small_mut_key","text":"SMALL_MUT_KEY = SMALL_MUT_REQ + [ 'altSeq' , 'chromosome' , 'endPosition' , 'refSeq' , 'startPosition' , 'transcript' ,","title":"SMALL_MUT_KEY"},{"location":"developer_reference/ipr/inputs/#small_mut_optional","text":"SMALL_MUT_OPTIONAL = [ 'altSeq' , 'chromosome' , 'endPosition' , 'germline' , 'hgvsCds' , 'hgvsGenomic' , 'hgvsProtein' , 'ncbiBuild' , 'normalAltCount' , 'normalDepth' , 'normalRefCount' , 'refSeq' , 'rnaAltCount' , 'rnaDepth' , 'rnaRefCount' , 'startPosition' , 'transcript' , 'tumourAltCount' , 'tumourDepth' , 'tumourRefCount' , 'zygosity' , ]","title":"SMALL_MUT_OPTIONAL"},{"location":"developer_reference/ipr/inputs/#exp_req","text":"EXP_REQ = [ 'gene' , 'kbCategory' ]","title":"EXP_REQ"},{"location":"developer_reference/ipr/inputs/#exp_key","text":"EXP_KEY = [ 'gene' ]","title":"EXP_KEY"},{"location":"developer_reference/ipr/inputs/#exp_optional","text":"EXP_OPTIONAL = [ 'biopsySiteFoldChange' , 'biopsySitePercentile' , 'biopsySiteQC' , 'biopsySiteZScore' , 'biopsySitekIQR' , 'diseaseFoldChange' , 'diseasekIQR' , 'diseasePercentile' , 'diseaseQC' , 'diseaseZScore' , 'expressionState' , 'histogramImage' , 'primarySiteFoldChange' , 'primarySitekIQR' , 'primarySitePercentile' , 'primarySiteQC' , 'primarySiteZScore' , 'rnaReads' , 'rpkm' , 'tpm' , ]","title":"EXP_OPTIONAL"},{"location":"developer_reference/ipr/inputs/#sv_req","text":"SV_REQ = [ 'eventType' , 'breakpoint' , 'gene1' , # prev: nterm_hugo 'gene2' , # prev: cterm_hugo 'exon1' , # n-terminal 'exon2' , # c-terminal ]","title":"SV_REQ"},{"location":"developer_reference/ipr/inputs/#sv_key","text":"SV_KEY = SV_REQ [:]","title":"SV_KEY"},{"location":"developer_reference/ipr/inputs/#sv_optional","text":"SV_OPTIONAL = [ 'ctermTranscript' , 'ntermTranscript' , 'ctermGene' , # combined hugo ensembl form 'ntermGene' , # combined hugo ensembl form 'detectedIn' , 'conventionalName' , 'svg' , 'svgTitle' , 'name' , 'frame' , 'omicSupport' , 'highQuality' , ]","title":"SV_OPTIONAL"},{"location":"developer_reference/ipr/inputs/#defaultvalidatingdraft7validator","text":"DefaultValidatingDraft7Validator = extend_with_default ( jsonschema . Draft7Validator )","title":"DefaultValidatingDraft7Validator"},{"location":"developer_reference/ipr/inputs/#validate_variant_rows","text":"check that the required columns are present check that a unique key can be formed for each row drop any non-defined columns def validate_variant_rows ( rows : Iterable [ Dict ], required : List [ str ], optional : List [ str ], row_to_key : Callable ) -> List [ IprVariant ]: Args rows ( Iterable[Dict] ): the input files rows required ( List[str] ) optional ( List[str] ): list of optional column names row_to_key ( Callable ): function to generate a key for a given row Returns List[ IprVariant ]: the rows from the tab file as dictionaries Raises ValueError : row keys are not unique ValueError : A required column is missing","title":"validate_variant_rows()"},{"location":"developer_reference/ipr/inputs/#preprocess_copy_variants","text":"Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_copy_variants ( rows : Iterable [ Dict ]) -> List [ IprVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprVariant ]","title":"preprocess_copy_variants()"},{"location":"developer_reference/ipr/inputs/#preprocess_small_mutations","text":"Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_small_mutations ( rows : Iterable [ Dict ]) -> List [ IprGeneVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprGeneVariant ]","title":"preprocess_small_mutations()"},{"location":"developer_reference/ipr/inputs/#preprocess_expression_variants","text":"Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_expression_variants ( rows : Iterable [ Dict ]) -> List [ IprGeneVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprGeneVariant ]","title":"preprocess_expression_variants()"},{"location":"developer_reference/ipr/inputs/#create_graphkb_sv_notation","text":"Generate GKB style structural variant notation from a structural variant input row def create_graphkb_sv_notation ( row : IprStructuralVariant ) -> str : Args row ( IprStructuralVariant ) Returns str","title":"create_graphkb_sv_notation()"},{"location":"developer_reference/ipr/inputs/#preprocess_structural_variants","text":"Validate the input rows contain the minimum required fields and generate any default values where possible def preprocess_structural_variants ( rows : Iterable [ Dict ]) -> List [ IprVariant ]: Args rows ( Iterable[Dict] ) Returns List[ IprVariant ]","title":"preprocess_structural_variants()"},{"location":"developer_reference/ipr/inputs/#check_variant_links","text":"Check matching information for any genes with variants. Warn about genes with only one experimental measure. def check_variant_links ( small_mutations : List [ IprGeneVariant ], expression_variants : List [ IprGeneVariant ], copy_variants : List [ IprGeneVariant ], structural_variants : List [ IprStructuralVariant ], ) -> Set [ str ]: Args small_mutations (List[ IprGeneVariant ]): list of small mutations expression_variants (List[ IprGeneVariant ]): list of expression variants copy_variants (List[ IprGeneVariant ]): list of copy variants structural_variants (List[ IprStructuralVariant ]): list of structural variants Returns Set[str] : set of gene names with variants (used for filtering before upload to IPR)","title":"check_variant_links()"},{"location":"developer_reference/ipr/inputs/#check_comparators","text":"Given the optional content dictionary, check that based on the analyses present the correct/sufficient comparators have also been specified def check_comparators ( content : Dict , expresssionVariants : Iterable [ Dict ] = []) -> None : Args content ( Dict ) expresssionVariants ( Iterable[Dict] )","title":"check_comparators()"},{"location":"developer_reference/ipr/inputs/#validate_report_content","text":"Validate a report content input JSON object against the schema specification Adds defaults as reccommended by: https://python-jsonschema.readthedocs.io/en/latest/faq/#why-doesn-t-my-schema-s-default-property-set-the-default-on-my-instance def validate_report_content ( content : Dict , schema_file : str = SPECIFICATION ) -> None : Args content ( Dict ) schema_file ( str )","title":"validate_report_content()"},{"location":"developer_reference/ipr/ipr/","text":"ipr.ipr \u00b6 Contains functions specific to formatting reports for IPR that are unlikely to be used by other reporting systems filter_structural_variants() \u00b6 Filter structural variants to remove non-high quality events unless they are matched/annotated or they involve a gene that is a known fusion partner def filter_structural_variants ( structural_variants : List [ IprStructuralVariant ], kb_matches : List [ KbMatch ], gene_annotations : List [ IprGene ], ) -> List [ IprStructuralVariant ]: Args structural_variants (List[ IprStructuralVariant ]) kb_matches (List[ KbMatch ]) gene_annotations (List[ IprGene ]) Returns List[ IprStructuralVariant ] convert_statements_to_alterations() \u00b6 Given a set of statements matched from graphkb, convert these into their IPR equivalent representations def convert_statements_to_alterations ( graphkb_conn : GraphKBConnection , statements : List [ Statement ], disease_name : str , variant_matches : Iterable [ str ], ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ): the graphkb connection object statements ( List[Statement] ): list of statement records from graphkb disease_name ( str ): name of the cancer type for the patient being reported on variant_matches ( Iterable[str] ): the list of RIDs the variant matched for these statements Returns List[ KbMatch ]: IPR graphkb row representations Notes: - only report disease matched prognostic markers https://www.bcgsc.ca/jira/browse/GERO-72 and GERO-196 Raises ValueError : could not find the disease type in GraphKB select_expression_plots() \u00b6 Given the list of expression variants, determine which expression historgram plots should be included in the IPR upload. This filters them based on the graphkb annotations to avoid loading more images than are required def select_expression_plots ( kb_matches : List [ KbMatch ], all_variants : List [ IprVariant ] ) -> List [ Dict [ str , ImageDefinition ]]: Args kb_matches (List[ KbMatch ]): the IPR graphkb annoations for all variants all_variants (List[ IprVariant ]) Returns List[Dict[ str , ImageDefinition ]]: list of expression images to be loaded by IPR create_key_alterations() \u00b6 Creates the list of genomic key alterations which summarizes all the variants matched by the KB This list of matches is also used to create the variant counts def create_key_alterations ( kb_matches : List [ KbMatch ], all_variants : List [ IprVariant ], ) -> Tuple [ List [ Dict ], Dict ]: Args kb_matches (List[ KbMatch ]) all_variants (List[ IprVariant ]) Returns Tuple[List[Dict], Dict]","title":"ipr.ipr"},{"location":"developer_reference/ipr/ipr/#ipripr","text":"Contains functions specific to formatting reports for IPR that are unlikely to be used by other reporting systems","title":"ipr.ipr"},{"location":"developer_reference/ipr/ipr/#filter_structural_variants","text":"Filter structural variants to remove non-high quality events unless they are matched/annotated or they involve a gene that is a known fusion partner def filter_structural_variants ( structural_variants : List [ IprStructuralVariant ], kb_matches : List [ KbMatch ], gene_annotations : List [ IprGene ], ) -> List [ IprStructuralVariant ]: Args structural_variants (List[ IprStructuralVariant ]) kb_matches (List[ KbMatch ]) gene_annotations (List[ IprGene ]) Returns List[ IprStructuralVariant ]","title":"filter_structural_variants()"},{"location":"developer_reference/ipr/ipr/#convert_statements_to_alterations","text":"Given a set of statements matched from graphkb, convert these into their IPR equivalent representations def convert_statements_to_alterations ( graphkb_conn : GraphKBConnection , statements : List [ Statement ], disease_name : str , variant_matches : Iterable [ str ], ) -> List [ KbMatch ]: Args graphkb_conn ( GraphKBConnection ): the graphkb connection object statements ( List[Statement] ): list of statement records from graphkb disease_name ( str ): name of the cancer type for the patient being reported on variant_matches ( Iterable[str] ): the list of RIDs the variant matched for these statements Returns List[ KbMatch ]: IPR graphkb row representations Notes: - only report disease matched prognostic markers https://www.bcgsc.ca/jira/browse/GERO-72 and GERO-196 Raises ValueError : could not find the disease type in GraphKB","title":"convert_statements_to_alterations()"},{"location":"developer_reference/ipr/ipr/#select_expression_plots","text":"Given the list of expression variants, determine which expression historgram plots should be included in the IPR upload. This filters them based on the graphkb annotations to avoid loading more images than are required def select_expression_plots ( kb_matches : List [ KbMatch ], all_variants : List [ IprVariant ] ) -> List [ Dict [ str , ImageDefinition ]]: Args kb_matches (List[ KbMatch ]): the IPR graphkb annoations for all variants all_variants (List[ IprVariant ]) Returns List[Dict[ str , ImageDefinition ]]: list of expression images to be loaded by IPR","title":"select_expression_plots()"},{"location":"developer_reference/ipr/ipr/#create_key_alterations","text":"Creates the list of genomic key alterations which summarizes all the variants matched by the KB This list of matches is also used to create the variant counts def create_key_alterations ( kb_matches : List [ KbMatch ], all_variants : List [ IprVariant ], ) -> Tuple [ List [ Dict ], Dict ]: Args kb_matches (List[ KbMatch ]) all_variants (List[ IprVariant ]) Returns Tuple[List[Dict], Dict]","title":"create_key_alterations()"},{"location":"developer_reference/ipr/main/","text":"ipr.main \u00b6 CACHE_GENE_MINIMUM \u00b6 CACHE_GENE_MINIMUM = 5000 clean_unsupported_content() \u00b6 Remove unsupported content. This content is either added to facilitate creation or to support upcoming and soon to be supported content that we would like to implement but is not yet supported by the upload def clean_unsupported_content ( upload_content : Dict ) -> Dict : Args upload_content ( Dict ) Returns Dict create_report() \u00b6 Run the matching and create the report JSON for upload to IPR def create_report ( username : str , password : str , content : Dict , ipr_url : str = DEFAULT_URL , log_level : str = 'info' , output_json_path : str = None , always_write_output_json : bool = False , ipr_upload : bool = True , interactive : bool = False , graphkb_url : str = '' , generate_therapeutics : bool = False , generate_comments : bool = True , ) -> Dict : Args username ( str ): the username for connecting to GraphKB and IPR password ( str ): the password for connecting to GraphKB and IPR content ( Dict ): report content ipr_url ( str ): base URL to use in connecting to IPR log_level ( str ): the logging level output_json_path ( str ): path to a JSON file to output the report upload body. always_write_output_json ( bool ): with successful IPR upload ipr_upload ( bool ): upload report to ipr interactive ( bool ): progressbars for interactive users graphkb_url ( str ) generate_therapeutics ( bool ): create therapeutic options for upload with the report generate_comments ( bool ): create the analyst comments section for upload with the report Returns Dict : ipr_conn.upload_report return dictionary","title":"ipr.main"},{"location":"developer_reference/ipr/main/#iprmain","text":"","title":"ipr.main"},{"location":"developer_reference/ipr/main/#cache_gene_minimum","text":"CACHE_GENE_MINIMUM = 5000","title":"CACHE_GENE_MINIMUM"},{"location":"developer_reference/ipr/main/#clean_unsupported_content","text":"Remove unsupported content. This content is either added to facilitate creation or to support upcoming and soon to be supported content that we would like to implement but is not yet supported by the upload def clean_unsupported_content ( upload_content : Dict ) -> Dict : Args upload_content ( Dict ) Returns Dict","title":"clean_unsupported_content()"},{"location":"developer_reference/ipr/main/#create_report","text":"Run the matching and create the report JSON for upload to IPR def create_report ( username : str , password : str , content : Dict , ipr_url : str = DEFAULT_URL , log_level : str = 'info' , output_json_path : str = None , always_write_output_json : bool = False , ipr_upload : bool = True , interactive : bool = False , graphkb_url : str = '' , generate_therapeutics : bool = False , generate_comments : bool = True , ) -> Dict : Args username ( str ): the username for connecting to GraphKB and IPR password ( str ): the password for connecting to GraphKB and IPR content ( Dict ): report content ipr_url ( str ): base URL to use in connecting to IPR log_level ( str ): the logging level output_json_path ( str ): path to a JSON file to output the report upload body. always_write_output_json ( bool ): with successful IPR upload ipr_upload ( bool ): upload report to ipr interactive ( bool ): progressbars for interactive users graphkb_url ( str ) generate_therapeutics ( bool ): create therapeutic options for upload with the report generate_comments ( bool ): create the analyst comments section for upload with the report Returns Dict : ipr_conn.upload_report return dictionary","title":"create_report()"},{"location":"developer_reference/ipr/summary/","text":"ipr.summary \u00b6 OTHER_DISEASES \u00b6 OTHER_DISEASES = 'other disease types' ENTREZ_GENE_URL \u00b6 ENTREZ_GENE_URL = 'https://www.ncbi.nlm.nih.gov/gene' GRAPHKB_GUI \u00b6 GRAPHKB_GUI = 'https://graphkb.bcgsc.ca' filter_by_record_class() \u00b6 Given a list of records, return the subset matching a class or list of classes def filter_by_record_class ( record_list : List [ Dict ], * record_classes , exclude : bool = False ) -> List [ Dict ]: Args record_list ( List[Dict] ) Returns List[Dict] create_graphkb_link() \u00b6 Create a link for a set of statements to the GraphKB client def create_graphkb_link ( record_ids : List [ str ], record_class : str = 'Statement' , ) -> str : Args record_ids ( List[str] ) record_class ( str ) Returns str substitute_sentence_template() \u00b6 Create the filled-in sentence template for a given template and list of substitutions which may be the result of the aggregation of 1 or more statements def substitute_sentence_template ( template : str , conditions : List [ Record ], subjects : List [ Record ], relevance : Record , evidence : List [ Record ], statement_rids : List [ str ] = [], disease_matches : Set [ str ] = set (), ) -> str : Args template ( str ) conditions ( List[Record] ) subjects ( List[Record] ) relevance ( Record ) evidence ( List[Record] ) statement_rids ( List[str] ) disease_matches ( Set[str] ) Returns str aggregate_statements() \u00b6 Group Statements that only differ in disease conditions and evidence def aggregate_statements ( graphkb_conn : GraphKBConnection , template : str , statements : List [ Statement ], disease_matches : Set [ str ], ) -> Dict [ str , str ]: Args graphkb_conn ( GraphKBConnection ) template ( str ) statements ( List[Statement] ) disease_matches ( Set[str] ) Returns Dict[str, str] create_section_html() \u00b6 Generate HTML for a gene section of the comments def create_section_html ( graphkb_conn : GraphKBConnection , gene_name : str , sentences_by_statement_id : Dict [ str , str ], statements : Dict [ str , Statement ], exp_variants : List [ IprVariant ], ) -> str : Args graphkb_conn ( GraphKBConnection ) gene_name ( str ) sentences_by_statement_id ( Dict[str, str] ) statements ( Dict[str, Statement] ) exp_variants (List[ IprVariant ]) Returns str section_statements_by_genes() \u00b6 Determine the statements associated with each gene name def section_statements_by_genes ( graphkb_conn : GraphKBConnection , statements : Sequence [ Statement ] ) -> Dict [ str , Set [ str ]]: Args graphkb_conn ( GraphKBConnection ) statements ( Sequence[Statement] ) Returns Dict[str, Set[str]] summarize() \u00b6 Given a list of GraphKB matches generate a text summary to add to the report def summarize ( graphkb_conn : GraphKBConnection , matches : Sequence [ KbMatch ], disease_name : str , variants : List [ IprVariant ], ) -> str : Args graphkb_conn ( GraphKBConnection ) matches (Sequence[ KbMatch ]) disease_name ( str ) variants (List[ IprVariant ]) Returns str","title":"ipr.summary"},{"location":"developer_reference/ipr/summary/#iprsummary","text":"","title":"ipr.summary"},{"location":"developer_reference/ipr/summary/#other_diseases","text":"OTHER_DISEASES = 'other disease types'","title":"OTHER_DISEASES"},{"location":"developer_reference/ipr/summary/#entrez_gene_url","text":"ENTREZ_GENE_URL = 'https://www.ncbi.nlm.nih.gov/gene'","title":"ENTREZ_GENE_URL"},{"location":"developer_reference/ipr/summary/#graphkb_gui","text":"GRAPHKB_GUI = 'https://graphkb.bcgsc.ca'","title":"GRAPHKB_GUI"},{"location":"developer_reference/ipr/summary/#filter_by_record_class","text":"Given a list of records, return the subset matching a class or list of classes def filter_by_record_class ( record_list : List [ Dict ], * record_classes , exclude : bool = False ) -> List [ Dict ]: Args record_list ( List[Dict] ) Returns List[Dict]","title":"filter_by_record_class()"},{"location":"developer_reference/ipr/summary/#create_graphkb_link","text":"Create a link for a set of statements to the GraphKB client def create_graphkb_link ( record_ids : List [ str ], record_class : str = 'Statement' , ) -> str : Args record_ids ( List[str] ) record_class ( str ) Returns str","title":"create_graphkb_link()"},{"location":"developer_reference/ipr/summary/#substitute_sentence_template","text":"Create the filled-in sentence template for a given template and list of substitutions which may be the result of the aggregation of 1 or more statements def substitute_sentence_template ( template : str , conditions : List [ Record ], subjects : List [ Record ], relevance : Record , evidence : List [ Record ], statement_rids : List [ str ] = [], disease_matches : Set [ str ] = set (), ) -> str : Args template ( str ) conditions ( List[Record] ) subjects ( List[Record] ) relevance ( Record ) evidence ( List[Record] ) statement_rids ( List[str] ) disease_matches ( Set[str] ) Returns str","title":"substitute_sentence_template()"},{"location":"developer_reference/ipr/summary/#aggregate_statements","text":"Group Statements that only differ in disease conditions and evidence def aggregate_statements ( graphkb_conn : GraphKBConnection , template : str , statements : List [ Statement ], disease_matches : Set [ str ], ) -> Dict [ str , str ]: Args graphkb_conn ( GraphKBConnection ) template ( str ) statements ( List[Statement] ) disease_matches ( Set[str] ) Returns Dict[str, str]","title":"aggregate_statements()"},{"location":"developer_reference/ipr/summary/#create_section_html","text":"Generate HTML for a gene section of the comments def create_section_html ( graphkb_conn : GraphKBConnection , gene_name : str , sentences_by_statement_id : Dict [ str , str ], statements : Dict [ str , Statement ], exp_variants : List [ IprVariant ], ) -> str : Args graphkb_conn ( GraphKBConnection ) gene_name ( str ) sentences_by_statement_id ( Dict[str, str] ) statements ( Dict[str, Statement] ) exp_variants (List[ IprVariant ]) Returns str","title":"create_section_html()"},{"location":"developer_reference/ipr/summary/#section_statements_by_genes","text":"Determine the statements associated with each gene name def section_statements_by_genes ( graphkb_conn : GraphKBConnection , statements : Sequence [ Statement ] ) -> Dict [ str , Set [ str ]]: Args graphkb_conn ( GraphKBConnection ) statements ( Sequence[Statement] ) Returns Dict[str, Set[str]]","title":"section_statements_by_genes()"},{"location":"developer_reference/ipr/summary/#summarize","text":"Given a list of GraphKB matches generate a text summary to add to the report def summarize ( graphkb_conn : GraphKBConnection , matches : Sequence [ KbMatch ], disease_name : str , variants : List [ IprVariant ], ) -> str : Args graphkb_conn ( GraphKBConnection ) matches (Sequence[ KbMatch ]) disease_name ( str ) variants (List[ IprVariant ]) Returns str","title":"summarize()"},{"location":"developer_reference/ipr/therapeutic_options/","text":"ipr.therapeutic_options \u00b6 upload variant and report information to IPR create_therapeutic_options() \u00b6 Generate therapeutic options summary from the list of kb-matches def create_therapeutic_options ( graphkb_conn : GraphKBConnection , kb_matches : List [ KbMatch ], variants : List [ IprVariant ] ) -> List [ Dict ]: Args graphkb_conn ( GraphKBConnection ) kb_matches (List[ KbMatch ]) variants (List[ IprVariant ]) Returns List[Dict]","title":"ipr.therapeutic_options"},{"location":"developer_reference/ipr/therapeutic_options/#iprtherapeutic_options","text":"upload variant and report information to IPR","title":"ipr.therapeutic_options"},{"location":"developer_reference/ipr/therapeutic_options/#create_therapeutic_options","text":"Generate therapeutic options summary from the list of kb-matches def create_therapeutic_options ( graphkb_conn : GraphKBConnection , kb_matches : List [ KbMatch ], variants : List [ IprVariant ] ) -> List [ Dict ]: Args graphkb_conn ( GraphKBConnection ) kb_matches (List[ KbMatch ]) variants (List[ IprVariant ]) Returns List[Dict]","title":"create_therapeutic_options()"},{"location":"developer_reference/ipr/types/","text":"ipr.types \u00b6 IprVariant \u00b6 IprVariant = Union [ IprGeneVariant , IprStructuralVariant ] class KbMatch \u00b6 inherits TypedDict Attributes variant ( str ) variantType ( str ) approvedTherapy ( bool ) category ( str ) context ( str ) kbContextId ( str ) disease ( str ) evidenceLevel ( str ) kbStatementId ( str ) kbVariant ( str ) kbVariantId ( str ) matchedCancer ( bool ) reference ( str ) relevance ( str ) kbRelevanceId ( str ) externalSource ( str ) externalStatementId ( str ) reviewStatus ( str ) class IprGeneVariant \u00b6 inherits TypedDict Attributes gene ( str ) key ( str ) variantType ( str ) variant ( str ) class IprGene \u00b6 inherits TypedDict Attributes name ( str ) cancerRelated ( Optional[bool] ) knownFusionPartner ( Optional[bool] ) knownSmallMutation ( Optional[bool] ) tumourSuppressor ( Optional[bool] ) oncogene ( Optional[bool] ) therapeuticAssociated ( Optional[bool] ) class IprStructuralVariant \u00b6 inherits TypedDict Attributes key ( str ) variantType ( str ) variant ( str ) gene1 ( str ) gene2 ( str ) exon1 ( int ) exon2 ( int ) class ImageDefinition \u00b6 inherits TypedDict Attributes key ( str ) path ( str )","title":"ipr.types"},{"location":"developer_reference/ipr/types/#iprtypes","text":"","title":"ipr.types"},{"location":"developer_reference/ipr/types/#iprvariant","text":"IprVariant = Union [ IprGeneVariant , IprStructuralVariant ]","title":"IprVariant"},{"location":"developer_reference/ipr/types/#class-kbmatch","text":"inherits TypedDict Attributes variant ( str ) variantType ( str ) approvedTherapy ( bool ) category ( str ) context ( str ) kbContextId ( str ) disease ( str ) evidenceLevel ( str ) kbStatementId ( str ) kbVariant ( str ) kbVariantId ( str ) matchedCancer ( bool ) reference ( str ) relevance ( str ) kbRelevanceId ( str ) externalSource ( str ) externalStatementId ( str ) reviewStatus ( str )","title":"class KbMatch"},{"location":"developer_reference/ipr/types/#class-iprgenevariant","text":"inherits TypedDict Attributes gene ( str ) key ( str ) variantType ( str ) variant ( str )","title":"class IprGeneVariant"},{"location":"developer_reference/ipr/types/#class-iprgene","text":"inherits TypedDict Attributes name ( str ) cancerRelated ( Optional[bool] ) knownFusionPartner ( Optional[bool] ) knownSmallMutation ( Optional[bool] ) tumourSuppressor ( Optional[bool] ) oncogene ( Optional[bool] ) therapeuticAssociated ( Optional[bool] )","title":"class IprGene"},{"location":"developer_reference/ipr/types/#class-iprstructuralvariant","text":"inherits TypedDict Attributes key ( str ) variantType ( str ) variant ( str ) gene1 ( str ) gene2 ( str ) exon1 ( int ) exon2 ( int )","title":"class IprStructuralVariant"},{"location":"developer_reference/ipr/types/#class-imagedefinition","text":"inherits TypedDict Attributes key ( str ) path ( str )","title":"class ImageDefinition"},{"location":"developer_reference/ipr/util/","text":"ipr.util \u00b6 VERBOSE_ERROR_CODE \u00b6 VERBOSE_ERROR_CODE = ( logging . INFO + logging . DEBUG ) // 2 logger \u00b6 logger = logging . getLogger ( 'ipr' ) LOG_LEVELS \u00b6 LOG_LEVELS = { 'info' : logging . INFO , 'debug' : logging . DEBUG , 'warn' : logging . WARN , 'error' : logging . ERROR , 'verbose' : VERBOSE_ERROR_CODE , create_variant_name() \u00b6 Given an IPR variant row, create the variant representation to be used as the name of the variant def create_variant_name ( variant : IprVariant ) -> str : Args variant ( IprVariant ) Returns str create_variant_name_tuple() \u00b6 Given an IPR variant row, create the variant representation to be used as the name of the variant def create_variant_name_tuple ( variant : IprVariant ) -> Tuple [ str , str ]: Args variant ( IprVariant ) Returns Tuple[str, str] find_variant() \u00b6 Find a variant in a list of variants by its key and type def find_variant ( all_variants : List [ IprVariant ], variant_type : str , variant_key : str ) -> IprVariant : Args all_variants (List[ IprVariant ]) variant_type ( str ) variant_key ( str ) Returns IprVariant generate_ontology_preference_key() \u00b6 Generate a tuple key for comparing preferred ontology terms. def generate_ontology_preference_key ( record : Dict , sources_sort : Dict [ str , int ] = {}) -> Tuple : Args record ( Dict ) sources_sort ( Dict[str, int] ) Returns Tuple get_preferred_drug_representation() \u00b6 Given a Drug record, follow its linked records to find the preferred representation by following alias, deprecating, and cross reference links def get_preferred_drug_representation ( graphkb_conn : GraphKBConnection , drug_record_id : str ) -> Dict : Args graphkb_conn ( GraphKBConnection ) drug_record_id ( str ) Returns Dict get_preferred_gene_name() \u00b6 Given some Feature record ID return the preferred gene name def get_preferred_gene_name ( graphkb_conn : GraphKBConnection , record_id : str ) -> str : Args graphkb_conn ( GraphKBConnection ) record_id ( str ) Returns str pandas_falsy() \u00b6 Check if a field is python falsy or pandas null def pandas_falsy ( field ): Args field","title":"ipr.util"},{"location":"developer_reference/ipr/util/#iprutil","text":"","title":"ipr.util"},{"location":"developer_reference/ipr/util/#verbose_error_code","text":"VERBOSE_ERROR_CODE = ( logging . INFO + logging . DEBUG ) // 2","title":"VERBOSE_ERROR_CODE"},{"location":"developer_reference/ipr/util/#logger","text":"logger = logging . getLogger ( 'ipr' )","title":"logger"},{"location":"developer_reference/ipr/util/#log_levels","text":"LOG_LEVELS = { 'info' : logging . INFO , 'debug' : logging . DEBUG , 'warn' : logging . WARN , 'error' : logging . ERROR , 'verbose' : VERBOSE_ERROR_CODE ,","title":"LOG_LEVELS"},{"location":"developer_reference/ipr/util/#create_variant_name","text":"Given an IPR variant row, create the variant representation to be used as the name of the variant def create_variant_name ( variant : IprVariant ) -> str : Args variant ( IprVariant ) Returns str","title":"create_variant_name()"},{"location":"developer_reference/ipr/util/#create_variant_name_tuple","text":"Given an IPR variant row, create the variant representation to be used as the name of the variant def create_variant_name_tuple ( variant : IprVariant ) -> Tuple [ str , str ]: Args variant ( IprVariant ) Returns Tuple[str, str]","title":"create_variant_name_tuple()"},{"location":"developer_reference/ipr/util/#find_variant","text":"Find a variant in a list of variants by its key and type def find_variant ( all_variants : List [ IprVariant ], variant_type : str , variant_key : str ) -> IprVariant : Args all_variants (List[ IprVariant ]) variant_type ( str ) variant_key ( str ) Returns IprVariant","title":"find_variant()"},{"location":"developer_reference/ipr/util/#generate_ontology_preference_key","text":"Generate a tuple key for comparing preferred ontology terms. def generate_ontology_preference_key ( record : Dict , sources_sort : Dict [ str , int ] = {}) -> Tuple : Args record ( Dict ) sources_sort ( Dict[str, int] ) Returns Tuple","title":"generate_ontology_preference_key()"},{"location":"developer_reference/ipr/util/#get_preferred_drug_representation","text":"Given a Drug record, follow its linked records to find the preferred representation by following alias, deprecating, and cross reference links def get_preferred_drug_representation ( graphkb_conn : GraphKBConnection , drug_record_id : str ) -> Dict : Args graphkb_conn ( GraphKBConnection ) drug_record_id ( str ) Returns Dict","title":"get_preferred_drug_representation()"},{"location":"developer_reference/ipr/util/#get_preferred_gene_name","text":"Given some Feature record ID return the preferred gene name def get_preferred_gene_name ( graphkb_conn : GraphKBConnection , record_id : str ) -> str : Args graphkb_conn ( GraphKBConnection ) record_id ( str ) Returns str","title":"get_preferred_gene_name()"},{"location":"developer_reference/ipr/util/#pandas_falsy","text":"Check if a field is python falsy or pandas null def pandas_falsy ( field ): Args field","title":"pandas_falsy()"},{"location":"graphkb/","text":"About GraphKB \u00b6 GraphKB is a graph-based implementation of a cancer knowledge base. An overview of some of the features of GraphKB are given below. Features \u00b6 Dual Aggregate and Standalone KB \u00b6 GraphKB functions both as an aggregate knowledge base as well as a standalone application. Data can be imported from many external sources (see the data loading page ), but it can also be input directly. This also allows users to make manual updates and changes to imported content which is helpful when there may be errors or missing data that needs to be addressed in a time-sensitive manner. Multiple Overlapping Ontologies \u00b6 GraphKB is unique among other knowledge base projects in its inclusion of ontology relations and subsequent real-time leveraging of their inherent graph structure. The simultaneous loading of multiple overlapping ontologies allows for better coverage of terms when loading data from resources without controlled vocabulary 1 . It also enables users to match the chosen ontology of the source resource when specified. Non-specific Variant Notation Allows Curating Novel Variants \u00b6 The goal of GraphKB is to allow users to input content and match the specificity that was given by the source that they are curating. For example if a source claims that any truncating mutation in a particular gene is damaging then we would like to put that in as any truncating mutation rather than create a list of known or previously seen truncating mutations. The motivation here is that then if a novel mutation appears which fits this categorization we will be able to match and annotate it as well. GraphKB accomplishes this both by extending HGVS to allow other coordinate systems (such as exons) but also through allowing categorical variants as seen in the next section. Support for Complex Variant Types \u00b6 Variants in GraphKB can be defined by a position (PositionalVariant) or a category (CategoricalVariant). While GraphKB supports the traditional variant types (ex. single nucleotide variants), it also supports any number of more complex variant types (ex. molecular signatures). These can be defined via the categorical variant types which require only a reference element and a variant type. The reference element would point to a gene in a traditional mutation but can also point to any ontology defined in the database which includes molecular signatures and biological pathways. The type is defined by the Vocabulary packaged with GraphKB as a JSON input and can be edited and added to through the user interface. GraphKB was designed with storing fusions and structural variants in mind. Each variant record includes two reference fields, the latter of which is most often null for other variant types. This allows us to specify the second gene with the same level of specificity as the first. Some examples of the various categorical variants that it is possible to create in GraphKB may be Reference1 Reference2 Type Description Homologous Recombination Deficiency null strong signature A strong HRD signature KRAS null gain of function mutation Any gain of function mutation in the gene, KRAS EWSR1 FLI1 fusion Any fusion between EWSR1 and FLI1 The vocabulary used to create signature variants has been organized to allow multiple levels of specificity. Similarly, common names of signatures have been organized and related to allow users to input the terminology used by the source they are curating. We include a molecular signatures ontology file in the GraphKB loaders repository for convenience. We welcome contributions and suggestions via that repository. Getting Started \u00b6 Users \u00b6 The simplest way to try out GraphKB is via the demo we provide here . simply click on the /graphkb link and enter the provided credentials ( graphkb_admin / graphkb_admin ). This will allow you to test out the application before having to set up your own instance. If your institution would like to host an instance of GraphKB please see the instructions for developers and system administrators in the next section. Developers / Sys-Admins \u00b6 GraphKB can be installed/setup by itself or in combination with the PORI reporting application, IPR. To see instructions for setup of the complete platform please see the main install page . Loading Data \u00b6 When you setup/install GraphKB you will create a new and empty database. Most users will then want to load some standard content into their newly created instance. We have created scripts and modules to simplify this process. See the data loading page for more information. Using the Python Adapter \u00b6 The python adapter to GraphKB is provided for users who would like to incorporate an instance of GraphKB into their own scripts and pipelines. Additionally it is used by the IPR python adapter to connect to GraphKB. Reisle, C. et al. A Platform for Oncogenomic Reporting and Interpretation. bioRxiv 2021.04.13.439667 (2021) doi:10.1101/2021.04.13.439667 \u21a9","title":"About GraphKB"},{"location":"graphkb/#about-graphkb","text":"GraphKB is a graph-based implementation of a cancer knowledge base. An overview of some of the features of GraphKB are given below.","title":"About GraphKB"},{"location":"graphkb/#features","text":"","title":"Features"},{"location":"graphkb/#dual-aggregate-and-standalone-kb","text":"GraphKB functions both as an aggregate knowledge base as well as a standalone application. Data can be imported from many external sources (see the data loading page ), but it can also be input directly. This also allows users to make manual updates and changes to imported content which is helpful when there may be errors or missing data that needs to be addressed in a time-sensitive manner.","title":"Dual Aggregate and Standalone KB"},{"location":"graphkb/#multiple-overlapping-ontologies","text":"GraphKB is unique among other knowledge base projects in its inclusion of ontology relations and subsequent real-time leveraging of their inherent graph structure. The simultaneous loading of multiple overlapping ontologies allows for better coverage of terms when loading data from resources without controlled vocabulary 1 . It also enables users to match the chosen ontology of the source resource when specified.","title":"Multiple Overlapping Ontologies"},{"location":"graphkb/#non-specific-variant-notation-allows-curating-novel-variants","text":"The goal of GraphKB is to allow users to input content and match the specificity that was given by the source that they are curating. For example if a source claims that any truncating mutation in a particular gene is damaging then we would like to put that in as any truncating mutation rather than create a list of known or previously seen truncating mutations. The motivation here is that then if a novel mutation appears which fits this categorization we will be able to match and annotate it as well. GraphKB accomplishes this both by extending HGVS to allow other coordinate systems (such as exons) but also through allowing categorical variants as seen in the next section.","title":"Non-specific Variant Notation Allows Curating Novel Variants"},{"location":"graphkb/#support-for-complex-variant-types","text":"Variants in GraphKB can be defined by a position (PositionalVariant) or a category (CategoricalVariant). While GraphKB supports the traditional variant types (ex. single nucleotide variants), it also supports any number of more complex variant types (ex. molecular signatures). These can be defined via the categorical variant types which require only a reference element and a variant type. The reference element would point to a gene in a traditional mutation but can also point to any ontology defined in the database which includes molecular signatures and biological pathways. The type is defined by the Vocabulary packaged with GraphKB as a JSON input and can be edited and added to through the user interface. GraphKB was designed with storing fusions and structural variants in mind. Each variant record includes two reference fields, the latter of which is most often null for other variant types. This allows us to specify the second gene with the same level of specificity as the first. Some examples of the various categorical variants that it is possible to create in GraphKB may be Reference1 Reference2 Type Description Homologous Recombination Deficiency null strong signature A strong HRD signature KRAS null gain of function mutation Any gain of function mutation in the gene, KRAS EWSR1 FLI1 fusion Any fusion between EWSR1 and FLI1 The vocabulary used to create signature variants has been organized to allow multiple levels of specificity. Similarly, common names of signatures have been organized and related to allow users to input the terminology used by the source they are curating. We include a molecular signatures ontology file in the GraphKB loaders repository for convenience. We welcome contributions and suggestions via that repository.","title":"Support for Complex Variant Types"},{"location":"graphkb/#getting-started","text":"","title":"Getting Started"},{"location":"graphkb/#users","text":"The simplest way to try out GraphKB is via the demo we provide here . simply click on the /graphkb link and enter the provided credentials ( graphkb_admin / graphkb_admin ). This will allow you to test out the application before having to set up your own instance. If your institution would like to host an instance of GraphKB please see the instructions for developers and system administrators in the next section.","title":"Users"},{"location":"graphkb/#developers-sys-admins","text":"GraphKB can be installed/setup by itself or in combination with the PORI reporting application, IPR. To see instructions for setup of the complete platform please see the main install page .","title":"Developers / Sys-Admins"},{"location":"graphkb/#loading-data","text":"When you setup/install GraphKB you will create a new and empty database. Most users will then want to load some standard content into their newly created instance. We have created scripts and modules to simplify this process. See the data loading page for more information.","title":"Loading Data"},{"location":"graphkb/#using-the-python-adapter","text":"The python adapter to GraphKB is provided for users who would like to incorporate an instance of GraphKB into their own scripts and pipelines. Additionally it is used by the IPR python adapter to connect to GraphKB. Reisle, C. et al. A Platform for Oncogenomic Reporting and Interpretation. bioRxiv 2021.04.13.439667 (2021) doi:10.1101/2021.04.13.439667 \u21a9","title":"Using the Python Adapter"},{"location":"graphkb/loading_data/","text":"Loading Data \u00b6 We have provided a number of modules to automate loading external resources into GraphKB. Users can pick and choose which resources they would like to load or use the snakemake pipeline to load them all (see instructions here ). This will download and load content by default into your newly created GraphKB instance. Popular Resources \u00b6 Most popular resources which have pre-built loaders provided for GraphKB are listed below. However, for an exhaustive list of all possible loaders, please see the loader project itself. Cancer Genome Interpreter \u00b6 https://www.cancergenomeinterpreter.org/home CC BY-NC 4.0 This is an external knowledge base which can be imported as statements into GraphKB. ChEMBL \u00b6 https://www.ebi.ac.uk/chembl CC BY-SA 3.0 Drug definitions and relationships can be loaded from ChEMBL via their REST API. CIViC \u00b6 https://civicdb.org CC0 1.0 This is an external knowledge base which can be imported as statements into GraphKB. ClinicalTrials.gov \u00b6 https://clinicaltrials.gov/ct2/home Attribution Contains details for clinical trials around the world. Where possible the drugs and disease terms associated with the trial are matched and linked to the trial when the data is loaded. COSMIC \u00b6 https://cancer.sanger.ac.uk/cosmic Non-commercial Catalogue of Somatic Mutations in Cancer. Loaders are written for importing both the resistance mutations as well as recurrent fusions information. DGIdb \u00b6 https://www.dgidb.org Open Access Loads Gene-Drug Interactions into GraphKB. These are used in exploring novel mutation targets. Disease Ontology \u00b6 https://disease-ontology.org CC0 1.0 Universal Disease definitions and relationships are loaded from Data files provided by the Disease Ontology. DoCM \u00b6 http://docm.info CC BY 4.0 This is an external knowledge base which can be imported as statements into GraphKB. DrugBank \u00b6 https://go.drugbank.com Attribution-NonCommercial 4.0 International Drug Definitions and relationships along with cross references to the FDA drugs list are loaded from the XML database dumps of DrugBank. Ensembl \u00b6 https://uswest.ensembl.org/index.html No Restrictions Gene, Transcript, and Protein definitions as well as cross-mappings to RefSeq versions. Entrez API \u00b6 https://www.ncbi.nlm.nih.gov/books/NBK25501 No Restrictions Module used in other loaders for fetching publications (PubMed, PMC); genes (Entrez gene); RS IDs (snp), etc. from the NCBI Entrez API utitlies. FDA Approval Announcements \u00b6 https://www.fda.gov/drugs/resources-information-approved-drugs/hematologyoncology-cancer-approvals-safety-notifications Parses Oncology Approval Announcements from the FDA site, stores as evidence items. FDA SRS \u00b6 https://precision.fda.gov/uniisearch The FDA global substance registration system contains drug definitions and names. GraphKB Ontology JSON \u00b6 https://github.com/bcgsc/pori_graphkb_loader/tree/master/src/ontology This loads a simple JSON format describing a set of ontology terms. We have included some examples and helpful ontology JSON files in the data folder of the corresponding repository. HGNC \u00b6 https://www.genenames.org No Restrictions Gene names and definitions as well as cross-mappings to several other gene resources such as ensembl and entrez. MOAlmanac \u00b6 https://moalmanac.org ODbL v1.0 A collection of putative alteration/action relationships identified in clinical, preclinical, and inferential studies. NCIt \u00b6 https://ncithesaurus.nci.nih.gov/ncitbrowser CC BY 4.0 NCI Thesaurus which contains therapies, anatomical entities, and disease definitions. OncoKB \u00b6 https://www.oncokb.org Restricted This is a legacy loader. It is written to load the actionability JSON files provided by OncoKB. As this is not an open data resource, using this loader will require licensing specific to your user/instance. This is an external knowledge base which can be imported as statements into GraphKB. Uberon \u00b6 https://uberon.github.io CC BY 3.0 The uberon ontology contains anatomical entity definitions. Custom Content \u00b6 If you have your own instance of GraphKB and would like to transform your existing knowledge base to load it into GraphKB please look at the other knowledge base loaders for examples. There are some commonly used helper modules and functions available in the code base to make this process simpler. You can see documentation for individual loaders grouped with their loader (See their corresponding README.md). src/ `--loader/ |-- index.js `-- README.md If you have any issues or questions please make an issue in the loaders repo . Loading Content \u00b6 For convenience, a snakemake workflow is included to run all available loaders in an optimal order to initialize the content in a new instance of GraphKB. This is done via python snakemake. To set up snakemake in a virtual environment run the following python3 -m venv venv source venv/bin/activate pip install -U pip setuptools wheel pip install snakemake Then the workflow can be run as follows (single core by default but can be adjusted depending on your server settings) snakemake -j 1 You will want to pass snakemake the specific GraphKB instance you are working with as well as the credentials of the user that will be uploading. If you have followed the docker install demo instructions this might looks something like this snakemake -j 1 \\ --config gkb_user = 'graphkb_importer' \\ gkb_pass = 'secret' \\ gkb_url = 'http://localhost:8080/api' The COSMIC and DrugBank options require licensing and are therefore not run by default. If you have a license to use them then you can include one or both of them by providing email and password as config parameters snakemake -j 1 \\ --config drugbank_email = \"YOUR EMAIL\" \\ drugbank_password = \"YOUR PASSWORD\" \\ cosmic_email = \"YOUR EMAIL\" \\ cosmic_password = \"YOUR PASSWORD\"","title":"Loading Data"},{"location":"graphkb/loading_data/#loading-data","text":"We have provided a number of modules to automate loading external resources into GraphKB. Users can pick and choose which resources they would like to load or use the snakemake pipeline to load them all (see instructions here ). This will download and load content by default into your newly created GraphKB instance.","title":"Loading Data"},{"location":"graphkb/loading_data/#popular-resources","text":"Most popular resources which have pre-built loaders provided for GraphKB are listed below. However, for an exhaustive list of all possible loaders, please see the loader project itself.","title":"Popular Resources"},{"location":"graphkb/loading_data/#cancer-genome-interpreter","text":"https://www.cancergenomeinterpreter.org/home CC BY-NC 4.0 This is an external knowledge base which can be imported as statements into GraphKB.","title":"Cancer Genome Interpreter"},{"location":"graphkb/loading_data/#chembl","text":"https://www.ebi.ac.uk/chembl CC BY-SA 3.0 Drug definitions and relationships can be loaded from ChEMBL via their REST API.","title":"ChEMBL"},{"location":"graphkb/loading_data/#civic","text":"https://civicdb.org CC0 1.0 This is an external knowledge base which can be imported as statements into GraphKB.","title":"CIViC"},{"location":"graphkb/loading_data/#clinicaltrialsgov","text":"https://clinicaltrials.gov/ct2/home Attribution Contains details for clinical trials around the world. Where possible the drugs and disease terms associated with the trial are matched and linked to the trial when the data is loaded.","title":"ClinicalTrials.gov"},{"location":"graphkb/loading_data/#cosmic","text":"https://cancer.sanger.ac.uk/cosmic Non-commercial Catalogue of Somatic Mutations in Cancer. Loaders are written for importing both the resistance mutations as well as recurrent fusions information.","title":"COSMIC"},{"location":"graphkb/loading_data/#dgidb","text":"https://www.dgidb.org Open Access Loads Gene-Drug Interactions into GraphKB. These are used in exploring novel mutation targets.","title":"DGIdb"},{"location":"graphkb/loading_data/#disease-ontology","text":"https://disease-ontology.org CC0 1.0 Universal Disease definitions and relationships are loaded from Data files provided by the Disease Ontology.","title":"Disease Ontology"},{"location":"graphkb/loading_data/#docm","text":"http://docm.info CC BY 4.0 This is an external knowledge base which can be imported as statements into GraphKB.","title":"DoCM"},{"location":"graphkb/loading_data/#drugbank","text":"https://go.drugbank.com Attribution-NonCommercial 4.0 International Drug Definitions and relationships along with cross references to the FDA drugs list are loaded from the XML database dumps of DrugBank.","title":"DrugBank"},{"location":"graphkb/loading_data/#ensembl","text":"https://uswest.ensembl.org/index.html No Restrictions Gene, Transcript, and Protein definitions as well as cross-mappings to RefSeq versions.","title":"Ensembl"},{"location":"graphkb/loading_data/#entrez-api","text":"https://www.ncbi.nlm.nih.gov/books/NBK25501 No Restrictions Module used in other loaders for fetching publications (PubMed, PMC); genes (Entrez gene); RS IDs (snp), etc. from the NCBI Entrez API utitlies.","title":"Entrez API"},{"location":"graphkb/loading_data/#fda-approval-announcements","text":"https://www.fda.gov/drugs/resources-information-approved-drugs/hematologyoncology-cancer-approvals-safety-notifications Parses Oncology Approval Announcements from the FDA site, stores as evidence items.","title":"FDA Approval Announcements"},{"location":"graphkb/loading_data/#fda-srs","text":"https://precision.fda.gov/uniisearch The FDA global substance registration system contains drug definitions and names.","title":"FDA SRS"},{"location":"graphkb/loading_data/#graphkb-ontology-json","text":"https://github.com/bcgsc/pori_graphkb_loader/tree/master/src/ontology This loads a simple JSON format describing a set of ontology terms. We have included some examples and helpful ontology JSON files in the data folder of the corresponding repository.","title":"GraphKB Ontology JSON"},{"location":"graphkb/loading_data/#hgnc","text":"https://www.genenames.org No Restrictions Gene names and definitions as well as cross-mappings to several other gene resources such as ensembl and entrez.","title":"HGNC"},{"location":"graphkb/loading_data/#moalmanac","text":"https://moalmanac.org ODbL v1.0 A collection of putative alteration/action relationships identified in clinical, preclinical, and inferential studies.","title":"MOAlmanac"},{"location":"graphkb/loading_data/#ncit","text":"https://ncithesaurus.nci.nih.gov/ncitbrowser CC BY 4.0 NCI Thesaurus which contains therapies, anatomical entities, and disease definitions.","title":"NCIt"},{"location":"graphkb/loading_data/#oncokb","text":"https://www.oncokb.org Restricted This is a legacy loader. It is written to load the actionability JSON files provided by OncoKB. As this is not an open data resource, using this loader will require licensing specific to your user/instance. This is an external knowledge base which can be imported as statements into GraphKB.","title":"OncoKB"},{"location":"graphkb/loading_data/#uberon","text":"https://uberon.github.io CC BY 3.0 The uberon ontology contains anatomical entity definitions.","title":"Uberon"},{"location":"graphkb/loading_data/#custom-content","text":"If you have your own instance of GraphKB and would like to transform your existing knowledge base to load it into GraphKB please look at the other knowledge base loaders for examples. There are some commonly used helper modules and functions available in the code base to make this process simpler. You can see documentation for individual loaders grouped with their loader (See their corresponding README.md). src/ `--loader/ |-- index.js `-- README.md If you have any issues or questions please make an issue in the loaders repo .","title":"Custom Content"},{"location":"graphkb/loading_data/#loading-content","text":"For convenience, a snakemake workflow is included to run all available loaders in an optimal order to initialize the content in a new instance of GraphKB. This is done via python snakemake. To set up snakemake in a virtual environment run the following python3 -m venv venv source venv/bin/activate pip install -U pip setuptools wheel pip install snakemake Then the workflow can be run as follows (single core by default but can be adjusted depending on your server settings) snakemake -j 1 You will want to pass snakemake the specific GraphKB instance you are working with as well as the credentials of the user that will be uploading. If you have followed the docker install demo instructions this might looks something like this snakemake -j 1 \\ --config gkb_user = 'graphkb_importer' \\ gkb_pass = 'secret' \\ gkb_url = 'http://localhost:8080/api' The COSMIC and DrugBank options require licensing and are therefore not run by default. If you have a license to use them then you can include one or both of them by providing email and password as config parameters snakemake -j 1 \\ --config drugbank_email = \"YOUR EMAIL\" \\ drugbank_password = \"YOUR PASSWORD\" \\ cosmic_email = \"YOUR EMAIL\" \\ cosmic_password = \"YOUR PASSWORD\"","title":"Loading Content"},{"location":"graphkb/_pori_graphkb_loader/","text":"GraphKB Loader \u00b6 This repository is part of the platform for oncogenomic reporting and interpretation . This package is used to import content from a variety of sources into GraphKB using the API. Loaders Ontologies Knowledge Bases Guidelines for Developers Getting Started Creating a new Loader API Loaders File Loaders Initializing GraphKB Content Automatic Import modules are provided for a variety of input sources. To Start importing external data, first the GraphKB API must already be running. Then the command line interface can be used for upload. Get the help menu detailing the commands and required inputs as follows node bin/load.js -- --help or using docker docker run bcgsc/pori-graphkb-loader --help Loaders \u00b6 Ontologies \u00b6 ChEMBL Disease Ontology DrugBank Ensembl Entrez Utilities FDA SRS FDA Approval Announcements HGNC NCIt OncoTree GraphKB Ontology JSON RefSeq Uberon Knowledge Bases \u00b6 Cancer Genome Interpreter Cancer Hotspots CGL CIViC ClinicalTrials.gov COSMIC DGIdb DoCM MOAlmanac OncoKB PMC4468049 PMC4232638 Guidelines for Developers \u00b6 Getting Started \u00b6 To write and test the GraphKB loaders you will need the following NodeJS version 12 or higher An instance of the GraphKB API and its required OrientDB instance An instance of keycloak for testing authentication If you do not already have access to a development server of the GraphKB API, the easiest way to set this up is with docker. Follow the developers install instructions from the PORI user guide. Once you have the GraphKB API and keycloak server running you are ready to start writing and testing loaders. clone this repository and install via npm git clone https://github.com/bcgsc/pori_graphkb_loader.git cd por_graphkb_laoder npm install The tests can be run with the following command npm run test Run the loader with the -h flag to see the user help menu npm start -- -h # (1) the -- must be used so that arguments following it are passed to the script being called by the start command and not node itself. You can also run the script directory with node bin/load.js Now you are ready to test running your first loader against the dev API and keycloak instance you set up earlier. It is simplest to run a loader which does not require any preloaded data such as one of the JSON ontology files included in the data directory. npm start -- file ontology data/vocab.json -g http://localhost:8080/api -u graphkb_importer -p password # (1) \"password\" is the default password, and \"graphkb_importer\" is one of the default users used when setting up the development environment with docker-compose. Things should be changed to match the keycloak user in whatever instance you are running the loader against. Creating a new Loader \u00b6 Loaders should be created with a directory directly under src name after the source of the content being loaded. The directory should contain a README.md describing the loader and content and how to obtain the data used by the loader. There are 2 main patterns used by the loaders API Loaders \u00b6 These loaders do not require a file input and directly access an API (ex. CIViC ). Their main module will export a function called upload which has the following signature /** * @param {object} opt options * @param {ApiConnection} opt.conn the api connection object */ const upload = async ({ conn }) => { conn above will be an ApiConnection instance that has already been authenticated against the GraphKB API instance. File Loaders \u00b6 Other loaders which use a file to load content follow a similar pattern except the function they export is called uploadFile and accepts an additional argument. For example see the disease ontology loader. /** * @param {object} opt options * @param {string} opt.filename the path to the input JSON file * @param {ApiConnection} opt.conn the api connection object */ const uploadFile = async ({ filename , conn }) => { Initializing GraphKB Content \u00b6 For convenience, a snakemake workflow is included to run all available loaders in an optimal order to initialize the content in a new instance of GraphKB. This is done via python snakemake. To set up snakemake in a virtual environment run the following python3 -m venv venv source venv/bin/activate pip install -U pip setuptools wheel pip install snakemake Then the workflow can be run as follows (single core by default but can be adjusted depending on your server settings) snakemake -j 1 You will want to pass snakemake the specific GraphKB instance you are working with as well as the credentials of the user that will be uploading. If you have followed the docker install demo instructions this might looks something like this snakemake -j 1 \\ --config gkb_user = 'graphkb_importer' \\ gkb_pass = 'secret' \\ gkb_url = 'http://localhost:8080/api' The COSMIC and DrugBank options require licensing and are therefore not run by default. If you have a license to use them then you can include one or both of them by providing email and password as config parameters snakemake -j 1 \\ --config drugbank_email = \"YOUR EMAIL\" \\ drugbank_password = \"YOUR PASSWORD\" \\ cosmic_email = \"YOUR EMAIL\" \\ cosmic_password = \"YOUR PASSWORD\"","title":"GraphKB Loader"},{"location":"graphkb/_pori_graphkb_loader/#graphkb-loader","text":"This repository is part of the platform for oncogenomic reporting and interpretation . This package is used to import content from a variety of sources into GraphKB using the API. Loaders Ontologies Knowledge Bases Guidelines for Developers Getting Started Creating a new Loader API Loaders File Loaders Initializing GraphKB Content Automatic Import modules are provided for a variety of input sources. To Start importing external data, first the GraphKB API must already be running. Then the command line interface can be used for upload. Get the help menu detailing the commands and required inputs as follows node bin/load.js -- --help or using docker docker run bcgsc/pori-graphkb-loader --help","title":"GraphKB Loader"},{"location":"graphkb/_pori_graphkb_loader/#loaders","text":"","title":"Loaders"},{"location":"graphkb/_pori_graphkb_loader/#ontologies","text":"ChEMBL Disease Ontology DrugBank Ensembl Entrez Utilities FDA SRS FDA Approval Announcements HGNC NCIt OncoTree GraphKB Ontology JSON RefSeq Uberon","title":"Ontologies"},{"location":"graphkb/_pori_graphkb_loader/#knowledge-bases","text":"Cancer Genome Interpreter Cancer Hotspots CGL CIViC ClinicalTrials.gov COSMIC DGIdb DoCM MOAlmanac OncoKB PMC4468049 PMC4232638","title":"Knowledge Bases"},{"location":"graphkb/_pori_graphkb_loader/#guidelines-for-developers","text":"","title":"Guidelines for Developers"},{"location":"graphkb/_pori_graphkb_loader/#getting-started","text":"To write and test the GraphKB loaders you will need the following NodeJS version 12 or higher An instance of the GraphKB API and its required OrientDB instance An instance of keycloak for testing authentication If you do not already have access to a development server of the GraphKB API, the easiest way to set this up is with docker. Follow the developers install instructions from the PORI user guide. Once you have the GraphKB API and keycloak server running you are ready to start writing and testing loaders. clone this repository and install via npm git clone https://github.com/bcgsc/pori_graphkb_loader.git cd por_graphkb_laoder npm install The tests can be run with the following command npm run test Run the loader with the -h flag to see the user help menu npm start -- -h # (1) the -- must be used so that arguments following it are passed to the script being called by the start command and not node itself. You can also run the script directory with node bin/load.js Now you are ready to test running your first loader against the dev API and keycloak instance you set up earlier. It is simplest to run a loader which does not require any preloaded data such as one of the JSON ontology files included in the data directory. npm start -- file ontology data/vocab.json -g http://localhost:8080/api -u graphkb_importer -p password # (1) \"password\" is the default password, and \"graphkb_importer\" is one of the default users used when setting up the development environment with docker-compose. Things should be changed to match the keycloak user in whatever instance you are running the loader against.","title":"Getting Started"},{"location":"graphkb/_pori_graphkb_loader/#creating-a-new-loader","text":"Loaders should be created with a directory directly under src name after the source of the content being loaded. The directory should contain a README.md describing the loader and content and how to obtain the data used by the loader. There are 2 main patterns used by the loaders","title":"Creating a new Loader"},{"location":"graphkb/_pori_graphkb_loader/#api-loaders","text":"These loaders do not require a file input and directly access an API (ex. CIViC ). Their main module will export a function called upload which has the following signature /** * @param {object} opt options * @param {ApiConnection} opt.conn the api connection object */ const upload = async ({ conn }) => { conn above will be an ApiConnection instance that has already been authenticated against the GraphKB API instance.","title":"API Loaders"},{"location":"graphkb/_pori_graphkb_loader/#file-loaders","text":"Other loaders which use a file to load content follow a similar pattern except the function they export is called uploadFile and accepts an additional argument. For example see the disease ontology loader. /** * @param {object} opt options * @param {string} opt.filename the path to the input JSON file * @param {ApiConnection} opt.conn the api connection object */ const uploadFile = async ({ filename , conn }) => {","title":"File Loaders"},{"location":"graphkb/_pori_graphkb_loader/#initializing-graphkb-content","text":"For convenience, a snakemake workflow is included to run all available loaders in an optimal order to initialize the content in a new instance of GraphKB. This is done via python snakemake. To set up snakemake in a virtual environment run the following python3 -m venv venv source venv/bin/activate pip install -U pip setuptools wheel pip install snakemake Then the workflow can be run as follows (single core by default but can be adjusted depending on your server settings) snakemake -j 1 You will want to pass snakemake the specific GraphKB instance you are working with as well as the credentials of the user that will be uploading. If you have followed the docker install demo instructions this might looks something like this snakemake -j 1 \\ --config gkb_user = 'graphkb_importer' \\ gkb_pass = 'secret' \\ gkb_url = 'http://localhost:8080/api' The COSMIC and DrugBank options require licensing and are therefore not run by default. If you have a license to use them then you can include one or both of them by providing email and password as config parameters snakemake -j 1 \\ --config drugbank_email = \"YOUR EMAIL\" \\ drugbank_password = \"YOUR PASSWORD\" \\ cosmic_email = \"YOUR EMAIL\" \\ cosmic_password = \"YOUR PASSWORD\"","title":"Initializing GraphKB Content"},{"location":"graphkb/_pori_graphkb_loader/src/PMC4232638/","text":"Functional Impact Statements \u00b6 This loader loads and processes fusion data from the supplementary files of the following publication . Since this creates statements, ontology and vocabulary loaders should be run first so that it has content to match. First download the data wget https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4232638/bin/13059_2014_484_MOESM2_ESM.xlsx Next use the file loader to load it node bin/load.js file PMC4232638 13059_2014_484_MOESM2_ESM.xlsx","title":"Functional Impact Statements"},{"location":"graphkb/_pori_graphkb_loader/src/PMC4232638/#functional-impact-statements","text":"This loader loads and processes fusion data from the supplementary files of the following publication . Since this creates statements, ontology and vocabulary loaders should be run first so that it has content to match. First download the data wget https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4232638/bin/13059_2014_484_MOESM2_ESM.xlsx Next use the file loader to load it node bin/load.js file PMC4232638 13059_2014_484_MOESM2_ESM.xlsx","title":"Functional Impact Statements"},{"location":"graphkb/_pori_graphkb_loader/src/PMC4468049/","text":"TCGA Fusions \u00b6 This loader loads and processes fusion data from the supplementary files of one of the publications that was associated with TCGA. Since this creates statements, ontology and vocabulary loaders should be run first so that it has content to match. First download the data wget https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4468049/bin/NIHMS632238-supplement-2.xlsx Next use the file loader to load it node bin/load.js file PMC4468049 NIHMS632238-supplement-2.xlsx","title":"TCGA Fusions"},{"location":"graphkb/_pori_graphkb_loader/src/PMC4468049/#tcga-fusions","text":"This loader loads and processes fusion data from the supplementary files of one of the publications that was associated with TCGA. Since this creates statements, ontology and vocabulary loaders should be run first so that it has content to match. First download the data wget https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4468049/bin/NIHMS632238-supplement-2.xlsx Next use the file loader to load it node bin/load.js file PMC4468049 NIHMS632238-supplement-2.xlsx","title":"TCGA Fusions"},{"location":"graphkb/_pori_graphkb_loader/src/asco/","text":"ASCO \u00b6 Loads citation information for ASCO abstracts from their unofficial REST API. Generally used as a helper for other loaders rather than a standalone loader.","title":"ASCO"},{"location":"graphkb/_pori_graphkb_loader/src/asco/#asco","text":"Loads citation information for ASCO abstracts from their unofficial REST API. Generally used as a helper for other loaders rather than a standalone loader.","title":"ASCO"},{"location":"graphkb/_pori_graphkb_loader/src/cancergenomeinterpreter/","text":"Cancer Genome Interpreter (CGI) \u00b6 Since this loader produces statements, ontology and vocabulary data should be loaded first Loads Statements from Cancer Genome Intepreter files. First, download the data wget https://www.cancergenomeinterpreter.org/data/cgi_biomarkers_latest.zip unzip cgi_biomarkers_latest.zip Then load into graphkb node bin/load.js file cgi cgi_biomarkers_per_variant.tsv","title":"Cancer Genome Interpreter (CGI)"},{"location":"graphkb/_pori_graphkb_loader/src/cancergenomeinterpreter/#cancer-genome-interpreter-cgi","text":"Since this loader produces statements, ontology and vocabulary data should be loaded first Loads Statements from Cancer Genome Intepreter files. First, download the data wget https://www.cancergenomeinterpreter.org/data/cgi_biomarkers_latest.zip unzip cgi_biomarkers_latest.zip Then load into graphkb node bin/load.js file cgi cgi_biomarkers_per_variant.tsv","title":"Cancer Genome Interpreter (CGI)"},{"location":"graphkb/_pori_graphkb_loader/src/cancerhotspots/","text":"Cancer Hotspots \u00b6 Since this loader produces statements, ontology and vocabulary data should be loaded first First fetch the data wget http://download.cbioportal.org/cancerhotspots/cancerhotspots.v2.maf.gz gunzip cancerhotspots.v2.maf.gz Then load with the general file loader node bin/load.js file cancerhotspots cancerhotspots.v2.maf","title":"Cancer Hotspots"},{"location":"graphkb/_pori_graphkb_loader/src/cancerhotspots/#cancer-hotspots","text":"Since this loader produces statements, ontology and vocabulary data should be loaded first First fetch the data wget http://download.cbioportal.org/cancerhotspots/cancerhotspots.v2.maf.gz gunzip cancerhotspots.v2.maf.gz Then load with the general file loader node bin/load.js file cancerhotspots cancerhotspots.v2.maf","title":"Cancer Hotspots"},{"location":"graphkb/_pori_graphkb_loader/src/cgl/","text":"CGL \u00b6 This is a custom loader specific to Genome Sciences Centre Internal Content Since this loader produces statements, ontology and vocabulary data should be loaded first","title":"CGL"},{"location":"graphkb/_pori_graphkb_loader/src/cgl/#cgl","text":"This is a custom loader specific to Genome Sciences Centre Internal Content Since this loader produces statements, ontology and vocabulary data should be loaded first","title":"CGL"},{"location":"graphkb/_pori_graphkb_loader/src/chembl/","text":"ChEMBL \u00b6 This module is used by other loaders and does not load a dump itself. Content is loaded via the ChEMBL REST API.","title":"ChEMBL"},{"location":"graphkb/_pori_graphkb_loader/src/chembl/#chembl","text":"This module is used by other loaders and does not load a dump itself. Content is loaded via the ChEMBL REST API.","title":"ChEMBL"},{"location":"graphkb/_pori_graphkb_loader/src/civic/","text":"CIViC \u00b6 Since this loader produces statements, ontology and vocabulary data should be loaded first Loads statements into GraphKB using the CIViC REST API. node bin/load.js civic About \u00b6 The variant.js module handles all parsing/processing of variant records in CIViC for entry into GraphKB. The corresponding tests are under test/civic.test.js . In general this loader attempts to update existing records based on their CIViC evidence ID, however when the mapping from CIViC evidence record to GraphKB statement is not 1 to 1 then the statement is sometimes recreated and the old version soft-deleted instead since we cannot resolve tracking between the 2 for these cases. Trusted Curators \u00b6 By default this loader only loads accepted (reviewed and approved) evidence items from CIViC. However, sometimes items can take a while to be reviewed. To mitigate this problem we allow a list of \"trusted curators\" for which we can load statements in the submitted state. These will be loaded with a GraphKB status of \"pending\". The IDs that should be passed are the CIViC user IDs. For example node bin/load.js civic --trustedCurators 123 124 Mapping Objects from CIViC to GraphKB \u00b6 In general CIViC (v1) and GraphKB have a lot in common so this mapping can be fairly straightforward. In CIViC Evidence Items are similar to GraphKB statements. However, there are a couple of key differences In CIViC a list of drugs can be given as \"substitutes\", in GraphKB these are separate statements In CIViC, generally, there is a 1 to 1 relationship with variants and evidence items, in GraphKB any number of variants can be associated with a statement GraphKB has a separate field for \"appliesTo\", this is the target of the statement Each Evidence Item in CIViC is associated with 1 PubMed article. In GraphKB a statement may have 1-n associated articles. A mapping between CIViC and GraphKB for Evidence Item vs Statement fields is given below GraphKB Field CIViC Field conditions disease conditions variant conditions drug relevance evidence type relevance clinical significance relevance evidence direction evidence source The current implementation of the relevance mapping from CIViC to GraphKB is summarized below CIViC Evidence Type CIViC Evidence Direction CIViC Clinical Significance GraphKB Relevance Diagnostic Supports Negative opposes diagnosis Diagnostic Supports Positive favours diagnosis Functional Supports Dominant Negative dominant negative Functional Supports Gain of Function gain of function Functional Supports Loss of Function loss of function Functional Supports Neomorphic neomorphic Predictive Does Not Support Sensitivity no response Predictive Does Not Support Sensitivity/Response no response Predictive Supports Adverse Response adverse response Predictive Supports Resistance resistance Predictive Does Not Support Resistance no resistance Predictive Supports Sensitivity sensitivity Predictive Supports Sensitivity/Response sensitivity Predisposing Supports Likely Pathogenic likely pathogenic Predisposing Supports Pathogenic pathogenic Predisposing Supports Uncertain Significance likely predisposing Prognostic Supports Better Outcome favourable prognosis Prognostic Supports Negative unfavourable prognosis Prognostic Supports Poor Outcome unfavourable prognosis Prognostic Supports Positive favourable prognosis","title":"CIViC"},{"location":"graphkb/_pori_graphkb_loader/src/civic/#civic","text":"Since this loader produces statements, ontology and vocabulary data should be loaded first Loads statements into GraphKB using the CIViC REST API. node bin/load.js civic","title":"CIViC"},{"location":"graphkb/_pori_graphkb_loader/src/civic/#about","text":"The variant.js module handles all parsing/processing of variant records in CIViC for entry into GraphKB. The corresponding tests are under test/civic.test.js . In general this loader attempts to update existing records based on their CIViC evidence ID, however when the mapping from CIViC evidence record to GraphKB statement is not 1 to 1 then the statement is sometimes recreated and the old version soft-deleted instead since we cannot resolve tracking between the 2 for these cases.","title":"About"},{"location":"graphkb/_pori_graphkb_loader/src/civic/#trusted-curators","text":"By default this loader only loads accepted (reviewed and approved) evidence items from CIViC. However, sometimes items can take a while to be reviewed. To mitigate this problem we allow a list of \"trusted curators\" for which we can load statements in the submitted state. These will be loaded with a GraphKB status of \"pending\". The IDs that should be passed are the CIViC user IDs. For example node bin/load.js civic --trustedCurators 123 124","title":"Trusted Curators"},{"location":"graphkb/_pori_graphkb_loader/src/civic/#mapping-objects-from-civic-to-graphkb","text":"In general CIViC (v1) and GraphKB have a lot in common so this mapping can be fairly straightforward. In CIViC Evidence Items are similar to GraphKB statements. However, there are a couple of key differences In CIViC a list of drugs can be given as \"substitutes\", in GraphKB these are separate statements In CIViC, generally, there is a 1 to 1 relationship with variants and evidence items, in GraphKB any number of variants can be associated with a statement GraphKB has a separate field for \"appliesTo\", this is the target of the statement Each Evidence Item in CIViC is associated with 1 PubMed article. In GraphKB a statement may have 1-n associated articles. A mapping between CIViC and GraphKB for Evidence Item vs Statement fields is given below GraphKB Field CIViC Field conditions disease conditions variant conditions drug relevance evidence type relevance clinical significance relevance evidence direction evidence source The current implementation of the relevance mapping from CIViC to GraphKB is summarized below CIViC Evidence Type CIViC Evidence Direction CIViC Clinical Significance GraphKB Relevance Diagnostic Supports Negative opposes diagnosis Diagnostic Supports Positive favours diagnosis Functional Supports Dominant Negative dominant negative Functional Supports Gain of Function gain of function Functional Supports Loss of Function loss of function Functional Supports Neomorphic neomorphic Predictive Does Not Support Sensitivity no response Predictive Does Not Support Sensitivity/Response no response Predictive Supports Adverse Response adverse response Predictive Supports Resistance resistance Predictive Does Not Support Resistance no resistance Predictive Supports Sensitivity sensitivity Predictive Supports Sensitivity/Response sensitivity Predisposing Supports Likely Pathogenic likely pathogenic Predisposing Supports Pathogenic pathogenic Predisposing Supports Uncertain Significance likely predisposing Prognostic Supports Better Outcome favourable prognosis Prognostic Supports Negative unfavourable prognosis Prognostic Supports Poor Outcome unfavourable prognosis Prognostic Supports Positive favourable prognosis","title":"Mapping Objects from CIViC to GraphKB"},{"location":"graphkb/_pori_graphkb_loader/src/clinicaltrialsgov/","text":"ClinicalTrials.gov \u00b6 This module loads clinical trials data into GraphKB from https://www.clinicaltrials.gov . Since this loader produces statements, ontology and vocabulary data should be loaded first Multiple XML Files \u00b6 Loads Trial records from XML files. See: https://clinicaltrials.gov/ct2/resources/download#DownloadMultipleRecords wget https://clinicaltrials.gov/AllPublicXML.zip unzip AllPublicXML.zip Then you can load these by pointing directly to the sub-folders for folder in AllPublicXML/* ; do echo \"Loading folder: $folder \" node bin/clinicaltrialsgov.js --dir $folder done","title":"ClinicalTrials.gov"},{"location":"graphkb/_pori_graphkb_loader/src/clinicaltrialsgov/#clinicaltrialsgov","text":"This module loads clinical trials data into GraphKB from https://www.clinicaltrials.gov . Since this loader produces statements, ontology and vocabulary data should be loaded first","title":"ClinicalTrials.gov"},{"location":"graphkb/_pori_graphkb_loader/src/clinicaltrialsgov/#multiple-xml-files","text":"Loads Trial records from XML files. See: https://clinicaltrials.gov/ct2/resources/download#DownloadMultipleRecords wget https://clinicaltrials.gov/AllPublicXML.zip unzip AllPublicXML.zip Then you can load these by pointing directly to the sub-folders for folder in AllPublicXML/* ; do echo \"Loading folder: $folder \" node bin/clinicaltrialsgov.js --dir $folder done","title":"Multiple XML Files"},{"location":"graphkb/_pori_graphkb_loader/src/cosmic/","text":"COSMiC \u00b6 This loads fusion and drug resistance data from COSMiC . Since this loader produces statements, ontology and vocabulary data should be loaded first First the data must be downloaded. This requires an account AUTH = $( echo \" $COSMIC_EMAIL : $COSMIC_PASSWORD \" | base64 ) # Download resistance mutations resp = $( curl -H \"Authorization: Basic $AUTH \" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh38/cosmic/v92/CosmicResistanceMutations.tsv.gz ) ; echo $resp url = $( node -e \"var resp = $resp ; console.log(resp.url);\" ) ; curl \" $url \" -o CosmicResistanceMutations.tsv.gz gunzip CosmicResistanceMutations.tsv.gz # Download disease mappings resp = $( curl -H \"Authorization: Basic $AUTH \" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh38/cosmic/v92/classification.csv ) ; echo $resp url = $( node -e \"var resp = $resp ; console.log(resp.url);\" ) ; curl \" $url \" -o classification.csv # Download fusion files resp = $( curl -H \"Authorization: Basic $AUTH \" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh38/cosmic/v92/CosmicFusionExport.tsv.gz ) ; echo $resp url = $( node -e \"var resp = $resp ; console.log(resp.url);\" ) ; curl \" $url \" -o CosmicFusionExport.tsv.gz gunzip CosmicFusionExport.tsv.gz Since this loader requires 2 files, it is separate from the other more general loaders node bin/load.js cosmic resistance CosmicResistanceMutations.tsv classification.csv And then to load the fusions (Will create recurrency statements) node bin/load.js cosmic fusions CosmicFusionExport.tsv classification.csv","title":"COSMiC"},{"location":"graphkb/_pori_graphkb_loader/src/cosmic/#cosmic","text":"This loads fusion and drug resistance data from COSMiC . Since this loader produces statements, ontology and vocabulary data should be loaded first First the data must be downloaded. This requires an account AUTH = $( echo \" $COSMIC_EMAIL : $COSMIC_PASSWORD \" | base64 ) # Download resistance mutations resp = $( curl -H \"Authorization: Basic $AUTH \" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh38/cosmic/v92/CosmicResistanceMutations.tsv.gz ) ; echo $resp url = $( node -e \"var resp = $resp ; console.log(resp.url);\" ) ; curl \" $url \" -o CosmicResistanceMutations.tsv.gz gunzip CosmicResistanceMutations.tsv.gz # Download disease mappings resp = $( curl -H \"Authorization: Basic $AUTH \" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh38/cosmic/v92/classification.csv ) ; echo $resp url = $( node -e \"var resp = $resp ; console.log(resp.url);\" ) ; curl \" $url \" -o classification.csv # Download fusion files resp = $( curl -H \"Authorization: Basic $AUTH \" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh38/cosmic/v92/CosmicFusionExport.tsv.gz ) ; echo $resp url = $( node -e \"var resp = $resp ; console.log(resp.url);\" ) ; curl \" $url \" -o CosmicFusionExport.tsv.gz gunzip CosmicFusionExport.tsv.gz Since this loader requires 2 files, it is separate from the other more general loaders node bin/load.js cosmic resistance CosmicResistanceMutations.tsv classification.csv And then to load the fusions (Will create recurrency statements) node bin/load.js cosmic fusions CosmicFusionExport.tsv classification.csv","title":"COSMiC"},{"location":"graphkb/_pori_graphkb_loader/src/dgidb/","text":"Drug Gene Interaction Database (DGIdb) \u00b6 This loader pulls data into GraphKB using the DGIdb API. Since this loads gene-drug relationships. Loaders for genes and drugs should be run beforehand","title":"Drug Gene Interaction Database (DGIdb)"},{"location":"graphkb/_pori_graphkb_loader/src/dgidb/#drug-gene-interaction-database-dgidb","text":"This loader pulls data into GraphKB using the DGIdb API. Since this loads gene-drug relationships. Loaders for genes and drugs should be run beforehand","title":"Drug Gene Interaction Database (DGIdb)"},{"location":"graphkb/_pori_graphkb_loader/src/diseaseOntology/","text":"Disease Ontology \u00b6 Load data from the disease ontology. First download the latest version of the JSON formatted release REPO = https://github.com/DiseaseOntology/HumanDiseaseOntology.git LATEST = $( git ls-remote $REPO --tags v \\* | cut -f 2 | sed 's/refs\\/tags\\///' | grep '\\bv[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]\\b' | sort -d | tail -n 1 ) echo \"latest version: $LATEST \" wget https://github.com/DiseaseOntology/HumanDiseaseOntology/raw/ $LATEST /src/ontology/doid.json mv doid.json doid_ ${ LATEST } .json Then load this through the general loadFile script node bin/load.js file diseaseOntology doid_ ${ LATEST } .json","title":"Disease Ontology"},{"location":"graphkb/_pori_graphkb_loader/src/diseaseOntology/#disease-ontology","text":"Load data from the disease ontology. First download the latest version of the JSON formatted release REPO = https://github.com/DiseaseOntology/HumanDiseaseOntology.git LATEST = $( git ls-remote $REPO --tags v \\* | cut -f 2 | sed 's/refs\\/tags\\///' | grep '\\bv[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]\\b' | sort -d | tail -n 1 ) echo \"latest version: $LATEST \" wget https://github.com/DiseaseOntology/HumanDiseaseOntology/raw/ $LATEST /src/ontology/doid.json mv doid.json doid_ ${ LATEST } .json Then load this through the general loadFile script node bin/load.js file diseaseOntology doid_ ${ LATEST } .json","title":"Disease Ontology"},{"location":"graphkb/_pori_graphkb_loader/src/docm/","text":"Database of Curated Mutations (DoCM) \u00b6 Uses the DoCM REST API to load content into GraphKB node bin/load.js api docm","title":"Database of Curated Mutations (DoCM)"},{"location":"graphkb/_pori_graphkb_loader/src/docm/#database-of-curated-mutations-docm","text":"Uses the DoCM REST API to load content into GraphKB node bin/load.js api docm","title":"Database of Curated Mutations (DoCM)"},{"location":"graphkb/_pori_graphkb_loader/src/drugbank/","text":"DrugBank \u00b6 Download the complete latest DrugBank Data as XML. You will need an account wget https://www.drugbank.ca/releases latest = $( grep 'href=\"/releases/[^\"]*\"' -o releases | cut -f 3 -d/ | sed 's/\"//' | sort -V | tail -n 2 | head -n 1 ) echo \"newest version: $latest \" rm releases filename = \"drugbank_all_full_database_v $latest \" .xml echo $filename curl -Lfv -o ${ filename } .zip -u $DRUGBANK_EMAIL : $DRUGBANK_PASSWORD https://go.drugbank.com/releases/5-1-8/downloads/all-full-database unzip ${ filename } .zip mv full \\ database.xml $filename Then use the general file loader to load this into GraphKB node bin/load.js file drugbank_all_full_database_*.xml Since this contains cross-mappings to FDA-SRS UNII identifiers it is useful to load that file first","title":"DrugBank"},{"location":"graphkb/_pori_graphkb_loader/src/drugbank/#drugbank","text":"Download the complete latest DrugBank Data as XML. You will need an account wget https://www.drugbank.ca/releases latest = $( grep 'href=\"/releases/[^\"]*\"' -o releases | cut -f 3 -d/ | sed 's/\"//' | sort -V | tail -n 2 | head -n 1 ) echo \"newest version: $latest \" rm releases filename = \"drugbank_all_full_database_v $latest \" .xml echo $filename curl -Lfv -o ${ filename } .zip -u $DRUGBANK_EMAIL : $DRUGBANK_PASSWORD https://go.drugbank.com/releases/5-1-8/downloads/all-full-database unzip ${ filename } .zip mv full \\ database.xml $filename Then use the general file loader to load this into GraphKB node bin/load.js file drugbank_all_full_database_*.xml Since this contains cross-mappings to FDA-SRS UNII identifiers it is useful to load that file first","title":"DrugBank"},{"location":"graphkb/_pori_graphkb_loader/src/ensembl/","text":"Ensembl \u00b6 This loader loads both a BioMart export TSV file or individual records by ID. It is not required to batch load Ensembl data but you can do so if you would like it to appear for users who will use the auto-complete adding variants through GraphKB client First download the batch export from BioMart query_string = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE Query><Query virtualSchemaName = \"default\" formatter = \"TSV\" header = \"1\" uniqueRows = \"0\" count = \"\" datasetConfigVersion = \"0.6\" ><Dataset name = \"hsapiens_gene_ensembl\" interface = \"default\" ><Filter name = \"transcript_biotype\" value = \"protein_coding\"/><Attribute name = \"ensembl_gene_id\" /><Attribute name = \"ensembl_gene_id_version\" /><Attribute name = \"ensembl_transcript_id\" /><Attribute name = \"ensembl_transcript_id_version\" /><Attribute name = \"hgnc_id\" /><Attribute name = \"refseq_mrna\" /><Attribute name = \"description\" /><Attribute name = \"external_gene_name\" /><Attribute name = \"external_gene_source\" /></Dataset></Query>' wget -O biomart_export.tsv \"http://www.ensembl.org/biomart/martservice?query= $query_string \" Next use the general file loader node bin/load.js file ensembl biomart_export.tsv","title":"Ensembl"},{"location":"graphkb/_pori_graphkb_loader/src/ensembl/#ensembl","text":"This loader loads both a BioMart export TSV file or individual records by ID. It is not required to batch load Ensembl data but you can do so if you would like it to appear for users who will use the auto-complete adding variants through GraphKB client First download the batch export from BioMart query_string = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE Query><Query virtualSchemaName = \"default\" formatter = \"TSV\" header = \"1\" uniqueRows = \"0\" count = \"\" datasetConfigVersion = \"0.6\" ><Dataset name = \"hsapiens_gene_ensembl\" interface = \"default\" ><Filter name = \"transcript_biotype\" value = \"protein_coding\"/><Attribute name = \"ensembl_gene_id\" /><Attribute name = \"ensembl_gene_id_version\" /><Attribute name = \"ensembl_transcript_id\" /><Attribute name = \"ensembl_transcript_id_version\" /><Attribute name = \"hgnc_id\" /><Attribute name = \"refseq_mrna\" /><Attribute name = \"description\" /><Attribute name = \"external_gene_name\" /><Attribute name = \"external_gene_source\" /></Dataset></Query>' wget -O biomart_export.tsv \"http://www.ensembl.org/biomart/martservice?query= $query_string \" Next use the general file loader node bin/load.js file ensembl biomart_export.tsv","title":"Ensembl"},{"location":"graphkb/_pori_graphkb_loader/src/entrez/","text":"Entrez API \u00b6 These modules load records by ID from the Entrez REST APIs","title":"Entrez API"},{"location":"graphkb/_pori_graphkb_loader/src/entrez/#entrez-api","text":"These modules load records by ID from the Entrez REST APIs","title":"Entrez API"},{"location":"graphkb/_pori_graphkb_loader/src/fdaApprovals/","text":"FDA Oncology Approval Announcements \u00b6 Loads Evidence records which are a copy of the content from the FDA Oncology Approval Announcements Page. These are loaded so that they can be used as evidence for statements. The web pages are parsed and the cleaned text is included in an Evidence record for reference node bin/load.js api fdaApprovals","title":"FDA Oncology Approval Announcements"},{"location":"graphkb/_pori_graphkb_loader/src/fdaApprovals/#fda-oncology-approval-announcements","text":"Loads Evidence records which are a copy of the content from the FDA Oncology Approval Announcements Page. These are loaded so that they can be used as evidence for statements. The web pages are parsed and the cleaned text is included in an Evidence record for reference node bin/load.js api fdaApprovals","title":"FDA Oncology Approval Announcements"},{"location":"graphkb/_pori_graphkb_loader/src/fdaSrs/","text":"FDA Substance Registration System \u00b6 These are drug names and identifiers used by the FDA SRS . First download the data which should be in a TEXT format wget https://fdasis.nlm.nih.gov/srs/download/srs/UNII_Data.zip unzip UNII_Data.zip rm UNII_Data.zip rm \"README UNII_Lists.txt\" for filename in UNII*txt do echo $filename mv \" $filename \" \" ${ filename // /_ } \" ; done Now use the general file loader to load this into GraphKB node bin/load.js file fdaSrs UNII*.txt Since this file contains cross-reference mappings to NCIt , it is useful to load NCIt first.","title":"FDA Substance Registration System"},{"location":"graphkb/_pori_graphkb_loader/src/fdaSrs/#fda-substance-registration-system","text":"These are drug names and identifiers used by the FDA SRS . First download the data which should be in a TEXT format wget https://fdasis.nlm.nih.gov/srs/download/srs/UNII_Data.zip unzip UNII_Data.zip rm UNII_Data.zip rm \"README UNII_Lists.txt\" for filename in UNII*txt do echo $filename mv \" $filename \" \" ${ filename // /_ } \" ; done Now use the general file loader to load this into GraphKB node bin/load.js file fdaSrs UNII*.txt Since this file contains cross-reference mappings to NCIt , it is useful to load NCIt first.","title":"FDA Substance Registration System"},{"location":"graphkb/_pori_graphkb_loader/src/hgnc/","text":"HGNC \u00b6 Load Hugo genes into GraphKB. This module is primarly used by other modules and not as a standalone. The content is accesssed via the public API found at: https://www.genenames.org/help/rest/ .","title":"HGNC"},{"location":"graphkb/_pori_graphkb_loader/src/hgnc/#hgnc","text":"Load Hugo genes into GraphKB. This module is primarly used by other modules and not as a standalone. The content is accesssed via the public API found at: https://www.genenames.org/help/rest/ .","title":"HGNC"},{"location":"graphkb/_pori_graphkb_loader/src/moa/","text":"MOAlmanac \u00b6 Load variant assestions from the Molecular Oncology Almanac 1 . node bin/load.js api moa Loading Assumptions \u00b6 A specific drug ontology is not used/given and therefore drugs are matched by name A specific gene ontology is not specified and therefore we default to using Entrez genes as they are popular amongst other knowledge bases When given, diseases are preferentially matched to their OncoTree term by both name and code. This falls back to matching by name when the oncotree term/code is not given Relevance Mapping \u00b6 The mapping of relevance terms to their GraphKB equivalent is given below MOA field MOA term GraphKB relevance .therapy_resistance true resistance .therapy_sensitivity true sensitivity .therapy_sensitivity false no sensitivity .favorable_prognosis true favorable prognosis .favorable_prognosis false unfavorable prognosis .features[].attributes[].pathogenic \"1.0\" pathogenic Evidence Level Mapping \u00b6 We have linked the predictive_implication from MOA to specific evidence levels in GraphKB MOA AMP CIViC IPR Clinical evidence Level B (Tier II) B B Clinical trial Level B (Tier II) B B FDA-Approved Level A (Tier I) A A Guideline Level A (Tier I) A A Preclinical Level D (Tier II) D D Inferential E E Category Variant Mapping \u00b6 Specific MOA variant types are mapped as category variants in GraphKB: MOA feature_type MOA field MOA field value GraphKB reference1 class GraphKB reference1 GraphKB type microsatellite_stability status MSI-High Signature microsatellite instability high signature mutational_signature cosmic_signature_number # Signature SBS# signature present knockdown n/a <gene name> Feature <gene name> knockdown Reardon, B. et al. Integrating molecular profiles into clinical frameworks through the Molecular Oncology Almanac to prospectively guide precision oncology. Nature Cancer 2, 1102\u20131112 (2021) \u21a9","title":"MOAlmanac"},{"location":"graphkb/_pori_graphkb_loader/src/moa/#moalmanac","text":"Load variant assestions from the Molecular Oncology Almanac 1 . node bin/load.js api moa","title":"MOAlmanac"},{"location":"graphkb/_pori_graphkb_loader/src/moa/#loading-assumptions","text":"A specific drug ontology is not used/given and therefore drugs are matched by name A specific gene ontology is not specified and therefore we default to using Entrez genes as they are popular amongst other knowledge bases When given, diseases are preferentially matched to their OncoTree term by both name and code. This falls back to matching by name when the oncotree term/code is not given","title":"Loading Assumptions"},{"location":"graphkb/_pori_graphkb_loader/src/moa/#relevance-mapping","text":"The mapping of relevance terms to their GraphKB equivalent is given below MOA field MOA term GraphKB relevance .therapy_resistance true resistance .therapy_sensitivity true sensitivity .therapy_sensitivity false no sensitivity .favorable_prognosis true favorable prognosis .favorable_prognosis false unfavorable prognosis .features[].attributes[].pathogenic \"1.0\" pathogenic","title":"Relevance Mapping"},{"location":"graphkb/_pori_graphkb_loader/src/moa/#evidence-level-mapping","text":"We have linked the predictive_implication from MOA to specific evidence levels in GraphKB MOA AMP CIViC IPR Clinical evidence Level B (Tier II) B B Clinical trial Level B (Tier II) B B FDA-Approved Level A (Tier I) A A Guideline Level A (Tier I) A A Preclinical Level D (Tier II) D D Inferential E E","title":"Evidence Level Mapping"},{"location":"graphkb/_pori_graphkb_loader/src/moa/#category-variant-mapping","text":"Specific MOA variant types are mapped as category variants in GraphKB: MOA feature_type MOA field MOA field value GraphKB reference1 class GraphKB reference1 GraphKB type microsatellite_stability status MSI-High Signature microsatellite instability high signature mutational_signature cosmic_signature_number # Signature SBS# signature present knockdown n/a <gene name> Feature <gene name> knockdown Reardon, B. et al. Integrating molecular profiles into clinical frameworks through the Molecular Oncology Almanac to prospectively guide precision oncology. Nature Cancer 2, 1102\u20131112 (2021) \u21a9","title":"Category Variant Mapping"},{"location":"graphkb/_pori_graphkb_loader/src/ncit/","text":"NCI Thesaurus \u00b6 First download the latest version of the plain text tab delimited files. This should include both the main thesaurus file and the cross mapping file Load the Main Flat File FDA Cross Mapping File Load the Main Flat File \u00b6 Download the file wget https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/Thesaurus.FLAT.zip unzip Thesaurus.FLAT.zip rm Thesaurus.FLAT.zip This is a headerless tab delimited file with the following format code concept name parents synonyms definition display name concept status semantic type Next use the general file loader to load the NCIt terms node bin/loadFile ncit Thesaurus.txt FDA Cross Mapping File \u00b6 Now download the FDA cross-mapping reference file wget https://evs.nci.nih.gov/ftp1/FDA/UNII/FDA-UNII_NCIt_Subsets.txt Then, after you have loaded the FDA-SRS data (if you are planning to load it) load the cross-reference mapping data node bin/loadFile ncitFdaXref FDA-UNII_NCIt_Subsets.txt","title":"NCI Thesaurus"},{"location":"graphkb/_pori_graphkb_loader/src/ncit/#nci-thesaurus","text":"First download the latest version of the plain text tab delimited files. This should include both the main thesaurus file and the cross mapping file Load the Main Flat File FDA Cross Mapping File","title":"NCI Thesaurus"},{"location":"graphkb/_pori_graphkb_loader/src/ncit/#load-the-main-flat-file","text":"Download the file wget https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/Thesaurus.FLAT.zip unzip Thesaurus.FLAT.zip rm Thesaurus.FLAT.zip This is a headerless tab delimited file with the following format code concept name parents synonyms definition display name concept status semantic type Next use the general file loader to load the NCIt terms node bin/loadFile ncit Thesaurus.txt","title":"Load the Main Flat File"},{"location":"graphkb/_pori_graphkb_loader/src/ncit/#fda-cross-mapping-file","text":"Now download the FDA cross-mapping reference file wget https://evs.nci.nih.gov/ftp1/FDA/UNII/FDA-UNII_NCIt_Subsets.txt Then, after you have loaded the FDA-SRS data (if you are planning to load it) load the cross-reference mapping data node bin/loadFile ncitFdaXref FDA-UNII_NCIt_Subsets.txt","title":"FDA Cross Mapping File"},{"location":"graphkb/_pori_graphkb_loader/src/oncokb/","text":"OncoKB \u00b6 This is a deprecated loader as OncoKB content is no longer openly available. This loader was written for the previously available JSON files and for comparison purposes.","title":"OncoKB"},{"location":"graphkb/_pori_graphkb_loader/src/oncokb/#oncokb","text":"This is a deprecated loader as OncoKB content is no longer openly available. This loader was written for the previously available JSON files and for comparison purposes.","title":"OncoKB"},{"location":"graphkb/_pori_graphkb_loader/src/oncotree/","text":"OncoTree \u00b6 OncoTree is a well-connected minimal Ontology of Cancers which can be found here . This can be loaded into GraphKB via the API. By default it will load all available versions and set terms lost from one version to the next as deprecated. node bin/load.js api oncotree This resource contains cross-reference mappings to NCIt so it preferred to load after loading NCIt","title":"OncoTree"},{"location":"graphkb/_pori_graphkb_loader/src/oncotree/#oncotree","text":"OncoTree is a well-connected minimal Ontology of Cancers which can be found here . This can be loaded into GraphKB via the API. By default it will load all available versions and set terms lost from one version to the next as deprecated. node bin/load.js api oncotree This resource contains cross-reference mappings to NCIt so it preferred to load after loading NCIt","title":"OncoTree"},{"location":"graphkb/_pori_graphkb_loader/src/ontology/","text":"General Ontology file (JSON) \u00b6 Any ontology can be uploaded (for a single record class) as long as the JSON file is in the expected custom GraphKB JSON format as detailed. There are a number of examples included by default in this repository GraphKB General Vocabulary Molecular Signatures Basic Chromosomes Cross-KB Evidence Levels The file should have a source definition. This must contain at least a name, but may optionally include any of the attributes expected for a source definition (ex. description, url, usage). { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } } } The class of records this ontology belongs to must also be defined. { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } }, \"class\" : \"Publication\" } The last top level attribute is the records. This must be an object. The keys will be used as the record sourceId if an explicit sourceId is not given. { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } }, \"class\" : \"Publication\" , \"records\" : { \"<key1>\" : {}, \"<key1>\" : {} } } Each record will then define the properties of each ontology term. { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } }, \"class\" : \"Publication\" , \"records\" : { \"19584866\" : { \"name\" : \"a small molecule blocking oncogenic protein ews-fli1 interaction with rna helicase a inhibits growth of ewing's sarcoma.\" , \"year\" : \"2009\" , \"journalName\" : \"nature medicine\" } } } Links within the ontology can also be defined. These are given via a property on the ontology term { \"name\" : \"a small molecule blocking oncogenic protein ews-fli1 interaction with rna helicase a inhibits growth of ewing's sarcoma.\" , \"links\" : [ { \"class\" : \"<Relationship type>\" , \"target\" : \"<key of another term>\" } ] } Once this file has been built it can be loaded as follows. The script will create records if they do not already exist. Any conflicts will be reported in the logging node bin/ontology.js --filename /path/to/json/file","title":"General Ontology file (JSON)"},{"location":"graphkb/_pori_graphkb_loader/src/ontology/#general-ontology-file-json","text":"Any ontology can be uploaded (for a single record class) as long as the JSON file is in the expected custom GraphKB JSON format as detailed. There are a number of examples included by default in this repository GraphKB General Vocabulary Molecular Signatures Basic Chromosomes Cross-KB Evidence Levels The file should have a source definition. This must contain at least a name, but may optionally include any of the attributes expected for a source definition (ex. description, url, usage). { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } } } The class of records this ontology belongs to must also be defined. { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } }, \"class\" : \"Publication\" } The last top level attribute is the records. This must be an object. The keys will be used as the record sourceId if an explicit sourceId is not given. { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } }, \"class\" : \"Publication\" , \"records\" : { \"<key1>\" : {}, \"<key1>\" : {} } } Each record will then define the properties of each ontology term. { \"sources\" : { \"default\" : { \"name\" : \"pubmed\" } }, \"class\" : \"Publication\" , \"records\" : { \"19584866\" : { \"name\" : \"a small molecule blocking oncogenic protein ews-fli1 interaction with rna helicase a inhibits growth of ewing's sarcoma.\" , \"year\" : \"2009\" , \"journalName\" : \"nature medicine\" } } } Links within the ontology can also be defined. These are given via a property on the ontology term { \"name\" : \"a small molecule blocking oncogenic protein ews-fli1 interaction with rna helicase a inhibits growth of ewing's sarcoma.\" , \"links\" : [ { \"class\" : \"<Relationship type>\" , \"target\" : \"<key of another term>\" } ] } Once this file has been built it can be loaded as follows. The script will create records if they do not already exist. Any conflicts will be reported in the logging node bin/ontology.js --filename /path/to/json/file","title":"General Ontology file (JSON)"},{"location":"graphkb/_pori_graphkb_loader/src/refseq/","text":"RefSeq \u00b6 In general this data will be fetched as-needed by other loaders. However if you would like the transcripts to be back-filled to support auto-complete by users entering variants through the GraphKB client, it is sometimes useful to batch load these. To complete a batch load you will first need to download the data wget -O LRG_RefSeqGene.tab ftp://ftp.ncbi.nih.gov/refseq/H_sapiens/RefSeqGene/LRG_RefSeqGene This can then be loaded with the general file loader node bin/load.js file refseq LRG_RefSeqGene.tab","title":"RefSeq"},{"location":"graphkb/_pori_graphkb_loader/src/refseq/#refseq","text":"In general this data will be fetched as-needed by other loaders. However if you would like the transcripts to be back-filled to support auto-complete by users entering variants through the GraphKB client, it is sometimes useful to batch load these. To complete a batch load you will first need to download the data wget -O LRG_RefSeqGene.tab ftp://ftp.ncbi.nih.gov/refseq/H_sapiens/RefSeqGene/LRG_RefSeqGene This can then be loaded with the general file loader node bin/load.js file refseq LRG_RefSeqGene.tab","title":"RefSeq"},{"location":"graphkb/_pori_graphkb_loader/src/uberon/","text":"Uberon \u00b6 Loads the Uberon anantomy ontology. First download the data # get the list of releases as index.html wget http://purl.obolibrary.org/obo/uberon/releases/ # figure out which is the latest release RELEASE = $( grep li index.html | tail -n 1 | grep -P '\\d+-\\d\\d-\\d\\d' -o | head -n 1 ) # clean up the index.html file rm index.html # Fetch the latest release wget http://purl.obolibrary.org/obo/uberon/releases/ $RELEASE /uberon.owl mv uberon.owl uberon_v ${ RELEASE } .owl Then load the terms into GraphKB This resource contains cross-reference mappings to NCIt so it preferred to load after loading NCIt node bin/load.js file uberon uberon_v*.owl","title":"Uberon"},{"location":"graphkb/_pori_graphkb_loader/src/uberon/#uberon","text":"Loads the Uberon anantomy ontology. First download the data # get the list of releases as index.html wget http://purl.obolibrary.org/obo/uberon/releases/ # figure out which is the latest release RELEASE = $( grep li index.html | tail -n 1 | grep -P '\\d+-\\d\\d-\\d\\d' -o | head -n 1 ) # clean up the index.html file rm index.html # Fetch the latest release wget http://purl.obolibrary.org/obo/uberon/releases/ $RELEASE /uberon.owl mv uberon.owl uberon_v ${ RELEASE } .owl Then load the terms into GraphKB This resource contains cross-reference mappings to NCIt so it preferred to load after loading NCIt node bin/load.js file uberon uberon_v*.owl","title":"Uberon"},{"location":"graphkb/_pori_graphkb_loader/src/variants/","text":"Variant Loader \u00b6 This loads a list of variants into GraphKB based on an input string representation of the variant which should use the standard syntax implemented by GraphKB (extended HGVS). This is a convenience loader and is therefore a simplified version. All features are assumed to be Entrez gene names and all variants are assumed to follow standard GraphKB syntax. All variants must be positional variants. The input is a headerless plain text file where each line is a variant representation. For example KRAS:p.G12D KRAS:p.G12C KRAS:p.G12_G13insK KRAS:p.G13delG Would be the input to load the 4 KRAS variants above into GraphKB as positional variant records. The above file would be loaded by the following command node bin/load.js file variant input.txt","title":"Variant Loader"},{"location":"graphkb/_pori_graphkb_loader/src/variants/#variant-loader","text":"This loads a list of variants into GraphKB based on an input string representation of the variant which should use the standard syntax implemented by GraphKB (extended HGVS). This is a convenience loader and is therefore a simplified version. All features are assumed to be Entrez gene names and all variants are assumed to follow standard GraphKB syntax. All variants must be positional variants. The input is a headerless plain text file where each line is a variant representation. For example KRAS:p.G12D KRAS:p.G12C KRAS:p.G12_G13insK KRAS:p.G13delG Would be the input to load the 4 KRAS variants above into GraphKB as positional variant records. The above file would be loaded by the following command node bin/load.js file variant input.txt","title":"Variant Loader"},{"location":"graphkb/matching/","text":"Ontology Algorithm \u00b6 The matching algorithm implemented by this adapter heavily uses the Graph Structure of GraphKB to resolve aliases, generalisms, etc. The default behaviour of this algorithm is described below and shown in the related examples. This is primarily accomplished via the similarTo query type provided by the GraphKB API. This algorithm can be viewed interactively in GraphKB via the matching section of the about pages Definitions \u00b6 The entire knowledge base is defined as the graph, \\(G = (V, E)\\) . For any given query let the subgraph of \\(G\\) containing only vertices of the class type specified in the query (ex. Disease) be, \\(V_t\\) . All edges between these vertices are then categorized into two disjoint sets: synonym-like ( \\(E_{syn}\\) ) or inheritance-like ( \\(E_{inh}\\) ). By default the synonym-like edges are: GeneralizationOf, AliasOf, CrossReferenceOf, DeprecatedBy, and Infers. Whereas the inheritance-like edges are: SubClassOf, and ElementOf. Edge Groups are Configurable These are the default division of Edges. However, classes used for the edge sets can be configured in the query body of similarTo type queries sent to GraphKB Synonym-like edges are treated as undirected and therefore the set of synonym-like edges used for the following steps can be written \\[ \\begin{equation} E_\\text{usyn} = \\bigcup_{uv \\in E_\\text{syn}} \\{uv,vu\\} \\end{equation} \\] Disease matching on the following graph will be used as a running example Match by Name \u00b6 Let the set of vertices (from \\(V_t\\) ) where the name attribute is an exact match to the input query name be \\(V_m\\) . Resolve Aliases \u00b6 Follow synonym-like edges from the set of name-matched vertices Let \\(P(v_0,v,E)\\) be the set of vertices that forms a path from vertex \\(v_0\\) to \\(v\\) along the edges in \\(E\\) and in their direction. If no such path exists, then \\(P = \\emptyset\\) . The set of vertices that resolve aliases in the query are formed by including all paths from \\(v_0 \\in V_\\text{m}\\) along the \\(E_\\text{usyn}\\) edges. \\[ \\begin{equation} V_\\text{syn} = V_\\text{m} \\cup \\bigcup_{v_0 \\in V_\\text{m}} \\bigcup_{ v_i \\in V_\\text{t} } P(v_0,v_i,E_\\text{usyn}) \\end{equation} \\] Follow the Inheritance-like Edges \u00b6 The inheritance-like edges are followed next. Unlike the synonym-like edges, directionality is important here. By following the inheritence-like edges in \\(E_\\text{inh}\\) from and to all vertices \\(V_\\text{syn}\\) we create the set of inheritence vertices. This is the set of vertics involved in paths which originate or terminate in a vertex perviously matched. \\[ \\begin{equation} V_\\text{inh} = V_\\text{syn} \\cup \\bigcup_{v_0 \\in V_\\text{syn}} \\bigcup_{ v_i \\in V_\\text{t} } P(v_0,v_i,E_\\text{inh}) \\cup P(v_i,v_0,E_\\text{inh}) \\end{equation} \\] Resolve Final Aliases \u00b6 Finally, we repeat the synonym-like expansion \\[ \\begin{equation} V_\\text{f} = V_\\text{inh} \\cup \\bigcup_{v_0 \\in V_\\text{inh}} \\bigcup_{ v_i \\in V_\\text{t} } P(v_0,v_i,E_\\text{usyn}) \\end{equation} \\] Bounding \u00b6 Note that the above Graph Traversals are bounded by input parameters to specify a maximum depth.","title":"Ontology Algorithm"},{"location":"graphkb/matching/#ontology-algorithm","text":"The matching algorithm implemented by this adapter heavily uses the Graph Structure of GraphKB to resolve aliases, generalisms, etc. The default behaviour of this algorithm is described below and shown in the related examples. This is primarily accomplished via the similarTo query type provided by the GraphKB API. This algorithm can be viewed interactively in GraphKB via the matching section of the about pages","title":"Ontology Algorithm"},{"location":"graphkb/matching/#definitions","text":"The entire knowledge base is defined as the graph, \\(G = (V, E)\\) . For any given query let the subgraph of \\(G\\) containing only vertices of the class type specified in the query (ex. Disease) be, \\(V_t\\) . All edges between these vertices are then categorized into two disjoint sets: synonym-like ( \\(E_{syn}\\) ) or inheritance-like ( \\(E_{inh}\\) ). By default the synonym-like edges are: GeneralizationOf, AliasOf, CrossReferenceOf, DeprecatedBy, and Infers. Whereas the inheritance-like edges are: SubClassOf, and ElementOf. Edge Groups are Configurable These are the default division of Edges. However, classes used for the edge sets can be configured in the query body of similarTo type queries sent to GraphKB Synonym-like edges are treated as undirected and therefore the set of synonym-like edges used for the following steps can be written \\[ \\begin{equation} E_\\text{usyn} = \\bigcup_{uv \\in E_\\text{syn}} \\{uv,vu\\} \\end{equation} \\] Disease matching on the following graph will be used as a running example","title":"Definitions"},{"location":"graphkb/matching/#match-by-name","text":"Let the set of vertices (from \\(V_t\\) ) where the name attribute is an exact match to the input query name be \\(V_m\\) .","title":"Match by Name"},{"location":"graphkb/matching/#resolve-aliases","text":"Follow synonym-like edges from the set of name-matched vertices Let \\(P(v_0,v,E)\\) be the set of vertices that forms a path from vertex \\(v_0\\) to \\(v\\) along the edges in \\(E\\) and in their direction. If no such path exists, then \\(P = \\emptyset\\) . The set of vertices that resolve aliases in the query are formed by including all paths from \\(v_0 \\in V_\\text{m}\\) along the \\(E_\\text{usyn}\\) edges. \\[ \\begin{equation} V_\\text{syn} = V_\\text{m} \\cup \\bigcup_{v_0 \\in V_\\text{m}} \\bigcup_{ v_i \\in V_\\text{t} } P(v_0,v_i,E_\\text{usyn}) \\end{equation} \\]","title":"Resolve Aliases"},{"location":"graphkb/matching/#follow-the-inheritance-like-edges","text":"The inheritance-like edges are followed next. Unlike the synonym-like edges, directionality is important here. By following the inheritence-like edges in \\(E_\\text{inh}\\) from and to all vertices \\(V_\\text{syn}\\) we create the set of inheritence vertices. This is the set of vertics involved in paths which originate or terminate in a vertex perviously matched. \\[ \\begin{equation} V_\\text{inh} = V_\\text{syn} \\cup \\bigcup_{v_0 \\in V_\\text{syn}} \\bigcup_{ v_i \\in V_\\text{t} } P(v_0,v_i,E_\\text{inh}) \\cup P(v_i,v_0,E_\\text{inh}) \\end{equation} \\]","title":"Follow the Inheritance-like Edges"},{"location":"graphkb/matching/#resolve-final-aliases","text":"Finally, we repeat the synonym-like expansion \\[ \\begin{equation} V_\\text{f} = V_\\text{inh} \\cup \\bigcup_{v_0 \\in V_\\text{inh}} \\bigcup_{ v_i \\in V_\\text{t} } P(v_0,v_i,E_\\text{usyn}) \\end{equation} \\]","title":"Resolve Final Aliases"},{"location":"graphkb/matching/#bounding","text":"Note that the above Graph Traversals are bounded by input parameters to specify a maximum depth.","title":"Bounding"},{"location":"graphkb/matching/gene/","text":"Gene Example \u00b6 The get_equivalent_features() method is used to find genes equivalent to the input/target feature. from graphkb.match import get_equivalent_features genes = get_equivalent_features ( graphkb_conn , 'KRAS' ) This will use a similar algorithm to what we have seen above in the disease matching example. In the graph above the relationship types shown are: GeneralizationOf (G), ElementOf (E), DeprecatedBy (D), and CrossReferenceOf (X). Match by Name \u00b6 As before, the first thing done is to match the input name Resolve Aliases \u00b6 The next step is to resolve equivalent names of the current set of terms. Follow the Elements Tree \u00b6 The next step is to follow the element relationships. This is treated the same as the subclassing except now our \"tree edge\" is the ElementOf relationship type. Resolve Final Aliases \u00b6 Finally we expand the current set of terms by alias terms again to capture aliases of the more general parent and more specific child terms expanded in the previous step. We have now collected all of the different terms for KRAS","title":"Gene Example"},{"location":"graphkb/matching/gene/#gene-example","text":"The get_equivalent_features() method is used to find genes equivalent to the input/target feature. from graphkb.match import get_equivalent_features genes = get_equivalent_features ( graphkb_conn , 'KRAS' ) This will use a similar algorithm to what we have seen above in the disease matching example. In the graph above the relationship types shown are: GeneralizationOf (G), ElementOf (E), DeprecatedBy (D), and CrossReferenceOf (X).","title":"Gene Example"},{"location":"graphkb/matching/gene/#match-by-name","text":"As before, the first thing done is to match the input name","title":"Match by Name"},{"location":"graphkb/matching/gene/#resolve-aliases","text":"The next step is to resolve equivalent names of the current set of terms.","title":"Resolve Aliases"},{"location":"graphkb/matching/gene/#follow-the-elements-tree","text":"The next step is to follow the element relationships. This is treated the same as the subclassing except now our \"tree edge\" is the ElementOf relationship type.","title":"Follow the Elements Tree"},{"location":"graphkb/matching/gene/#resolve-final-aliases","text":"Finally we expand the current set of terms by alias terms again to capture aliases of the more general parent and more specific child terms expanded in the previous step. We have now collected all of the different terms for KRAS","title":"Resolve Final Aliases"},{"location":"graphkb/scripting/","text":"About the Python Adapter \u00b6 The GraphKB python adapter is a python package to facilitate interacting with the GraphKB API. The openapi specification can be found at /api/spec . The client also contains documentation on the background and features of GraphKB. This adapter adds functions for common queries as well as for paginating and authenticating Tutorials \u00b6 There are a number of available tutorials in this space which cover using GraphKB for annotation via the python adapter. Introductory Tutorial Query Basics Annotate a VCF Annotate SnpSift Output Annotate a List of Variants","title":"About the Python Adapter"},{"location":"graphkb/scripting/#about-the-python-adapter","text":"The GraphKB python adapter is a python package to facilitate interacting with the GraphKB API. The openapi specification can be found at /api/spec . The client also contains documentation on the background and features of GraphKB. This adapter adds functions for common queries as well as for paginating and authenticating","title":"About the Python Adapter"},{"location":"graphkb/scripting/#tutorials","text":"There are a number of available tutorials in this space which cover using GraphKB for annotation via the python adapter. Introductory Tutorial Query Basics Annotate a VCF Annotate SnpSift Output Annotate a List of Variants","title":"Tutorials"},{"location":"graphkb/scripting/Annotate_a_VCF_with_GraphKB/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Annotate a VCF with GraphKB \u00b6 A common format for small mutations is the VCF file. There are a number of variants of this format. To help users getting started we have provided this example script of how to convert from a VCF file to the JSON format that the IPR python adapter expects. We expect users to annotate their VCF files with protein and/or cds HGVS notation prior to this. Download Files \u00b6 Install \u00b6 To do this we are going to install a couple of common python libraries. We will use pysam to read the vcf file ( Pysam - Working with VCF ). ! pip install pysam pandas seaborn graphkb Collecting pysam Downloading https://files.pythonhosted.org/packages/20/85/335857b9888f6d9a13b03a8f21b0a6228b180c361631d9d70e7be3e22163/pysam-0.16.0.1-cp37-cp37m-manylinux1_x86_64.whl (9.9MB) |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.9MB 4.3MB/s Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5) Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1) Collecting graphkb Downloading https://files.pythonhosted.org/packages/cc/34/48ec589f81fce66cc70053e666a7834c3a7f708cee9a101dfc3d90158fe6/graphkb-1.5.4-py3-none-any.whl Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9) Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1) Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5) Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2) Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1) Requirement already satisfied: typing-extensions<4,>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from graphkb) (3.7.4.3) Requirement already satisfied: requests<3,>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from graphkb) (2.23.0) Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7) Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0) Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1) Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (1.24.3) Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2.10) Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2021.5.30) Installing collected packages: pysam, graphkb Successfully installed graphkb-1.5.4 pysam-0.16.0.1 Prepare Canonical Transcripts List \u00b6 First we will read the tabbed biomart export file. This contains a list of gene and transcript IDs for only canonical transcripts. We'll use this to filter annotations in a later step import pandas as pd mart_df = pd . read_csv ( 'https://raw.githubusercontent.com/bcgsc/pori/feature/colab-notebooks/demo/mart_export.protein_coding.canonical.txt' , sep = ' \\t ' ) mart_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Gene stable ID version Transcript stable ID version 0 ENSG00000198888.2 ENST00000361390.2 1 ENSG00000198763.3 ENST00000361453.3 2 ENSG00000198804.2 ENST00000361624.2 3 ENSG00000198712.1 ENST00000361739.1 4 ENSG00000228253.1 ENST00000361851.1 ... ... ... 22791 ENSG00000181817.6 ENST00000315732.3 22792 ENSG00000116885.18 ENST00000235532.9 22793 ENSG00000116898.12 ENST00000373116.6 22794 ENSG00000119535.18 ENST00000373106.6 22795 ENSG00000142694.7 ENST00000490466.2 22796 rows \u00d7 2 columns In this case we know that the transcripts in our VCF are unversioned so we will store the transcript names without their versions as well for quick access in later steps mart_df [ 'unversioned' ] = mart_df [ 'Transcript stable ID version' ] . str . split ( '.' ) . str [ 0 ] canonical_transcripts = set ( mart_df [ 'Transcript stable ID version' ] . unique () . tolist () + mart_df [ 'unversioned' ] . unique () . tolist ()) len ( canonical_transcripts ) 45592 Process the VCF \u00b6 Then we are ready to read the VCF file as input ! wget https : // raw . githubusercontent . com / bcgsc / pori / feature / colab - notebooks / demo / example_snvs . variants . passed .4.3 . eff . hgvs . vcf --2021-06-17 20:42:11-- https://raw.githubusercontent.com/bcgsc/pori/feature/colab-notebooks/demo/example_snvs.variants.passed.4.3.eff.hgvs.vcf Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 387417 (378K) [text/plain] Saving to: \u2018example_snvs.variants.passed.4.3.eff.hgvs.vcf.1\u2019 example_snvs.varian 100%[===================>] 378.34K --.-KB/s in 0.04s 2021-06-17 20:42:12 (8.94 MB/s) - \u2018example_snvs.variants.passed.4.3.eff.hgvs.vcf.1\u2019 saved [387417/387417] from pysam import VariantFile fh = VariantFile ( '/content/example_snvs.variants.passed.4.3.eff.hgvs.vcf' ) Then we will iterate over the variant VCF records. From here we will need to pull out the HGVSp notation. Since this is output from SnpEff we can refer to their documentation for how to parse this. According to their site this is the expected format of the EFF field which contains the HGVS notation. This field is pipe delimited inside parentheses. EFF= Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_Change| Amino_Acid_Length | Gene_Name | Transcript_BioType | Gene_Coding | Transcript_ID | Exon_Rank | Genotype_Number [ | ERRORS | WARNINGS ] ) Note : EFF is a deprecated field. Newer versions use the ANN field. Parsing should be similar. We define the following functions below to help with parsing the INFO fields in the VCF import re def parse_eff ( eff ): match = re . match ( r '^[^(]+\\((.+)\\)$' , eff ) if match : [ impact , functional_class , codon_change , aa_change , _ , gene_name , transcript_biotype , gene_coding , transcript_id , _ , genotype_allele ] = match . group ( 1 ) . split ( '|' )[: 11 ] changes = aa_change . split ( '/' ) protein_changes = [ p for p in changes if p . startswith ( 'p.' )] cds_changes = [ p for p in changes if p . startswith ( 'c.' )] return [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_changes [ 0 ] if protein_changes else None , cds_changes [ 0 ] if cds_changes else None , genotype_allele ] raise NotImplementedError ( 'cannot parse eff string. Does not match the expected pattern' ) Now we want to convert the parsed content into a JSON/Dict to match the fields that we expect in IPR. If you are not uploading to IPR you can leave variants in their original format instead. Note : Some of the fields (support counts) require picking the samples. By default we have assumed the names are NORMAL and TUMOR. These may need to be customized for other input from graphkb.util import convert_aa_3to1 def pick_effect ( record ): non_canonical = [] for eff in record . info [ 'EFF' ]: [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ] = parse_eff ( eff ) # prefer canonical annotation if transcript_id in canonical_transcripts : return [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ] non_canonical . append ([ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ]) return non_canonical [ 0 ] ipr_variants = [] for record in fh . fetch (): tumour_sample = get_sample_by_name ( record , 'TUMOR' ) normal_sample = record . samples [ 'NORMAL' ] ref_key = f ' { record . ref } U' no_canonical = True [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ] = pick_effect ( record ) alt_key = f ' { alt_allele } U' if protein_change : protein_change = convert_aa_3to1 ( protein_change ) # convert variant string from 3 to 1 letter AA if it is protein notation ipr_format = { 'gene' : gene_name , 'transcript' : transcript_id , 'chromosome' : record . chrom , 'startPosition' : record . pos , 'endPosition' : record . pos + record . rlen , 'proteinChange' : protein_change or cds_change , # if no protein change use cds here instead 'refSeq' : record . ref , 'altSeq' : alt_allele , 'tumourDepth' : tumour_sample [ 'DP' ], 'normalDepth' : normal_sample [ 'DP' ], 'normalRefCount' : normal_sample [ ref_key ], 'normalAltCount' : normal_sample [ alt_key ], 'tumourRefCount' : tumour_sample [ ref_key ], 'tumourAltCount' : tumour_sample [ alt_key ], 'hgvsProtein' : f ' { gene_name } : { protein_change } ' if protein_change else '' , 'hgvsCds' : f ' { transcript_id } : { cds_change } ' if cds_change else '' } ipr_variants . append ( ipr_format ) # just for displaying in notebook variants_df = pd . DataFrame . from_records ( ipr_variants ) variants_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene transcript chromosome startPosition endPosition proteinChange refSeq altSeq tumourDepth normalDepth normalRefCount normalAltCount tumourRefCount tumourAltCount hgvsProtein hgvsCds 0 NOC2L ENST00000327044 1 883516 883517 p.L552L G A 69 44 (42, 45) (0, 0) (16, 16) (53, 56) NOC2L:p.L552L ENST00000327044:c.1654C>T 1 ATAD3B ENST00000378741 1 1418472 1418473 p.R114* A T 41 33 (31, 33) (0, 0) (29, 34) (10, 14) ATAD3B:p.R114* ENST00000378741:c.340A>T 2 PRDM16 ENST00000270722 1 3329312 3329313 p.P851S C T 52 49 (47, 49) (2, 2) (40, 44) (10, 10) PRDM16:p.P851S ENST00000270722:c.2551C>T 3 TNFRSF8 ENST00000263932 1 12170228 12170229 p.P215S C T 57 26 (24, 27) (0, 1) (12, 12) (43, 44) TNFRSF8:p.P215S ENST00000263932:c.643C>T 4 CLCNKB ENST00000375679 1 16372084 16372085 p.F44F C T 70 51 (51, 52) (0, 0) (50, 51) (18, 19) CLCNKB:p.F44F ENST00000375679:c.132C>T ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 410 ZNF280C ENST00000370978 X 129362963 129362964 p.H379Y G A 40 19 (19, 21) (0, 0) (0, 0) (39, 42) ZNF280C:p.H379Y ENST00000370978:c.1135C>T 411 ZNF280C ENST00000370978 X 129362964 129362965 p.P378P G A 40 19 (19, 21) (0, 0) (0, 1) (39, 41) ZNF280C:p.P378P ENST00000370978:c.1134C>T 412 PNMA3 ENST00000370264 X 152226437 152226438 p.P342L C T 60 28 (28, 32) (0, 0) (0, 1) (57, 61) PNMA3:p.P342L ENST00000370264:c.1025C>T 413 WASH6P ENST00000359512 X 155253820 155253821 p.G373S G A 74 40 (39, 59) (0, 1) (61, 114) (9, 20) WASH6P:p.G373S ENST00000359512:c.1117G>A 414 AC134882.1 ENST00000331172 Y 13524548 13524549 p.Y57S T G 15 15 (13, 13) (2, 3) (0, 0) (14, 26) AC134882.1:p.Y57S ENST00000331172:c.170A>C 415 rows \u00d7 16 columns Annotate \u00b6 Now we are ready to add GraphKB annotations. First connect to the API. Here we are using the demo credentials. If you were uploading to IPR you would skip this step and just input the variants. The IPR python adapter performs matching against GraphKB prior to uploading the report. NOTE : The demo server is incomplete. It contains a small subset of the data we would expect in a normal production instance of GraphKB and should be used for demonstration and testing only from graphkb import GraphKBConnection GKB_API_URL = 'https://pori-demo.bcgsc.ca/graphkb-api/api' GKB_USER = 'colab_demo' GKB_PASSWORD = 'colab_demo' graphkb_conn = GraphKBConnection ( GKB_API_URL , use_global_cache = False ) graphkb_conn . login ( GKB_USER , GKB_PASSWORD ) Now use the matching functions to get the equivalent variant forms from GraphKB. This may take several minutes on the demo server as it has limited resources and open access. from graphkb.match import match_positional_variant from graphkb.util import FeatureNotFoundError for variant in ipr_variants : # for the purposes of this tutorial we will skip non-protein changes for now if not variant [ 'hgvsProtein' ]: continue variant_name = variant [ 'gene' ] + ':' + variant [ 'proteinChange' ] try : variant_matches = match_positional_variant ( graphkb_conn , variant_name ) variant [ '_variantMatches' ] = variant_matches if variant_matches : print ( f ' { variant_name } matched { len ( variant_matches ) } other variant representations' ) except FeatureNotFoundError : pass # if the gene isn't in the db, there will not be annotations except Exception as err : print ( variant_name , err ) print ( f 'queried { len ( ipr_variants ) } variants' ) SF3B1:p.P718L matched 1 other variant representations STK19:p.D89N matched 2 other variant representations BRAF:p.V600E matched 6 other variant representations queried 415 variants Now that we have matched the variant we will fetch the related statements to annotate this variant with its possible relevance from graphkb.constants import BASE_RETURN_PROPERTIES , GENERIC_RETURN_PROPERTIES from graphkb.util import convert_to_rid_list # return properties should be customized to the users needs return_props = ( BASE_RETURN_PROPERTIES + [ 'sourceId' , 'source.name' , 'source.displayName' ] + [ f 'conditions. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'subject. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidence. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'relevance. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidenceLevel. { p } ' for p in GENERIC_RETURN_PROPERTIES ] ) results = [] for variant in ipr_variants : if not variant . get ( '_variantMatches' ): continue variant_name = variant [ 'gene' ] + ':' + variant [ 'proteinChange' ] variant_matches = variant [ '_variantMatches' ] statements = graphkb_conn . query ( { 'target' : 'Statement' , 'filters' : { 'conditions' : convert_to_rid_list ( variant_matches ), 'operator' : 'CONTAINSANY' }, 'returnProperties' : return_props , } ) print ( variant_name ) print ( f 'annotated { len ( variant_matches ) } variant matches with { len ( statements ) } statements' ) print () for statement in statements : results . append (( variant_name , len ( variant_matches ), ';' . join ([ c [ 'displayName' ] for c in statement [ 'conditions' ] if c [ '@class' ] . endswith ( 'Variant' )]), statement [ 'relevance' ][ 'displayName' ], statement [ 'subject' ][ 'displayName' ], statement [ 'source' ][ 'displayName' ] if statement [ 'source' ] else '' , ';' . join ([ c [ 'displayName' ] for c in statement [ 'evidence' ]]) )) SF3B1:p.P718L annotated 1 variant matches with 5 statements STK19:p.D89N annotated 2 variant matches with 2 statements BRAF:p.V600E annotated 6 variant matches with 135 statements Now we will put this into a dataframe to display nicely in this notebook df = pd . DataFrame ( results , columns = [ 'variant_name' , 'variant_matches' , 'statement_variants' , 'relevance' , 'subject' , 'statement_source' , 'evidence' ]) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variant_name variant_matches statement_variants relevance subject statement_source evidence 0 SF3B1:p.P718L 1 SF3B1 mutation favourable prognosis patient CIViC pmid:21995386 1 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:26837699 2 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:24943832 3 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:23086750 4 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:23568491 ... ... ... ... ... ... ... ... 137 BRAF:p.V600E 6 BRAF mutation resistance Irinotecan [c62040] CIViC pmid:19603024 138 BRAF:p.V600E 6 BRAF mutation resistance Oxaliplatin [c1181] CIViC pmid:19603024 139 BRAF:p.V600E 6 BRAF mutation unfavourable prognosis patient CIViC pmid:19603024 140 BRAF:p.V600E 6 BRAF mutation resistance cetuximab + chemotherapy CIViC pmid:20619739 141 BRAF:p.V600E 6 BRAF mutation resistance Cetuximab [c1723] CIViC pmid:22586653 142 rows \u00d7 7 columns","title":"Annotate a VCF with GraphKB"},{"location":"graphkb/scripting/Annotate_a_VCF_with_GraphKB/#annotate-a-vcf-with-graphkb","text":"A common format for small mutations is the VCF file. There are a number of variants of this format. To help users getting started we have provided this example script of how to convert from a VCF file to the JSON format that the IPR python adapter expects. We expect users to annotate their VCF files with protein and/or cds HGVS notation prior to this.","title":"Annotate a VCF with GraphKB"},{"location":"graphkb/scripting/Annotate_a_VCF_with_GraphKB/#download-files","text":"","title":"Download Files"},{"location":"graphkb/scripting/Annotate_a_VCF_with_GraphKB/#install","text":"To do this we are going to install a couple of common python libraries. We will use pysam to read the vcf file ( Pysam - Working with VCF ). ! pip install pysam pandas seaborn graphkb Collecting pysam Downloading https://files.pythonhosted.org/packages/20/85/335857b9888f6d9a13b03a8f21b0a6228b180c361631d9d70e7be3e22163/pysam-0.16.0.1-cp37-cp37m-manylinux1_x86_64.whl (9.9MB) |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.9MB 4.3MB/s Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5) Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1) Collecting graphkb Downloading https://files.pythonhosted.org/packages/cc/34/48ec589f81fce66cc70053e666a7834c3a7f708cee9a101dfc3d90158fe6/graphkb-1.5.4-py3-none-any.whl Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9) Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1) Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5) Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2) Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1) Requirement already satisfied: typing-extensions<4,>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from graphkb) (3.7.4.3) Requirement already satisfied: requests<3,>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from graphkb) (2.23.0) Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7) Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0) Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1) Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (1.24.3) Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2.10) Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2021.5.30) Installing collected packages: pysam, graphkb Successfully installed graphkb-1.5.4 pysam-0.16.0.1","title":"Install"},{"location":"graphkb/scripting/Annotate_a_VCF_with_GraphKB/#prepare-canonical-transcripts-list","text":"First we will read the tabbed biomart export file. This contains a list of gene and transcript IDs for only canonical transcripts. We'll use this to filter annotations in a later step import pandas as pd mart_df = pd . read_csv ( 'https://raw.githubusercontent.com/bcgsc/pori/feature/colab-notebooks/demo/mart_export.protein_coding.canonical.txt' , sep = ' \\t ' ) mart_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Gene stable ID version Transcript stable ID version 0 ENSG00000198888.2 ENST00000361390.2 1 ENSG00000198763.3 ENST00000361453.3 2 ENSG00000198804.2 ENST00000361624.2 3 ENSG00000198712.1 ENST00000361739.1 4 ENSG00000228253.1 ENST00000361851.1 ... ... ... 22791 ENSG00000181817.6 ENST00000315732.3 22792 ENSG00000116885.18 ENST00000235532.9 22793 ENSG00000116898.12 ENST00000373116.6 22794 ENSG00000119535.18 ENST00000373106.6 22795 ENSG00000142694.7 ENST00000490466.2 22796 rows \u00d7 2 columns In this case we know that the transcripts in our VCF are unversioned so we will store the transcript names without their versions as well for quick access in later steps mart_df [ 'unversioned' ] = mart_df [ 'Transcript stable ID version' ] . str . split ( '.' ) . str [ 0 ] canonical_transcripts = set ( mart_df [ 'Transcript stable ID version' ] . unique () . tolist () + mart_df [ 'unversioned' ] . unique () . tolist ()) len ( canonical_transcripts ) 45592","title":"Prepare Canonical Transcripts List"},{"location":"graphkb/scripting/Annotate_a_VCF_with_GraphKB/#process-the-vcf","text":"Then we are ready to read the VCF file as input ! wget https : // raw . githubusercontent . com / bcgsc / pori / feature / colab - notebooks / demo / example_snvs . variants . passed .4.3 . eff . hgvs . vcf --2021-06-17 20:42:11-- https://raw.githubusercontent.com/bcgsc/pori/feature/colab-notebooks/demo/example_snvs.variants.passed.4.3.eff.hgvs.vcf Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 387417 (378K) [text/plain] Saving to: \u2018example_snvs.variants.passed.4.3.eff.hgvs.vcf.1\u2019 example_snvs.varian 100%[===================>] 378.34K --.-KB/s in 0.04s 2021-06-17 20:42:12 (8.94 MB/s) - \u2018example_snvs.variants.passed.4.3.eff.hgvs.vcf.1\u2019 saved [387417/387417] from pysam import VariantFile fh = VariantFile ( '/content/example_snvs.variants.passed.4.3.eff.hgvs.vcf' ) Then we will iterate over the variant VCF records. From here we will need to pull out the HGVSp notation. Since this is output from SnpEff we can refer to their documentation for how to parse this. According to their site this is the expected format of the EFF field which contains the HGVS notation. This field is pipe delimited inside parentheses. EFF= Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_Change| Amino_Acid_Length | Gene_Name | Transcript_BioType | Gene_Coding | Transcript_ID | Exon_Rank | Genotype_Number [ | ERRORS | WARNINGS ] ) Note : EFF is a deprecated field. Newer versions use the ANN field. Parsing should be similar. We define the following functions below to help with parsing the INFO fields in the VCF import re def parse_eff ( eff ): match = re . match ( r '^[^(]+\\((.+)\\)$' , eff ) if match : [ impact , functional_class , codon_change , aa_change , _ , gene_name , transcript_biotype , gene_coding , transcript_id , _ , genotype_allele ] = match . group ( 1 ) . split ( '|' )[: 11 ] changes = aa_change . split ( '/' ) protein_changes = [ p for p in changes if p . startswith ( 'p.' )] cds_changes = [ p for p in changes if p . startswith ( 'c.' )] return [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_changes [ 0 ] if protein_changes else None , cds_changes [ 0 ] if cds_changes else None , genotype_allele ] raise NotImplementedError ( 'cannot parse eff string. Does not match the expected pattern' ) Now we want to convert the parsed content into a JSON/Dict to match the fields that we expect in IPR. If you are not uploading to IPR you can leave variants in their original format instead. Note : Some of the fields (support counts) require picking the samples. By default we have assumed the names are NORMAL and TUMOR. These may need to be customized for other input from graphkb.util import convert_aa_3to1 def pick_effect ( record ): non_canonical = [] for eff in record . info [ 'EFF' ]: [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ] = parse_eff ( eff ) # prefer canonical annotation if transcript_id in canonical_transcripts : return [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ] non_canonical . append ([ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ]) return non_canonical [ 0 ] ipr_variants = [] for record in fh . fetch (): tumour_sample = get_sample_by_name ( record , 'TUMOR' ) normal_sample = record . samples [ 'NORMAL' ] ref_key = f ' { record . ref } U' no_canonical = True [ impact , gene_name , transcript_biotype , gene_coding , transcript_id , protein_change , cds_change , alt_allele ] = pick_effect ( record ) alt_key = f ' { alt_allele } U' if protein_change : protein_change = convert_aa_3to1 ( protein_change ) # convert variant string from 3 to 1 letter AA if it is protein notation ipr_format = { 'gene' : gene_name , 'transcript' : transcript_id , 'chromosome' : record . chrom , 'startPosition' : record . pos , 'endPosition' : record . pos + record . rlen , 'proteinChange' : protein_change or cds_change , # if no protein change use cds here instead 'refSeq' : record . ref , 'altSeq' : alt_allele , 'tumourDepth' : tumour_sample [ 'DP' ], 'normalDepth' : normal_sample [ 'DP' ], 'normalRefCount' : normal_sample [ ref_key ], 'normalAltCount' : normal_sample [ alt_key ], 'tumourRefCount' : tumour_sample [ ref_key ], 'tumourAltCount' : tumour_sample [ alt_key ], 'hgvsProtein' : f ' { gene_name } : { protein_change } ' if protein_change else '' , 'hgvsCds' : f ' { transcript_id } : { cds_change } ' if cds_change else '' } ipr_variants . append ( ipr_format ) # just for displaying in notebook variants_df = pd . DataFrame . from_records ( ipr_variants ) variants_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene transcript chromosome startPosition endPosition proteinChange refSeq altSeq tumourDepth normalDepth normalRefCount normalAltCount tumourRefCount tumourAltCount hgvsProtein hgvsCds 0 NOC2L ENST00000327044 1 883516 883517 p.L552L G A 69 44 (42, 45) (0, 0) (16, 16) (53, 56) NOC2L:p.L552L ENST00000327044:c.1654C>T 1 ATAD3B ENST00000378741 1 1418472 1418473 p.R114* A T 41 33 (31, 33) (0, 0) (29, 34) (10, 14) ATAD3B:p.R114* ENST00000378741:c.340A>T 2 PRDM16 ENST00000270722 1 3329312 3329313 p.P851S C T 52 49 (47, 49) (2, 2) (40, 44) (10, 10) PRDM16:p.P851S ENST00000270722:c.2551C>T 3 TNFRSF8 ENST00000263932 1 12170228 12170229 p.P215S C T 57 26 (24, 27) (0, 1) (12, 12) (43, 44) TNFRSF8:p.P215S ENST00000263932:c.643C>T 4 CLCNKB ENST00000375679 1 16372084 16372085 p.F44F C T 70 51 (51, 52) (0, 0) (50, 51) (18, 19) CLCNKB:p.F44F ENST00000375679:c.132C>T ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 410 ZNF280C ENST00000370978 X 129362963 129362964 p.H379Y G A 40 19 (19, 21) (0, 0) (0, 0) (39, 42) ZNF280C:p.H379Y ENST00000370978:c.1135C>T 411 ZNF280C ENST00000370978 X 129362964 129362965 p.P378P G A 40 19 (19, 21) (0, 0) (0, 1) (39, 41) ZNF280C:p.P378P ENST00000370978:c.1134C>T 412 PNMA3 ENST00000370264 X 152226437 152226438 p.P342L C T 60 28 (28, 32) (0, 0) (0, 1) (57, 61) PNMA3:p.P342L ENST00000370264:c.1025C>T 413 WASH6P ENST00000359512 X 155253820 155253821 p.G373S G A 74 40 (39, 59) (0, 1) (61, 114) (9, 20) WASH6P:p.G373S ENST00000359512:c.1117G>A 414 AC134882.1 ENST00000331172 Y 13524548 13524549 p.Y57S T G 15 15 (13, 13) (2, 3) (0, 0) (14, 26) AC134882.1:p.Y57S ENST00000331172:c.170A>C 415 rows \u00d7 16 columns","title":"Process the VCF"},{"location":"graphkb/scripting/Annotate_a_VCF_with_GraphKB/#annotate","text":"Now we are ready to add GraphKB annotations. First connect to the API. Here we are using the demo credentials. If you were uploading to IPR you would skip this step and just input the variants. The IPR python adapter performs matching against GraphKB prior to uploading the report. NOTE : The demo server is incomplete. It contains a small subset of the data we would expect in a normal production instance of GraphKB and should be used for demonstration and testing only from graphkb import GraphKBConnection GKB_API_URL = 'https://pori-demo.bcgsc.ca/graphkb-api/api' GKB_USER = 'colab_demo' GKB_PASSWORD = 'colab_demo' graphkb_conn = GraphKBConnection ( GKB_API_URL , use_global_cache = False ) graphkb_conn . login ( GKB_USER , GKB_PASSWORD ) Now use the matching functions to get the equivalent variant forms from GraphKB. This may take several minutes on the demo server as it has limited resources and open access. from graphkb.match import match_positional_variant from graphkb.util import FeatureNotFoundError for variant in ipr_variants : # for the purposes of this tutorial we will skip non-protein changes for now if not variant [ 'hgvsProtein' ]: continue variant_name = variant [ 'gene' ] + ':' + variant [ 'proteinChange' ] try : variant_matches = match_positional_variant ( graphkb_conn , variant_name ) variant [ '_variantMatches' ] = variant_matches if variant_matches : print ( f ' { variant_name } matched { len ( variant_matches ) } other variant representations' ) except FeatureNotFoundError : pass # if the gene isn't in the db, there will not be annotations except Exception as err : print ( variant_name , err ) print ( f 'queried { len ( ipr_variants ) } variants' ) SF3B1:p.P718L matched 1 other variant representations STK19:p.D89N matched 2 other variant representations BRAF:p.V600E matched 6 other variant representations queried 415 variants Now that we have matched the variant we will fetch the related statements to annotate this variant with its possible relevance from graphkb.constants import BASE_RETURN_PROPERTIES , GENERIC_RETURN_PROPERTIES from graphkb.util import convert_to_rid_list # return properties should be customized to the users needs return_props = ( BASE_RETURN_PROPERTIES + [ 'sourceId' , 'source.name' , 'source.displayName' ] + [ f 'conditions. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'subject. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidence. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'relevance. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidenceLevel. { p } ' for p in GENERIC_RETURN_PROPERTIES ] ) results = [] for variant in ipr_variants : if not variant . get ( '_variantMatches' ): continue variant_name = variant [ 'gene' ] + ':' + variant [ 'proteinChange' ] variant_matches = variant [ '_variantMatches' ] statements = graphkb_conn . query ( { 'target' : 'Statement' , 'filters' : { 'conditions' : convert_to_rid_list ( variant_matches ), 'operator' : 'CONTAINSANY' }, 'returnProperties' : return_props , } ) print ( variant_name ) print ( f 'annotated { len ( variant_matches ) } variant matches with { len ( statements ) } statements' ) print () for statement in statements : results . append (( variant_name , len ( variant_matches ), ';' . join ([ c [ 'displayName' ] for c in statement [ 'conditions' ] if c [ '@class' ] . endswith ( 'Variant' )]), statement [ 'relevance' ][ 'displayName' ], statement [ 'subject' ][ 'displayName' ], statement [ 'source' ][ 'displayName' ] if statement [ 'source' ] else '' , ';' . join ([ c [ 'displayName' ] for c in statement [ 'evidence' ]]) )) SF3B1:p.P718L annotated 1 variant matches with 5 statements STK19:p.D89N annotated 2 variant matches with 2 statements BRAF:p.V600E annotated 6 variant matches with 135 statements Now we will put this into a dataframe to display nicely in this notebook df = pd . DataFrame ( results , columns = [ 'variant_name' , 'variant_matches' , 'statement_variants' , 'relevance' , 'subject' , 'statement_source' , 'evidence' ]) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variant_name variant_matches statement_variants relevance subject statement_source evidence 0 SF3B1:p.P718L 1 SF3B1 mutation favourable prognosis patient CIViC pmid:21995386 1 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:26837699 2 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:24943832 3 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:23086750 4 SF3B1:p.P718L 1 SF3B1 mutation unfavourable prognosis patient CIViC pmid:23568491 ... ... ... ... ... ... ... ... 137 BRAF:p.V600E 6 BRAF mutation resistance Irinotecan [c62040] CIViC pmid:19603024 138 BRAF:p.V600E 6 BRAF mutation resistance Oxaliplatin [c1181] CIViC pmid:19603024 139 BRAF:p.V600E 6 BRAF mutation unfavourable prognosis patient CIViC pmid:19603024 140 BRAF:p.V600E 6 BRAF mutation resistance cetuximab + chemotherapy CIViC pmid:20619739 141 BRAF:p.V600E 6 BRAF mutation resistance Cetuximab [c1723] CIViC pmid:22586653 142 rows \u00d7 7 columns","title":"Annotate"},{"location":"graphkb/scripting/Intro_Tutorial/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); GraphKB Variant Matching Tutorial \u00b6 This tutorial is an interactive notebook which can be run using google colab or a local jupyter server ( recommended if matching patient data). This tutorial will cover basic matching of variants using the python GraphKB adapter against an instance of the GraphKB API. Users must first have login credentials to an instance of GraphKB API (or use the demo server). Note for users using the demo credentials and server, the data is limited and more complete annotations would be expected for a production instance of GraphKB. For the purposes of this tutorial we will be matching the known KRAS variant p.G12D to the demo instance of GraphKB. You can adjust the API instance by changing the setup variables below To run this locally, download this file and start the server from the command line as follows jupyter notebook notebook.ipynb You should now be able to see the notebook by opening http://localhost:8888 in your browser ! pip3 install graphkb Looking in indexes: https://pypi.bcgsc.ca/gsc/packages/ Requirement already satisfied: graphkb in /projects/dat/workspace/creisle/graphkb/graphkb_python (1.5.1) Requirement already satisfied: requests<3,>=2.22.0 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from graphkb) (2.22.0) Requirement already satisfied: typing_extensions<4,>=3.7.4.2 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from graphkb) (3.7.4.2) Requirement already satisfied: certifi>=2017.4.17 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (2020.4.5.1) Requirement already satisfied: idna<2.9,>=2.5 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (2.8) Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (1.25.9) WARNING: You are using pip version 19.2.3, however version 21.0.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. from graphkb import GraphKBConnection GKB_API_URL = 'https://pori-demo.bcgsc.ca/graphkb-api/api' GKB_USER = 'colab_demo' GKB_PASSWORD = 'colab_demo' graphkb_conn = GraphKBConnection ( GKB_API_URL , use_global_cache = False ) graphkb_conn . login ( GKB_USER , GKB_PASSWORD ) Matching Variants \u00b6 Now you are ready to match variants from graphkb.match import match_positional_variant variant_name = 'KRAS:p.G12D' variant_matches = match_positional_variant ( graphkb_conn , variant_name ) print ( f ' { variant_name } matched { len ( variant_matches ) } other variant representations' ) print () for match in variant_matches : print ( variant_name , 'will match' , match [ 'displayName' ]) KRAS:p.G12D matched 7 other variant representations KRAS:p.G12D will match KRAS:p.(G12_G13)mut KRAS:p.G12D will match KRAS:p.G12mut KRAS:p.G12D will match KRAS:p.G12D KRAS:p.G12D will match chr12:g.25398284C>T KRAS:p.G12D will match KRAS:p.G12 KRAS:p.G12D will match KRAS:p.?12mut KRAS:p.G12D will match KRAS mutation We can see above that the KRAS protein variant has been matched to a number of other less specific mentions (ex. KRAS:p.G12mut) and also genomic equivalents (chr12:g.25398284C>T). Note that the results here will be dependent on the instance of GraphKB you are accessing. Annotating Variants \u00b6 Now that we have matched the variant we will fetch the related statements to annotate this variant with its possible relevance from graphkb.constants import BASE_RETURN_PROPERTIES , GENERIC_RETURN_PROPERTIES from graphkb.util import convert_to_rid_list # return properties should be customized to the users needs return_props = ( BASE_RETURN_PROPERTIES + [ 'sourceId' , 'source.name' , 'source.displayName' ] + [ f 'conditions. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'subject. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidence. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'relevance. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidenceLevel. { p } ' for p in GENERIC_RETURN_PROPERTIES ] ) statements = graphkb_conn . query ( { 'target' : 'Statement' , 'filters' : { 'conditions' : convert_to_rid_list ( variant_matches ), 'operator' : 'CONTAINSANY' }, 'returnProperties' : return_props , } ) print ( f 'annotated { len ( variant_matches ) } variant matches with { len ( statements ) } statements' ) print () for statement in statements [: 5 ]: print ( [ c [ 'displayName' ] for c in statement [ 'conditions' ] if c [ '@class' ] . endswith ( 'Variant' )], statement [ 'relevance' ][ 'displayName' ], statement [ 'subject' ][ 'displayName' ], statement [ 'source' ][ 'displayName' ] if statement [ 'source' ] else '' , [ c [ 'displayName' ] for c in statement [ 'evidence' ]], ) annotated 7 variant matches with 96 statements ['KRAS:p.(G12_G13)mut'] resistance Gefitinib [c1855] CIViC ['pmid:15696205'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19603024'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:18316791'] Categorizing Statements \u00b6 Something we often want to know is if a statement is therapeutic, or prognostic, etc. The naive approach is to base this on a list of known terms or a regex pattern. In GraphKB we can leverage the ontology structure instead. In this example we will look for all terms that would indicate a therapeutically relevent statement. To do this we pick our 'base' terms. These are the terms we consider to be the highest level of the ontology tree, the most general term for that category. from graphkb.vocab import get_term_tree BASE_THERAPEUTIC_TERMS = 'therapeutic efficacy' therapeutic_terms = get_term_tree ( graphkb_conn , BASE_THERAPEUTIC_TERMS , include_superclasses = False ) print ( f 'Found { len ( therapeutic_terms ) } equivalent terms' ) for term in therapeutic_terms : print ( '-' , term [ 'name' ]) Found 13 equivalent terms - therapeutic efficacy - targetable - response - sensitivity - likely sensitivity - no sensitivity - no response - resistance - reduced sensitivity - likely resistance - innate resistance - acquired resistance - no resistance We can filter the statements we have already retrieved, or we can add this to our original query and filter before we retrive from the API statements = graphkb_conn . query ( { 'target' : 'Statement' , 'filters' : { 'AND' : [ { 'conditions' : convert_to_rid_list ( variant_matches ), 'operator' : 'CONTAINSANY' }, { 'relevance' : convert_to_rid_list ( therapeutic_terms ), 'operator' : 'IN' }, ] }, 'returnProperties' : return_props , } ) for statement in statements : print ( [ c [ 'displayName' ] for c in statement [ 'conditions' ] if c [ '@class' ] . endswith ( 'Variant' )], statement [ 'relevance' ][ 'displayName' ], statement [ 'subject' ][ 'displayName' ], statement [ 'source' ][ 'displayName' ] if statement [ 'source' ] else '' , [ c [ 'displayName' ] for c in statement [ 'evidence' ]], ) ['KRAS:p.G12mut'] response mek inhibitor [c69145] CGI ['pmid:18701506'] ['KRAS:p.G12D'] sensitivity dactolisib + selumetinib CIViC ['pmid:19029981'] ['KRAS mutation'] sensitivity Decitabine [c981] CIViC ['pmid:25968887'] ['KRAS mutation'] sensitivity Trametinib [c77908] CIViC ['pmid:22169769'] ['KRAS:p.G12D'] sensitivity Akt Inhibitor MK2206 [c90581] CIViC ['pmid:22025163'] ['KRAS mutation'] sensitivity cetuximab + dasatinib CIViC ['pmid:20956938'] ['KRAS mutation'] sensitivity b-raf/vegfr-2 inhibitor raf265 + selumetinib CIViC ['pmid:25199829'] ['KRAS mutation'] sensitivity b-raf/vegfr-2 inhibitor raf265 + selumetinib CIViC ['pmid:25199829'] ['KRAS mutation'] sensitivity afatinib + trametinib CIViC ['pmid:24685132'] ['KRAS mutation'] sensitivity afatinib + trametinib CIViC ['pmid:24685132'] ['KRAS mutation'] sensitivity docetaxel + selumetinib CIViC ['pmid:23200175'] ['KRAS mutation'] sensitivity selumetinib + teprotumumab CIViC ['pmid:21985784'] ['KRAS mutation'] sensitivity MEK Inhibitor GDC-0623 [c95738] CIViC ['pmid:23934108'] ['KRAS mutation'] sensitivity Trametinib [c77908] CIViC ['pmid:22805291'] ['KRAS mutation'] sensitivity refametinib + sorafenib CIViC ['pmid:25294897'] ['KRAS:p.G12D'] sensitivity Therapeutic Tumor Infiltrating Lymphocytes [c28699] CIViC ['pmid:27959684'] ['KRAS:p.G12D'] sensitivity dactolisib + selumetinib CIViC ['pmid:22392911'] ['KRAS mutation'] sensitivity erlotinib + teprotumumab CIViC ['pmid:22025157'] ['KRAS mutation'] sensitivity abemaciclib [c97660] CIViC ['pmid:27217383'] ['KRAS mutation'] sensitivity docetaxel + pemetrexed + trametinib CIViC ['pmid:27876675'] ['KRAS mutation'] sensitivity Atezolizumab [c106250] CIViC ['pmid:28525386'] ['KRAS mutation'] sensitivity Nivolumab [c68814] CIViC ['pmid:28525386'] ['KRAS mutation'] sensitivity Immune Checkpoint Inhibitor [c143250] CIViC ['pmid:28259530'] ['KRAS mutation'] sensitivity binimetinib + palbociclib CIViC ['pmid:27167191'] ['KRAS mutation'] sensitivity Metformin [c61612] CIViC ['pmid:32444490'] ['KRAS mutation'] sensitivity Binimetinib [c84865] CIViC ['pmid:32822286'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:18202412'] ['KRAS:p.(G12_G13)mut'] resistance cetuximab + chemotherapy CIViC ['pmid:20619739'] ['KRAS:p.(G12_G13)mut'] resistance Erlotinib [c65530] CIViC ['pmid:15696205'] ['KRAS:p.(G12_G13)mut'] resistance Gefitinib [c1855] CIViC ['pmid:15696205'] ['KRAS:p.(G12_G13)mut'] resistance gemcitabine + trametinib CIViC ['pmid:24915778'] ['KRAS mutation'] resistance bevacizumab + chemotherapy CIViC ['pmid:23828442'] ['KRAS mutation'] resistance ixazomib [c97940] CIViC ['pmid:26709701'] ['KRAS:p.G12D'] resistance Vemurafenib [c64768] CIViC ['pmid:26352686'] ['KRAS mutation'] resistance Cetuximab [c1723] CIViC ['pmid:22586653'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:18316791'] ['KRAS:p.G12D'] resistance Panitumumab [c1857] CIViC ['pmid:20619739'] ['KRAS:p.G12D'] resistance Cetuximab [c1723] CIViC ['pmid:20619739'] ['KRAS:p.G12D'] resistance Panitumumab [c1857] CIViC ['pmid:18316791'] ['KRAS:p.G12D'] resistance Gefitinib [c1855] CIViC ['pmid:17409929'] ['KRAS mutation'] resistance Erlotinib [c65530] CIViC ['pmid:22025157'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:19284554'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:11050000'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:12483530'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:16497971'] ['KRAS mutation'] resistance Erlotinib [c65530] CIViC ['pmid:21258250'] ['KRAS mutation'] resistance Gefitinib [c1855] CIViC ['pmid:21258250'] ['KRAS mutation'] resistance docetaxel + selumetinib CIViC ['pmid:28492898'] ['KRAS mutation'] resistance cetuximab + chemotherapy CIViC ['pmid:20619739'] ['KRAS mutation'] resistance Erlotinib [c65530] CIViC ['pmid:21969500'] ['KRAS:p.G12D'] resistance Regorafenib [c78204] CIViC ['pmid:26161928'] ['KRAS:p.G12D'] resistance Vemurafenib [c64768] CIViC ['pmid:24265155'] ['KRAS:p.G12D'] resistance Cetuximab [c1723] CIViC ['pmid:22246397'] ['KRAS mutation'] resistance Panitumumab [c1857] CIViC ['pmid:28275037'] ['KRAS mutation'] resistance Cetuximab [c1723] CIViC ['pmid:28275037'] ['KRAS mutation'] resistance Vemurafenib [c64768] CIViC ['pmid:24265155'] ['KRAS mutation'] resistance Dabrafenib [c82386] CIViC ['pmid:24265155'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19603024'] ['KRAS:p.G12D'] resistance Cetuximab [c1723] CIViC ['pmid:19223544'] ['KRAS:p.G12D'] resistance Panitumumab [c1857] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:19223544'] ['KRAS:p.?12mut'] resistance Cetuximab [c1723] CGI ['CGI'] ['KRAS:p.?12mut'] resistance Panitumumab [c1857] CGI ['CGI']","title":"Introductory Tutorial"},{"location":"graphkb/scripting/Intro_Tutorial/#graphkb-variant-matching-tutorial","text":"This tutorial is an interactive notebook which can be run using google colab or a local jupyter server ( recommended if matching patient data). This tutorial will cover basic matching of variants using the python GraphKB adapter against an instance of the GraphKB API. Users must first have login credentials to an instance of GraphKB API (or use the demo server). Note for users using the demo credentials and server, the data is limited and more complete annotations would be expected for a production instance of GraphKB. For the purposes of this tutorial we will be matching the known KRAS variant p.G12D to the demo instance of GraphKB. You can adjust the API instance by changing the setup variables below To run this locally, download this file and start the server from the command line as follows jupyter notebook notebook.ipynb You should now be able to see the notebook by opening http://localhost:8888 in your browser ! pip3 install graphkb Looking in indexes: https://pypi.bcgsc.ca/gsc/packages/ Requirement already satisfied: graphkb in /projects/dat/workspace/creisle/graphkb/graphkb_python (1.5.1) Requirement already satisfied: requests<3,>=2.22.0 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from graphkb) (2.22.0) Requirement already satisfied: typing_extensions<4,>=3.7.4.2 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from graphkb) (3.7.4.2) Requirement already satisfied: certifi>=2017.4.17 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (2020.4.5.1) Requirement already satisfied: idna<2.9,>=2.5 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (2.8) Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /projects/dat/workspace/creisle/graphkb/graphkb_python/venv/lib/python3.8/site-packages (from requests<3,>=2.22.0->graphkb) (1.25.9) WARNING: You are using pip version 19.2.3, however version 21.0.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. from graphkb import GraphKBConnection GKB_API_URL = 'https://pori-demo.bcgsc.ca/graphkb-api/api' GKB_USER = 'colab_demo' GKB_PASSWORD = 'colab_demo' graphkb_conn = GraphKBConnection ( GKB_API_URL , use_global_cache = False ) graphkb_conn . login ( GKB_USER , GKB_PASSWORD )","title":"GraphKB Variant Matching Tutorial"},{"location":"graphkb/scripting/Intro_Tutorial/#matching-variants","text":"Now you are ready to match variants from graphkb.match import match_positional_variant variant_name = 'KRAS:p.G12D' variant_matches = match_positional_variant ( graphkb_conn , variant_name ) print ( f ' { variant_name } matched { len ( variant_matches ) } other variant representations' ) print () for match in variant_matches : print ( variant_name , 'will match' , match [ 'displayName' ]) KRAS:p.G12D matched 7 other variant representations KRAS:p.G12D will match KRAS:p.(G12_G13)mut KRAS:p.G12D will match KRAS:p.G12mut KRAS:p.G12D will match KRAS:p.G12D KRAS:p.G12D will match chr12:g.25398284C>T KRAS:p.G12D will match KRAS:p.G12 KRAS:p.G12D will match KRAS:p.?12mut KRAS:p.G12D will match KRAS mutation We can see above that the KRAS protein variant has been matched to a number of other less specific mentions (ex. KRAS:p.G12mut) and also genomic equivalents (chr12:g.25398284C>T). Note that the results here will be dependent on the instance of GraphKB you are accessing.","title":"Matching Variants"},{"location":"graphkb/scripting/Intro_Tutorial/#annotating-variants","text":"Now that we have matched the variant we will fetch the related statements to annotate this variant with its possible relevance from graphkb.constants import BASE_RETURN_PROPERTIES , GENERIC_RETURN_PROPERTIES from graphkb.util import convert_to_rid_list # return properties should be customized to the users needs return_props = ( BASE_RETURN_PROPERTIES + [ 'sourceId' , 'source.name' , 'source.displayName' ] + [ f 'conditions. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'subject. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidence. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'relevance. { p } ' for p in GENERIC_RETURN_PROPERTIES ] + [ f 'evidenceLevel. { p } ' for p in GENERIC_RETURN_PROPERTIES ] ) statements = graphkb_conn . query ( { 'target' : 'Statement' , 'filters' : { 'conditions' : convert_to_rid_list ( variant_matches ), 'operator' : 'CONTAINSANY' }, 'returnProperties' : return_props , } ) print ( f 'annotated { len ( variant_matches ) } variant matches with { len ( statements ) } statements' ) print () for statement in statements [: 5 ]: print ( [ c [ 'displayName' ] for c in statement [ 'conditions' ] if c [ '@class' ] . endswith ( 'Variant' )], statement [ 'relevance' ][ 'displayName' ], statement [ 'subject' ][ 'displayName' ], statement [ 'source' ][ 'displayName' ] if statement [ 'source' ] else '' , [ c [ 'displayName' ] for c in statement [ 'evidence' ]], ) annotated 7 variant matches with 96 statements ['KRAS:p.(G12_G13)mut'] resistance Gefitinib [c1855] CIViC ['pmid:15696205'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19603024'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:18316791']","title":"Annotating Variants"},{"location":"graphkb/scripting/Intro_Tutorial/#categorizing-statements","text":"Something we often want to know is if a statement is therapeutic, or prognostic, etc. The naive approach is to base this on a list of known terms or a regex pattern. In GraphKB we can leverage the ontology structure instead. In this example we will look for all terms that would indicate a therapeutically relevent statement. To do this we pick our 'base' terms. These are the terms we consider to be the highest level of the ontology tree, the most general term for that category. from graphkb.vocab import get_term_tree BASE_THERAPEUTIC_TERMS = 'therapeutic efficacy' therapeutic_terms = get_term_tree ( graphkb_conn , BASE_THERAPEUTIC_TERMS , include_superclasses = False ) print ( f 'Found { len ( therapeutic_terms ) } equivalent terms' ) for term in therapeutic_terms : print ( '-' , term [ 'name' ]) Found 13 equivalent terms - therapeutic efficacy - targetable - response - sensitivity - likely sensitivity - no sensitivity - no response - resistance - reduced sensitivity - likely resistance - innate resistance - acquired resistance - no resistance We can filter the statements we have already retrieved, or we can add this to our original query and filter before we retrive from the API statements = graphkb_conn . query ( { 'target' : 'Statement' , 'filters' : { 'AND' : [ { 'conditions' : convert_to_rid_list ( variant_matches ), 'operator' : 'CONTAINSANY' }, { 'relevance' : convert_to_rid_list ( therapeutic_terms ), 'operator' : 'IN' }, ] }, 'returnProperties' : return_props , } ) for statement in statements : print ( [ c [ 'displayName' ] for c in statement [ 'conditions' ] if c [ '@class' ] . endswith ( 'Variant' )], statement [ 'relevance' ][ 'displayName' ], statement [ 'subject' ][ 'displayName' ], statement [ 'source' ][ 'displayName' ] if statement [ 'source' ] else '' , [ c [ 'displayName' ] for c in statement [ 'evidence' ]], ) ['KRAS:p.G12mut'] response mek inhibitor [c69145] CGI ['pmid:18701506'] ['KRAS:p.G12D'] sensitivity dactolisib + selumetinib CIViC ['pmid:19029981'] ['KRAS mutation'] sensitivity Decitabine [c981] CIViC ['pmid:25968887'] ['KRAS mutation'] sensitivity Trametinib [c77908] CIViC ['pmid:22169769'] ['KRAS:p.G12D'] sensitivity Akt Inhibitor MK2206 [c90581] CIViC ['pmid:22025163'] ['KRAS mutation'] sensitivity cetuximab + dasatinib CIViC ['pmid:20956938'] ['KRAS mutation'] sensitivity b-raf/vegfr-2 inhibitor raf265 + selumetinib CIViC ['pmid:25199829'] ['KRAS mutation'] sensitivity b-raf/vegfr-2 inhibitor raf265 + selumetinib CIViC ['pmid:25199829'] ['KRAS mutation'] sensitivity afatinib + trametinib CIViC ['pmid:24685132'] ['KRAS mutation'] sensitivity afatinib + trametinib CIViC ['pmid:24685132'] ['KRAS mutation'] sensitivity docetaxel + selumetinib CIViC ['pmid:23200175'] ['KRAS mutation'] sensitivity selumetinib + teprotumumab CIViC ['pmid:21985784'] ['KRAS mutation'] sensitivity MEK Inhibitor GDC-0623 [c95738] CIViC ['pmid:23934108'] ['KRAS mutation'] sensitivity Trametinib [c77908] CIViC ['pmid:22805291'] ['KRAS mutation'] sensitivity refametinib + sorafenib CIViC ['pmid:25294897'] ['KRAS:p.G12D'] sensitivity Therapeutic Tumor Infiltrating Lymphocytes [c28699] CIViC ['pmid:27959684'] ['KRAS:p.G12D'] sensitivity dactolisib + selumetinib CIViC ['pmid:22392911'] ['KRAS mutation'] sensitivity erlotinib + teprotumumab CIViC ['pmid:22025157'] ['KRAS mutation'] sensitivity abemaciclib [c97660] CIViC ['pmid:27217383'] ['KRAS mutation'] sensitivity docetaxel + pemetrexed + trametinib CIViC ['pmid:27876675'] ['KRAS mutation'] sensitivity Atezolizumab [c106250] CIViC ['pmid:28525386'] ['KRAS mutation'] sensitivity Nivolumab [c68814] CIViC ['pmid:28525386'] ['KRAS mutation'] sensitivity Immune Checkpoint Inhibitor [c143250] CIViC ['pmid:28259530'] ['KRAS mutation'] sensitivity binimetinib + palbociclib CIViC ['pmid:27167191'] ['KRAS mutation'] sensitivity Metformin [c61612] CIViC ['pmid:32444490'] ['KRAS mutation'] sensitivity Binimetinib [c84865] CIViC ['pmid:32822286'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:18202412'] ['KRAS:p.(G12_G13)mut'] resistance cetuximab + chemotherapy CIViC ['pmid:20619739'] ['KRAS:p.(G12_G13)mut'] resistance Erlotinib [c65530] CIViC ['pmid:15696205'] ['KRAS:p.(G12_G13)mut'] resistance Gefitinib [c1855] CIViC ['pmid:15696205'] ['KRAS:p.(G12_G13)mut'] resistance gemcitabine + trametinib CIViC ['pmid:24915778'] ['KRAS mutation'] resistance bevacizumab + chemotherapy CIViC ['pmid:23828442'] ['KRAS mutation'] resistance ixazomib [c97940] CIViC ['pmid:26709701'] ['KRAS:p.G12D'] resistance Vemurafenib [c64768] CIViC ['pmid:26352686'] ['KRAS mutation'] resistance Cetuximab [c1723] CIViC ['pmid:22586653'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:18316791'] ['KRAS:p.G12D'] resistance Panitumumab [c1857] CIViC ['pmid:20619739'] ['KRAS:p.G12D'] resistance Cetuximab [c1723] CIViC ['pmid:20619739'] ['KRAS:p.G12D'] resistance Panitumumab [c1857] CIViC ['pmid:18316791'] ['KRAS:p.G12D'] resistance Gefitinib [c1855] CIViC ['pmid:17409929'] ['KRAS mutation'] resistance Erlotinib [c65530] CIViC ['pmid:22025157'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:19284554'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:11050000'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:12483530'] ['KRAS:p.G12D'] resistance Melphalan [c633] CIViC ['pmid:16497971'] ['KRAS mutation'] resistance Erlotinib [c65530] CIViC ['pmid:21258250'] ['KRAS mutation'] resistance Gefitinib [c1855] CIViC ['pmid:21258250'] ['KRAS mutation'] resistance docetaxel + selumetinib CIViC ['pmid:28492898'] ['KRAS mutation'] resistance cetuximab + chemotherapy CIViC ['pmid:20619739'] ['KRAS mutation'] resistance Erlotinib [c65530] CIViC ['pmid:21969500'] ['KRAS:p.G12D'] resistance Regorafenib [c78204] CIViC ['pmid:26161928'] ['KRAS:p.G12D'] resistance Vemurafenib [c64768] CIViC ['pmid:24265155'] ['KRAS:p.G12D'] resistance Cetuximab [c1723] CIViC ['pmid:22246397'] ['KRAS mutation'] resistance Panitumumab [c1857] CIViC ['pmid:28275037'] ['KRAS mutation'] resistance Cetuximab [c1723] CIViC ['pmid:28275037'] ['KRAS mutation'] resistance Vemurafenib [c64768] CIViC ['pmid:24265155'] ['KRAS mutation'] resistance Dabrafenib [c82386] CIViC ['pmid:24265155'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19603024'] ['KRAS:p.G12D'] resistance Cetuximab [c1723] CIViC ['pmid:19223544'] ['KRAS:p.G12D'] resistance Panitumumab [c1857] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Cetuximab [c1723] CIViC ['pmid:19223544'] ['KRAS:p.(G12_G13)mut'] resistance Panitumumab [c1857] CIViC ['pmid:19223544'] ['KRAS:p.?12mut'] resistance Cetuximab [c1723] CGI ['CGI'] ['KRAS:p.?12mut'] resistance Panitumumab [c1857] CGI ['CGI']","title":"Categorizing Statements"},{"location":"graphkb/scripting/Query_Basics/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Query Basics \u00b6 Documentation for the API can be seen via its OpenAPI specification at /api/spec . Here we will cover just the query endpoint which is the most commonly used endpoint as it is used for all searches. The /query endpoint accepts a JSON body in a POST request. This is how the user passes filters and other search-related parameters. We will define a few of the important fields and concepts that are used below. All the running examples below use the python GraphKB adapter. This assumes the user has aready initialized the connector and logged in as shown below (using the demo database and credentials). First install the adapter ! pip install graphkb Collecting graphkb Downloading graphkb-1.5.4-py3-none-any.whl (33 kB) Requirement already satisfied: requests<3,>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from graphkb) (2.23.0) Requirement already satisfied: typing-extensions<4,>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from graphkb) (3.7.4.3) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (1.24.3) Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2021.5.30) Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (3.0.4) Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2.10) Installing collected packages: graphkb Successfully installed graphkb-1.5.4 Then set up the connector from graphkb import GraphKBConnection GKB_API_URL = 'https://pori-demo.bcgsc.ca/graphkb-api/api' GKB_USER = 'colab_demo' GKB_PASSWORD = 'colab_demo' graphkb_conn = GraphKBConnection ( GKB_API_URL ) graphkb_conn . login ( GKB_USER , GKB_PASSWORD ) Important Fields and Concepts \u00b6 Query Target \u00b6 The target is the class/table that the users wishes to query. If it is at the top level of the request body then it is also the type of record which will be returned. For example to get a list of all publications in GraphKB. We limit this to the first 3 publications for the purposes of this demo graphkb_conn . query ({ 'target' : 'Publication' }, paginate = False , limit = 3 ) [{'@class': 'Publication', '@rid': '#38:0', 'alias': False, 'createdAt': 1612980878029, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:25500544', 'journalName': 'oncogene', 'name': 'the landscape and therapeutic relevance of cancer-associated transcript fusions.', 'source': '#17:21', 'sourceId': '25500544', 'updatedAt': 1612980878029, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/25500544', 'uuid': '1294db97-ee26-4bd4-9b50-d122436905be', 'year': 2015}, {'@class': 'Publication', '@rid': '#38:1', 'alias': False, 'createdAt': 1612981149054, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:16081687', 'journalName': 'blood', 'name': 'the jak2v617f activating mutation occurs in chronic myelomonocytic leukemia and acute myeloid leukemia, but not in acute lymphoblastic leukemia or chronic lymphocytic leukemia.', 'source': '#17:21', 'sourceId': '16081687', 'updatedAt': 1612981149054, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/16081687', 'uuid': '52e0d70f-07f8-48b9-b59d-b0258d60b9ae', 'year': 2005}, {'@class': 'Publication', '@rid': '#38:2', 'alias': False, 'createdAt': 1612981150038, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:15146165', 'journalName': 'laboratory investigation; a journal of technical methods and pathology', 'name': 'a great majority of gists with pdgfra mutations represent gastric tumors of low or no malignant potential.', 'source': '#17:21', 'sourceId': '15146165', 'updatedAt': 1612981150038, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/15146165', 'uuid': '9e600c55-3247-4e24-bcd8-4a20bb0fb794', 'year': 2004}] Filters \u00b6 Any field that is accessible with the current users permissions level can be queried via this endpoint. Most commonly users want to filter on this like a records name or source ID (ID in the external database it was imported from). Continuing our example from above let's search for publications with the word \"cancer\" in them. Note : The current full text index only searches on word and word prefixes. Future iterations will support a full lucene index. graphkb_conn . query ({ 'target' : 'Publication' , 'filters' : { 'name' : 'cancer' , 'operator' : 'CONTAINSTEXT' } }, paginate = False , limit = 3 ) [{'@class': 'Publication', '@rid': '#38:0', 'alias': False, 'createdAt': 1612980878029, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:25500544', 'journalName': 'oncogene', 'name': 'the landscape and therapeutic relevance of cancer-associated transcript fusions.', 'source': '#17:21', 'sourceId': '25500544', 'updatedAt': 1612980878029, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/25500544', 'uuid': '1294db97-ee26-4bd4-9b50-d122436905be', 'year': 2015}, {'@class': 'Publication', '@rid': '#38:19', 'alias': False, 'createdAt': 1612981162739, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:24666267', 'journalName': 'acta oncologica (stockholm, sweden)', 'name': 'the predictive value of kras, nras, braf, pik3ca and pten for anti-egfr treatment in metastatic colorectal cancer: a systematic review and meta-analysis.', 'source': '#17:21', 'sourceId': '24666267', 'updatedAt': 1612981162739, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/24666267', 'uuid': '06981f31-59d0-439e-b5cd-71f503f9c50e', 'year': 2014}, {'@class': 'Publication', '@rid': '#38:22', 'alias': False, 'createdAt': 1612981164833, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:21030459', 'journalName': 'cancer research', 'name': 'the neuroblastoma-associated f1174l alk mutation causes resistance to an alk kinase inhibitor in alk-translocated cancers.', 'source': '#17:21', 'sourceId': '21030459', 'updatedAt': 1612981164833, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/21030459', 'uuid': '4f088978-1736-4e3e-83fb-6d2c70e88873', 'year': 2010}] You can also filter on multiple conditions. To do this we nest filters in an object which uses a single AND/OR property with a list of regular conditions. For example if we want to find diseases with the name \"cancer\" or \"carcinoma\" graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'OR' : [ { 'name' : 'cancer' }, { 'name' : 'carcinoma' }, ] }, }) [{'@class': 'Disease', '@rid': '#43:99077', 'alias': False, 'createdAt': 1612926192944, 'createdBy': '#14:0', 'deprecated': True, 'displayName': 'carcinoma', 'name': 'carcinoma', 'out_DeprecatedBy': ['#29:1400'], 'source': '#17:19', 'sourceId': 'doid:2428', 'updatedAt': 1612926192944, 'updatedBy': '#14:0', 'uuid': '2c61fd80-43fb-4cd2-941c-889a020cbbde'}, {'@class': 'Disease', '@rid': '#43:99076', 'alias': False, 'createdAt': 1612926192912, 'createdBy': '#14:0', 'deprecated': True, 'displayName': 'carcinoma', 'name': 'carcinoma', 'out_DeprecatedBy': ['#29:1399'], 'source': '#17:19', 'sourceId': 'doid:6570', 'updatedAt': 1612926192912, 'updatedBy': '#14:0', 'uuid': 'baedee00-47a8-4d78-8ff5-7d9d8fadc03f'}, {'@class': 'Disease', '@rid': '#43:99072', 'alias': False, 'createdAt': 1612926192816, 'createdBy': '#14:0', 'deprecated': False, 'description': 'A cell type cancer that has_material_basis_in abnormally proliferating cells derives_from epithelial cells.', 'displayName': 'carcinoma', 'history': '#43:107676', 'in_AliasOf': ['#26:160594', '#26:160595', '#26:160596'], 'in_DeprecatedBy': ['#29:1399', '#29:1400'], 'in_SubClassOf': [], 'name': 'carcinoma', 'out_CrossReferenceOf': ['#28:37788'], 'out_SubClassOf': ['#33:13951'], 'source': '#17:19', 'sourceId': 'doid:305', 'subsets': ['doid#do_flybase_slim', 'doid#ncithesaurus', 'doid#do_cancer_slim'], 'updatedAt': 1612980618003, 'updatedBy': '#14:0', 'uuid': '1775c2a3-b923-49f4-9e28-d5ccfcb32bc3'}, {'@class': 'Disease', '@rid': '#43:68962', 'alias': True, 'createdAt': 1612863235878, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'cancer [c9305]', 'name': 'cancer', 'out_AliasOf': ['#26:137530'], 'source': '#17:0', 'sourceId': 'c9305', 'updatedAt': 1612863235878, 'updatedBy': '#14:0', 'uuid': 'ed0fffc2-31ef-435b-ae11-6efd6b193dd3'}, {'@class': 'Disease', '@rid': '#43:100548', 'alias': False, 'createdAt': 1612926228848, 'createdBy': '#14:0', 'deprecated': False, 'description': 'A disease of cellular proliferation that is malignant and primary, characterized by uncontrolled cellular proliferation, local cell invasion and metastasis.', 'displayName': 'cancer', 'history': '#43:107678', 'in_AliasOf': ['#26:161531', '#26:161532', '#26:161533'], 'in_SubClassOf': ['#33:5210', '#33:5268'], 'name': 'cancer', 'out_CrossReferenceOf': ['#28:37957'], 'out_ElementOf': ['#30:82543'], 'out_SubClassOf': ['#33:7594'], 'source': '#17:19', 'sourceId': 'doid:162', 'subsets': ['doid#do_flybase_slim', 'doid#ncithesaurus', 'doid#do_cancer_slim', 'doid#do_agr_slim', 'doid#do_gxd_slim'], 'updatedAt': 1612980640268, 'updatedBy': '#14:0', 'uuid': '6a051270-4611-4af2-a5ff-1b31a872b4e0'}] The operator can be omitted here since = is the default operator. We can also combine conditions with AND graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'name' : 'cancer' , 'operator' : 'CONTAINSTEXT' }, { 'name' : 'pancreatic' , 'operator' : 'CONTAINSTEXT' }, ] }, }, paginate = False , limit = 3 ) [{'@class': 'Disease', '@rid': '#43:1683', 'alias': True, 'createdAt': 1612854000193, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'recurrent pancreatic neuroendocrine cancer [c115433]', 'name': 'recurrent pancreatic neuroendocrine cancer', 'out_AliasOf': ['#26:5496'], 'source': '#17:0', 'sourceId': 'c115433', 'updatedAt': 1612854000193, 'updatedBy': '#14:0', 'uuid': 'a0831763-7bcb-4c68-a9dc-7aee6b3795c3'}, {'@class': 'Disease', '@rid': '#43:8254', 'alias': True, 'createdAt': 1612855453528, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pancreatic cancer by ajcc v6 and v7 stage [c134902]', 'name': 'pancreatic cancer by ajcc v6 and v7 stage', 'out_AliasOf': ['#26:18191'], 'source': '#17:0', 'sourceId': 'c134902', 'updatedAt': 1612855453528, 'updatedBy': '#14:0', 'uuid': '21e9a523-1982-4bf0-824d-c50bbe9b11b9'}, {'@class': 'Disease', '@rid': '#43:8255', 'alias': True, 'createdAt': 1612855453548, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'exocrine and endocrine pancreatic cancer by ajcc v6 and v7 stage [c134902]', 'name': 'exocrine and endocrine pancreatic cancer by ajcc v6 and v7 stage', 'out_AliasOf': ['#26:18192'], 'source': '#17:0', 'sourceId': 'c134902', 'updatedAt': 1612855453548, 'updatedBy': '#14:0', 'uuid': 'd66fdfc2-578c-49cf-b3d7-cfe693fae104'}] The above will look for diseases that have both 'cancer' and 'pancreatic' in the name. Subquery Filters \u00b6 Sometimes we would like to filter records on a linked field (essentially a foreign key). We can do this with subquery filters. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }} }, }, paginate = False , limit = 3 ) [{'@class': 'Disease', '@rid': '#43:72269', 'alias': True, 'createdAt': 1612924874193, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'von reklinghausen disease', 'name': 'von reklinghausen disease', 'out_AliasOf': ['#26:145059'], 'source': '#17:19', 'sourceId': 'doid:8712', 'updatedAt': 1612924874193, 'updatedBy': '#14:0', 'uuid': '5647ae2d-8837-48fd-8b46-7669ec046e8e'}, {'@class': 'Disease', '@rid': '#43:72251', 'alias': True, 'createdAt': 1612924873047, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'other named variants of lymphosarcoma and reticulosarcoma involving lymph nodes of axilla and upper limb', 'name': 'other named variants of lymphosarcoma and reticulosarcoma involving lymph nodes of axilla and upper limb', 'out_AliasOf': ['#26:145052'], 'source': '#17:19', 'sourceId': 'doid:8716', 'updatedAt': 1612924873047, 'updatedBy': '#14:0', 'uuid': '9586920c-fc10-4c5d-9cdb-f92d234d7cb3'}, {'@class': 'Disease', '@rid': '#43:72256', 'alias': True, 'createdAt': 1612924873474, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'other named variants of lymphosarcoma and reticulosarcoma involving intrapelvic lymph nodes', 'name': 'other named variants of lymphosarcoma and reticulosarcoma involving intrapelvic lymph nodes', 'out_AliasOf': ['#26:145057'], 'source': '#17:19', 'sourceId': 'doid:8716', 'updatedAt': 1612924873474, 'updatedBy': '#14:0', 'uuid': 'e8cf5e88-9624-4900-8986-177e607fd95a'}] Above we are only returning disease records that have been imported from the disease ontology. Return Properties (Fields) \u00b6 The return fields property allows the user to specify what they would like to return. This can mean returning a subset of fields for a large query to improve the speed of the client digesting the data, or it can be used to de-nest fields. By default the query will return only the immediate properties of the class being queries. This means that linked fields will be listed as their record ID. De-nesting these fields allows you to return them without additional queries. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }}}, { 'name' : 'cancer' } ], }, }) [{'@class': 'Disease', '@rid': '#43:100548', 'alias': False, 'createdAt': 1612926228848, 'createdBy': '#14:0', 'deprecated': False, 'description': 'A disease of cellular proliferation that is malignant and primary, characterized by uncontrolled cellular proliferation, local cell invasion and metastasis.', 'displayName': 'cancer', 'history': '#43:107678', 'in_AliasOf': ['#26:161531', '#26:161532', '#26:161533'], 'in_SubClassOf': ['#33:5210', '#33:5268'], 'name': 'cancer', 'out_CrossReferenceOf': ['#28:37957'], 'out_ElementOf': ['#30:82543'], 'out_SubClassOf': ['#33:7594'], 'source': '#17:19', 'sourceId': 'doid:162', 'subsets': ['doid#do_flybase_slim', 'doid#ncithesaurus', 'doid#do_cancer_slim', 'doid#do_agr_slim', 'doid#do_gxd_slim'], 'updatedAt': 1612980640268, 'updatedBy': '#14:0', 'uuid': '6a051270-4611-4af2-a5ff-1b31a872b4e0'}] We probably are not interested in all of these fields so let's pick a few to return. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }}}, { 'name' : 'cancer' } ], }, 'returnProperties' : [ 'name' , 'source' , 'sourceId' , 'alias' , 'deprecated' ] }) [{'alias': False, 'deprecated': False, 'name': 'cancer', 'source': '#17:19', 'sourceId': 'doid:162'}] The new return looks much more reasonable. However the source field right now is a seperate record ID. This means with the current query we would have to fetch that record separately if we want to see details about it. This can be done in a single query with the nested return properties. Simply delimit properties and sub-properties with a period. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }}}, { 'name' : 'cancer' } ], }, 'returnProperties' : [ 'name' , 'source.name' , 'sourceId' , 'alias' , 'deprecated' ] }) [{'alias': False, 'deprecated': False, 'name': 'cancer', 'source': {'name': 'disease ontology'}, 'sourceId': 'doid:162'}]","title":"Query Basics"},{"location":"graphkb/scripting/Query_Basics/#query-basics","text":"Documentation for the API can be seen via its OpenAPI specification at /api/spec . Here we will cover just the query endpoint which is the most commonly used endpoint as it is used for all searches. The /query endpoint accepts a JSON body in a POST request. This is how the user passes filters and other search-related parameters. We will define a few of the important fields and concepts that are used below. All the running examples below use the python GraphKB adapter. This assumes the user has aready initialized the connector and logged in as shown below (using the demo database and credentials). First install the adapter ! pip install graphkb Collecting graphkb Downloading graphkb-1.5.4-py3-none-any.whl (33 kB) Requirement already satisfied: requests<3,>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from graphkb) (2.23.0) Requirement already satisfied: typing-extensions<4,>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from graphkb) (3.7.4.3) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (1.24.3) Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2021.5.30) Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (3.0.4) Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22.0->graphkb) (2.10) Installing collected packages: graphkb Successfully installed graphkb-1.5.4 Then set up the connector from graphkb import GraphKBConnection GKB_API_URL = 'https://pori-demo.bcgsc.ca/graphkb-api/api' GKB_USER = 'colab_demo' GKB_PASSWORD = 'colab_demo' graphkb_conn = GraphKBConnection ( GKB_API_URL ) graphkb_conn . login ( GKB_USER , GKB_PASSWORD )","title":"Query Basics"},{"location":"graphkb/scripting/Query_Basics/#important-fields-and-concepts","text":"","title":"Important Fields and Concepts"},{"location":"graphkb/scripting/Query_Basics/#query-target","text":"The target is the class/table that the users wishes to query. If it is at the top level of the request body then it is also the type of record which will be returned. For example to get a list of all publications in GraphKB. We limit this to the first 3 publications for the purposes of this demo graphkb_conn . query ({ 'target' : 'Publication' }, paginate = False , limit = 3 ) [{'@class': 'Publication', '@rid': '#38:0', 'alias': False, 'createdAt': 1612980878029, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:25500544', 'journalName': 'oncogene', 'name': 'the landscape and therapeutic relevance of cancer-associated transcript fusions.', 'source': '#17:21', 'sourceId': '25500544', 'updatedAt': 1612980878029, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/25500544', 'uuid': '1294db97-ee26-4bd4-9b50-d122436905be', 'year': 2015}, {'@class': 'Publication', '@rid': '#38:1', 'alias': False, 'createdAt': 1612981149054, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:16081687', 'journalName': 'blood', 'name': 'the jak2v617f activating mutation occurs in chronic myelomonocytic leukemia and acute myeloid leukemia, but not in acute lymphoblastic leukemia or chronic lymphocytic leukemia.', 'source': '#17:21', 'sourceId': '16081687', 'updatedAt': 1612981149054, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/16081687', 'uuid': '52e0d70f-07f8-48b9-b59d-b0258d60b9ae', 'year': 2005}, {'@class': 'Publication', '@rid': '#38:2', 'alias': False, 'createdAt': 1612981150038, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:15146165', 'journalName': 'laboratory investigation; a journal of technical methods and pathology', 'name': 'a great majority of gists with pdgfra mutations represent gastric tumors of low or no malignant potential.', 'source': '#17:21', 'sourceId': '15146165', 'updatedAt': 1612981150038, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/15146165', 'uuid': '9e600c55-3247-4e24-bcd8-4a20bb0fb794', 'year': 2004}]","title":"Query Target"},{"location":"graphkb/scripting/Query_Basics/#filters","text":"Any field that is accessible with the current users permissions level can be queried via this endpoint. Most commonly users want to filter on this like a records name or source ID (ID in the external database it was imported from). Continuing our example from above let's search for publications with the word \"cancer\" in them. Note : The current full text index only searches on word and word prefixes. Future iterations will support a full lucene index. graphkb_conn . query ({ 'target' : 'Publication' , 'filters' : { 'name' : 'cancer' , 'operator' : 'CONTAINSTEXT' } }, paginate = False , limit = 3 ) [{'@class': 'Publication', '@rid': '#38:0', 'alias': False, 'createdAt': 1612980878029, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:25500544', 'journalName': 'oncogene', 'name': 'the landscape and therapeutic relevance of cancer-associated transcript fusions.', 'source': '#17:21', 'sourceId': '25500544', 'updatedAt': 1612980878029, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/25500544', 'uuid': '1294db97-ee26-4bd4-9b50-d122436905be', 'year': 2015}, {'@class': 'Publication', '@rid': '#38:19', 'alias': False, 'createdAt': 1612981162739, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:24666267', 'journalName': 'acta oncologica (stockholm, sweden)', 'name': 'the predictive value of kras, nras, braf, pik3ca and pten for anti-egfr treatment in metastatic colorectal cancer: a systematic review and meta-analysis.', 'source': '#17:21', 'sourceId': '24666267', 'updatedAt': 1612981162739, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/24666267', 'uuid': '06981f31-59d0-439e-b5cd-71f503f9c50e', 'year': 2014}, {'@class': 'Publication', '@rid': '#38:22', 'alias': False, 'createdAt': 1612981164833, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pmid:21030459', 'journalName': 'cancer research', 'name': 'the neuroblastoma-associated f1174l alk mutation causes resistance to an alk kinase inhibitor in alk-translocated cancers.', 'source': '#17:21', 'sourceId': '21030459', 'updatedAt': 1612981164833, 'updatedBy': '#14:0', 'url': 'https://pubmed.ncbi.nlm.nih.gov/21030459', 'uuid': '4f088978-1736-4e3e-83fb-6d2c70e88873', 'year': 2010}] You can also filter on multiple conditions. To do this we nest filters in an object which uses a single AND/OR property with a list of regular conditions. For example if we want to find diseases with the name \"cancer\" or \"carcinoma\" graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'OR' : [ { 'name' : 'cancer' }, { 'name' : 'carcinoma' }, ] }, }) [{'@class': 'Disease', '@rid': '#43:99077', 'alias': False, 'createdAt': 1612926192944, 'createdBy': '#14:0', 'deprecated': True, 'displayName': 'carcinoma', 'name': 'carcinoma', 'out_DeprecatedBy': ['#29:1400'], 'source': '#17:19', 'sourceId': 'doid:2428', 'updatedAt': 1612926192944, 'updatedBy': '#14:0', 'uuid': '2c61fd80-43fb-4cd2-941c-889a020cbbde'}, {'@class': 'Disease', '@rid': '#43:99076', 'alias': False, 'createdAt': 1612926192912, 'createdBy': '#14:0', 'deprecated': True, 'displayName': 'carcinoma', 'name': 'carcinoma', 'out_DeprecatedBy': ['#29:1399'], 'source': '#17:19', 'sourceId': 'doid:6570', 'updatedAt': 1612926192912, 'updatedBy': '#14:0', 'uuid': 'baedee00-47a8-4d78-8ff5-7d9d8fadc03f'}, {'@class': 'Disease', '@rid': '#43:99072', 'alias': False, 'createdAt': 1612926192816, 'createdBy': '#14:0', 'deprecated': False, 'description': 'A cell type cancer that has_material_basis_in abnormally proliferating cells derives_from epithelial cells.', 'displayName': 'carcinoma', 'history': '#43:107676', 'in_AliasOf': ['#26:160594', '#26:160595', '#26:160596'], 'in_DeprecatedBy': ['#29:1399', '#29:1400'], 'in_SubClassOf': [], 'name': 'carcinoma', 'out_CrossReferenceOf': ['#28:37788'], 'out_SubClassOf': ['#33:13951'], 'source': '#17:19', 'sourceId': 'doid:305', 'subsets': ['doid#do_flybase_slim', 'doid#ncithesaurus', 'doid#do_cancer_slim'], 'updatedAt': 1612980618003, 'updatedBy': '#14:0', 'uuid': '1775c2a3-b923-49f4-9e28-d5ccfcb32bc3'}, {'@class': 'Disease', '@rid': '#43:68962', 'alias': True, 'createdAt': 1612863235878, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'cancer [c9305]', 'name': 'cancer', 'out_AliasOf': ['#26:137530'], 'source': '#17:0', 'sourceId': 'c9305', 'updatedAt': 1612863235878, 'updatedBy': '#14:0', 'uuid': 'ed0fffc2-31ef-435b-ae11-6efd6b193dd3'}, {'@class': 'Disease', '@rid': '#43:100548', 'alias': False, 'createdAt': 1612926228848, 'createdBy': '#14:0', 'deprecated': False, 'description': 'A disease of cellular proliferation that is malignant and primary, characterized by uncontrolled cellular proliferation, local cell invasion and metastasis.', 'displayName': 'cancer', 'history': '#43:107678', 'in_AliasOf': ['#26:161531', '#26:161532', '#26:161533'], 'in_SubClassOf': ['#33:5210', '#33:5268'], 'name': 'cancer', 'out_CrossReferenceOf': ['#28:37957'], 'out_ElementOf': ['#30:82543'], 'out_SubClassOf': ['#33:7594'], 'source': '#17:19', 'sourceId': 'doid:162', 'subsets': ['doid#do_flybase_slim', 'doid#ncithesaurus', 'doid#do_cancer_slim', 'doid#do_agr_slim', 'doid#do_gxd_slim'], 'updatedAt': 1612980640268, 'updatedBy': '#14:0', 'uuid': '6a051270-4611-4af2-a5ff-1b31a872b4e0'}] The operator can be omitted here since = is the default operator. We can also combine conditions with AND graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'name' : 'cancer' , 'operator' : 'CONTAINSTEXT' }, { 'name' : 'pancreatic' , 'operator' : 'CONTAINSTEXT' }, ] }, }, paginate = False , limit = 3 ) [{'@class': 'Disease', '@rid': '#43:1683', 'alias': True, 'createdAt': 1612854000193, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'recurrent pancreatic neuroendocrine cancer [c115433]', 'name': 'recurrent pancreatic neuroendocrine cancer', 'out_AliasOf': ['#26:5496'], 'source': '#17:0', 'sourceId': 'c115433', 'updatedAt': 1612854000193, 'updatedBy': '#14:0', 'uuid': 'a0831763-7bcb-4c68-a9dc-7aee6b3795c3'}, {'@class': 'Disease', '@rid': '#43:8254', 'alias': True, 'createdAt': 1612855453528, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'pancreatic cancer by ajcc v6 and v7 stage [c134902]', 'name': 'pancreatic cancer by ajcc v6 and v7 stage', 'out_AliasOf': ['#26:18191'], 'source': '#17:0', 'sourceId': 'c134902', 'updatedAt': 1612855453528, 'updatedBy': '#14:0', 'uuid': '21e9a523-1982-4bf0-824d-c50bbe9b11b9'}, {'@class': 'Disease', '@rid': '#43:8255', 'alias': True, 'createdAt': 1612855453548, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'exocrine and endocrine pancreatic cancer by ajcc v6 and v7 stage [c134902]', 'name': 'exocrine and endocrine pancreatic cancer by ajcc v6 and v7 stage', 'out_AliasOf': ['#26:18192'], 'source': '#17:0', 'sourceId': 'c134902', 'updatedAt': 1612855453548, 'updatedBy': '#14:0', 'uuid': 'd66fdfc2-578c-49cf-b3d7-cfe693fae104'}] The above will look for diseases that have both 'cancer' and 'pancreatic' in the name.","title":"Filters"},{"location":"graphkb/scripting/Query_Basics/#subquery-filters","text":"Sometimes we would like to filter records on a linked field (essentially a foreign key). We can do this with subquery filters. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }} }, }, paginate = False , limit = 3 ) [{'@class': 'Disease', '@rid': '#43:72269', 'alias': True, 'createdAt': 1612924874193, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'von reklinghausen disease', 'name': 'von reklinghausen disease', 'out_AliasOf': ['#26:145059'], 'source': '#17:19', 'sourceId': 'doid:8712', 'updatedAt': 1612924874193, 'updatedBy': '#14:0', 'uuid': '5647ae2d-8837-48fd-8b46-7669ec046e8e'}, {'@class': 'Disease', '@rid': '#43:72251', 'alias': True, 'createdAt': 1612924873047, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'other named variants of lymphosarcoma and reticulosarcoma involving lymph nodes of axilla and upper limb', 'name': 'other named variants of lymphosarcoma and reticulosarcoma involving lymph nodes of axilla and upper limb', 'out_AliasOf': ['#26:145052'], 'source': '#17:19', 'sourceId': 'doid:8716', 'updatedAt': 1612924873047, 'updatedBy': '#14:0', 'uuid': '9586920c-fc10-4c5d-9cdb-f92d234d7cb3'}, {'@class': 'Disease', '@rid': '#43:72256', 'alias': True, 'createdAt': 1612924873474, 'createdBy': '#14:0', 'deprecated': False, 'displayName': 'other named variants of lymphosarcoma and reticulosarcoma involving intrapelvic lymph nodes', 'name': 'other named variants of lymphosarcoma and reticulosarcoma involving intrapelvic lymph nodes', 'out_AliasOf': ['#26:145057'], 'source': '#17:19', 'sourceId': 'doid:8716', 'updatedAt': 1612924873474, 'updatedBy': '#14:0', 'uuid': 'e8cf5e88-9624-4900-8986-177e607fd95a'}] Above we are only returning disease records that have been imported from the disease ontology.","title":"Subquery Filters"},{"location":"graphkb/scripting/Query_Basics/#return-properties-fields","text":"The return fields property allows the user to specify what they would like to return. This can mean returning a subset of fields for a large query to improve the speed of the client digesting the data, or it can be used to de-nest fields. By default the query will return only the immediate properties of the class being queries. This means that linked fields will be listed as their record ID. De-nesting these fields allows you to return them without additional queries. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }}}, { 'name' : 'cancer' } ], }, }) [{'@class': 'Disease', '@rid': '#43:100548', 'alias': False, 'createdAt': 1612926228848, 'createdBy': '#14:0', 'deprecated': False, 'description': 'A disease of cellular proliferation that is malignant and primary, characterized by uncontrolled cellular proliferation, local cell invasion and metastasis.', 'displayName': 'cancer', 'history': '#43:107678', 'in_AliasOf': ['#26:161531', '#26:161532', '#26:161533'], 'in_SubClassOf': ['#33:5210', '#33:5268'], 'name': 'cancer', 'out_CrossReferenceOf': ['#28:37957'], 'out_ElementOf': ['#30:82543'], 'out_SubClassOf': ['#33:7594'], 'source': '#17:19', 'sourceId': 'doid:162', 'subsets': ['doid#do_flybase_slim', 'doid#ncithesaurus', 'doid#do_cancer_slim', 'doid#do_agr_slim', 'doid#do_gxd_slim'], 'updatedAt': 1612980640268, 'updatedBy': '#14:0', 'uuid': '6a051270-4611-4af2-a5ff-1b31a872b4e0'}] We probably are not interested in all of these fields so let's pick a few to return. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }}}, { 'name' : 'cancer' } ], }, 'returnProperties' : [ 'name' , 'source' , 'sourceId' , 'alias' , 'deprecated' ] }) [{'alias': False, 'deprecated': False, 'name': 'cancer', 'source': '#17:19', 'sourceId': 'doid:162'}] The new return looks much more reasonable. However the source field right now is a seperate record ID. This means with the current query we would have to fetch that record separately if we want to see details about it. This can be done in a single query with the nested return properties. Simply delimit properties and sub-properties with a period. graphkb_conn . query ({ 'target' : 'Disease' , 'filters' : { 'AND' : [ { 'source' : { 'target' : 'Source' , 'filters' : { 'name' : 'disease ontology' }}}, { 'name' : 'cancer' } ], }, 'returnProperties' : [ 'name' , 'source.name' , 'sourceId' , 'alias' , 'deprecated' ] }) [{'alias': False, 'deprecated': False, 'name': 'cancer', 'source': {'name': 'disease ontology'}, 'sourceId': 'doid:162'}]","title":"Return Properties (Fields)"},{"location":"graphkb/scripting/snpsift/","text":"Annotate SNPSift Files \u00b6 The script annotate_snpsift.py can be used to match variants from input files to an instance of GraphKB. Copy the script locally and install the package dependencies. Must use Python3.6 or higher pip3 install graphkb pandas Then the annotator can be run as follows python annotate_snpsift.py <INPUT FILES> --output graphkb_annotations.tsv By default this will use the pori-demo version of GraphKB which has a limited amount of data. This demo version is intended for demonstration/testing only and a custom or shared production instance of the GraphKB API. This can be configured via the GraphKB arguments. See the help menu for a full list of arguments. python annotate_snpsift.py -h The output file will contain the variant name and the annotations pulled from GraphKB.","title":"Annotate SNPSift Files"},{"location":"graphkb/scripting/snpsift/#annotate-snpsift-files","text":"The script annotate_snpsift.py can be used to match variants from input files to an instance of GraphKB. Copy the script locally and install the package dependencies. Must use Python3.6 or higher pip3 install graphkb pandas Then the annotator can be run as follows python annotate_snpsift.py <INPUT FILES> --output graphkb_annotations.tsv By default this will use the pori-demo version of GraphKB which has a limited amount of data. This demo version is intended for demonstration/testing only and a custom or shared production instance of the GraphKB API. This can be configured via the GraphKB arguments. See the help menu for a full list of arguments. python annotate_snpsift.py -h The output file will contain the variant name and the annotations pulled from GraphKB.","title":"Annotate SNPSift Files"},{"location":"graphkb/scripting/variant_strings/","text":"Annotate Variant List \u00b6 The script annotate_variant_list.py can be used to match variants from input files to an instance of GraphKB. Copy the script locally and install the package dependencies. This example script expects a file with a single field (variant) and no header. Each line should be a separate HGVS-like variant notation. For example KRAS:p.G12D KRAS:p.G13E Must use Python3.6 or higher pip3 install graphkb pandas Then the annotator can be run as follows python annotate_variant_list.py <INPUT FILE> --output graphkb_annotations.tsv By default this will use the pori-demo version of GraphKB which has a limited amount of data. This demo version is intended for demonstration/testing only and a custom or shared production instance of the GraphKB API. This can be configured via the GraphKB arguments. See the help menu for a full list of arguments. python annotate_variant_list.py -h The output file will contain the variant name and the annotations pulled from GraphKB. The names of the variants matched will be included in the output file as \"variant_matches\", this will be a semi-colon delimited list of all the variants which were considered to be present/equivalent based on the input variant. For example if the input where KRAS:p.G12D we might expect to see something like this KRAS mutation;KRAS:p.(G12_G13)mut;KRAS:p.?12mut;KRAS:p.G12;KRAS:p.G12D;KRAS:p.G12mut;chr12:g.25398284C>T We can see the variant has matched less specific forms of the same variant such as KRAS mutation or KRAS:p.(G12_G13)mut (any KRAS mutation at G12 or G13)","title":"Annotate Variant List"},{"location":"graphkb/scripting/variant_strings/#annotate-variant-list","text":"The script annotate_variant_list.py can be used to match variants from input files to an instance of GraphKB. Copy the script locally and install the package dependencies. This example script expects a file with a single field (variant) and no header. Each line should be a separate HGVS-like variant notation. For example KRAS:p.G12D KRAS:p.G13E Must use Python3.6 or higher pip3 install graphkb pandas Then the annotator can be run as follows python annotate_variant_list.py <INPUT FILE> --output graphkb_annotations.tsv By default this will use the pori-demo version of GraphKB which has a limited amount of data. This demo version is intended for demonstration/testing only and a custom or shared production instance of the GraphKB API. This can be configured via the GraphKB arguments. See the help menu for a full list of arguments. python annotate_variant_list.py -h The output file will contain the variant name and the annotations pulled from GraphKB. The names of the variants matched will be included in the output file as \"variant_matches\", this will be a semi-colon delimited list of all the variants which were considered to be present/equivalent based on the input variant. For example if the input where KRAS:p.G12D we might expect to see something like this KRAS mutation;KRAS:p.(G12_G13)mut;KRAS:p.?12mut;KRAS:p.G12;KRAS:p.G12D;KRAS:p.G12mut;chr12:g.25398284C>T We can see the variant has matched less specific forms of the same variant such as KRAS mutation or KRAS:p.(G12_G13)mut (any KRAS mutation at G12 or G13)","title":"Annotate Variant List"},{"location":"help/faq/","text":"General FAQ \u00b6 How does Variant Annotation Work? \u00b6 Variants are annotated using the GraphKB Python Adapter via the GraphKB REST API. In general this consists of the following steps Parse HGVS-like notation 1 Disambiguate via ontologies (gene name, variant type, etc.) Pull matching variant records Refine matches base on position information 1 Follows inferences (ex. g. -> p.) Pull statements for these variant records This allows an input like KRAS:p.G12D to match to all equivalent forms of this variant. For example, in the demo database it would result in the following matches How do I cite PORI? \u00b6 Please cite Reisle, C. et al. A platform for oncogenomic reporting and interpretation. Nat. Commun. 13, 1\u201311 (2022) How Can I Migrate Our Existing KB to GraphKB? \u00b6 The simplest way to do this is using the API. THere are a number of examples of loader/migration scripts in the loaders project which can be used as examples as well as instructions on best practices for adding or including your own. If you would like a new loader for a public/popular resource, please make a ticket/issue on this github space Is there a Licensing Requirement for PORI Software? \u00b6 No. PORI is fully open source. The entire platform is released under a GPL-3 open source license. Is there a Licensing Requirement for PORI Data? \u00b6 Data is loaded and added externally by the users themselves and therefore there is no licensing requirement. We do provided loading scripts for some externally licensed content, but it is left up to the user to arrange and a license agreement for these sources if they would like to use them. By default the loaders only load the open data. How Can I Get Involved? \u00b6 We welcome and encourage community contributions! If you have a feature request, bug report, or question please feel free to submit an issue to our GitHub page. If you are not sure which repository to submit the issue to, use this main one by default and we will move or direct the issue as required. If you are a developer and would like to directly add and work on features, please submit a ticket for any new features and indicate that you would like to complete it or comment on an existing ticket. Following discussion with the main developers you should fork the repository and then submit a pull request from your forked version to the main repository. Please see the developer contributing guidelines here How Can I Try This Out? \u00b6 We have created a demo version of PORI for users to test without having to set anything up. Please see the IPR and GraphKB demos here What is Second-Pass Matching? \u00b6 Second-pass matching is built into the matching done by the IPR python adapter. First, variants are matched to statements. A second set of variants is then created using the subject and relevance of these matched statements. These newly created variants are passed back into matching to fetch statements. Any statements which are matched based on this second pass are labelled in IPR with the \"inferred\" flag. An example of this might be that a user inputs a variant, KRAS:p.G12D, which matches to a statement with a relevance of \"gain of function\" and a subject of \"KRAS\". This then creates the new variant \"KRAS gain of function\" which matches to a second statement with the subject \"EGFR inhibitor\" and relevance \"resistance\". An inferred match of EGFR inhibitor resistance will be reported for KRAS:p.G12D. Only applicable to positional variants, these steps are skipped when matching category variants. \u21a9 \u21a9","title":"General FAQ"},{"location":"help/faq/#general-faq","text":"","title":"General FAQ"},{"location":"help/faq/#how-does-variant-annotation-work","text":"Variants are annotated using the GraphKB Python Adapter via the GraphKB REST API. In general this consists of the following steps Parse HGVS-like notation 1 Disambiguate via ontologies (gene name, variant type, etc.) Pull matching variant records Refine matches base on position information 1 Follows inferences (ex. g. -> p.) Pull statements for these variant records This allows an input like KRAS:p.G12D to match to all equivalent forms of this variant. For example, in the demo database it would result in the following matches","title":"How does Variant Annotation Work?"},{"location":"help/faq/#how-do-i-cite-pori","text":"Please cite Reisle, C. et al. A platform for oncogenomic reporting and interpretation. Nat. Commun. 13, 1\u201311 (2022)","title":"How do I cite PORI?"},{"location":"help/faq/#how-can-i-migrate-our-existing-kb-to-graphkb","text":"The simplest way to do this is using the API. THere are a number of examples of loader/migration scripts in the loaders project which can be used as examples as well as instructions on best practices for adding or including your own. If you would like a new loader for a public/popular resource, please make a ticket/issue on this github space","title":"How Can I Migrate Our Existing KB to GraphKB?"},{"location":"help/faq/#is-there-a-licensing-requirement-for-pori-software","text":"No. PORI is fully open source. The entire platform is released under a GPL-3 open source license.","title":"Is there a Licensing Requirement for PORI Software?"},{"location":"help/faq/#is-there-a-licensing-requirement-for-pori-data","text":"Data is loaded and added externally by the users themselves and therefore there is no licensing requirement. We do provided loading scripts for some externally licensed content, but it is left up to the user to arrange and a license agreement for these sources if they would like to use them. By default the loaders only load the open data.","title":"Is there a Licensing Requirement for PORI Data?"},{"location":"help/faq/#how-can-i-get-involved","text":"We welcome and encourage community contributions! If you have a feature request, bug report, or question please feel free to submit an issue to our GitHub page. If you are not sure which repository to submit the issue to, use this main one by default and we will move or direct the issue as required. If you are a developer and would like to directly add and work on features, please submit a ticket for any new features and indicate that you would like to complete it or comment on an existing ticket. Following discussion with the main developers you should fork the repository and then submit a pull request from your forked version to the main repository. Please see the developer contributing guidelines here","title":"How Can I Get Involved?"},{"location":"help/faq/#how-can-i-try-this-out","text":"We have created a demo version of PORI for users to test without having to set anything up. Please see the IPR and GraphKB demos here","title":"How Can I Try This Out?"},{"location":"help/faq/#what-is-second-pass-matching","text":"Second-pass matching is built into the matching done by the IPR python adapter. First, variants are matched to statements. A second set of variants is then created using the subject and relevance of these matched statements. These newly created variants are passed back into matching to fetch statements. Any statements which are matched based on this second pass are labelled in IPR with the \"inferred\" flag. An example of this might be that a user inputs a variant, KRAS:p.G12D, which matches to a statement with a relevance of \"gain of function\" and a subject of \"KRAS\". This then creates the new variant \"KRAS gain of function\" which matches to a second statement with the subject \"EGFR inhibitor\" and relevance \"resistance\". An inferred match of EGFR inhibitor resistance will be reported for KRAS:p.G12D. Only applicable to positional variants, these steps are skipped when matching category variants. \u21a9 \u21a9","title":"What is Second-Pass Matching?"},{"location":"help/troubleshooting/","text":"Troubleshooting \u00b6 The following page contains questions related to set up, install, and management of the PORI system. Keycloak \u00b6 Invalid parameter: redirect_uri \u00b6 Valid redirect URIs are configured/set via the keycloak admin console. If you have set up the platform following the demo/dev instructions then you should already have the keycloak administrative console available over http. Go to http://localhost:8888/auth in your web browser and you should see something that looks like this. The user and password for this should be admin/admin for the dev setup . Go the \"Clients\" in the left-hand side bar Click on the \"GraphKB\" client Scroll near the bottom on that page and you will find the \"valid redirect URLs\" where you need to add your host","title":"Troubleshooting"},{"location":"help/troubleshooting/#troubleshooting","text":"The following page contains questions related to set up, install, and management of the PORI system.","title":"Troubleshooting"},{"location":"help/troubleshooting/#keycloak","text":"","title":"Keycloak"},{"location":"help/troubleshooting/#invalid-parameter-redirect_uri","text":"Valid redirect URIs are configured/set via the keycloak admin console. If you have set up the platform following the demo/dev instructions then you should already have the keycloak administrative console available over http. Go to http://localhost:8888/auth in your web browser and you should see something that looks like this. The user and password for this should be admin/admin for the dev setup . Go the \"Clients\" in the left-hand side bar Click on the \"GraphKB\" client Scroll near the bottom on that page and you will find the \"valid redirect URLs\" where you need to add your host","title":"Invalid parameter: redirect_uri"},{"location":"ipr/","text":"About IPR \u00b6 Integrated Pipeline Reports (IPR) is the main reporting application of IPR. It is a web application that is used to review and curate reports which summarize the interpretation of molecular data from precision oncology patients. This project is modularized across three repositories: web client , REST API , and a python adapter . The API and web client are servers and are provided as docker containers. The python adapter is used to build reports and upload them into IPR. Reports in IPR are divided into a series of sections. These are either: created by the IPR python adaptor (ex. knowledge base matches section); manually curated post-report creation (ex. analyst comments); or generated beforehand and included in the content passed to IPR via the python adaptor (ex. optional analyses).","title":"About IPR"},{"location":"ipr/#about-ipr","text":"Integrated Pipeline Reports (IPR) is the main reporting application of IPR. It is a web application that is used to review and curate reports which summarize the interpretation of molecular data from precision oncology patients. This project is modularized across three repositories: web client , REST API , and a python adapter . The API and web client are servers and are provided as docker containers. The python adapter is used to build reports and upload them into IPR. Reports in IPR are divided into a series of sections. These are either: created by the IPR python adaptor (ex. knowledge base matches section); manually curated post-report creation (ex. analyst comments); or generated beforehand and included in the content passed to IPR via the python adaptor (ex. optional analyses).","title":"About IPR"},{"location":"ipr/kb_matches/","text":"KB Matches \u00b6 The knowledge base (KB) matches section of the report is generated by the IPR python adapter during creation of a report. Any input core variants are annotated by matching against a GraphKB API instance. Known vs Observed Variants \u00b6 As GraphKB is able to support matching non-specfic variant notation, a distinction is needed between the sample variant and the variant it was matched to by the knowledge base. Linking Matched Statements \u00b6 The ID of the matched statement is included in the upload to facilitate direct linking to the paired GraphKB client instance (this feature is not available in the demo application). To see the matched annotation in GraphKB with links to and/or information about the original records click the \"open in new tab\" icon under actions This will bring you to the corresponding GraphKB page for the matched statement(s).","title":"KB Matches"},{"location":"ipr/kb_matches/#kb-matches","text":"The knowledge base (KB) matches section of the report is generated by the IPR python adapter during creation of a report. Any input core variants are annotated by matching against a GraphKB API instance.","title":"KB Matches"},{"location":"ipr/kb_matches/#known-vs-observed-variants","text":"As GraphKB is able to support matching non-specfic variant notation, a distinction is needed between the sample variant and the variant it was matched to by the knowledge base.","title":"Known vs Observed Variants"},{"location":"ipr/kb_matches/#linking-matched-statements","text":"The ID of the matched statement is included in the upload to facilitate direct linking to the paired GraphKB client instance (this feature is not available in the demo application). To see the matched annotation in GraphKB with links to and/or information about the original records click the \"open in new tab\" icon under actions This will bring you to the corresponding GraphKB page for the matched statement(s).","title":"Linking Matched Statements"},{"location":"ipr/manual_curation/","text":"Manual Curation \u00b6 IPR supports manually curating/editing many of the sections in the report. Analyst Comments \u00b6 This a free-text section of the report where the case analyst may summarize the findings of the report. Optionally Semi-Automated Comments can optionally be auto-populated by the report loader Therapeutic Options \u00b6 In this section tumour alterations are reviewed and those representing the most likely potential therapeutic targets are highlighted, with details on the associated therapy or general drug class, level of evidence, and any relevant clinical trials. Potential caveats are also specified. Alterations associated with potential resistance to relevant therapies are also documented. Optionally Semi-Automated Therapeutic options can optionally be auto-populated by the report loader Video Demo This section has a video demo on the demo page Clicking the \"Add row\" button will bring the user to a form which auto-completes from the GraphKB API. Discussion \u00b6 There is a section of the report for recording comments made on the report when it is presented/discussed at the molecular tumour board. This may record the decisions made by the board or anything else of interest that was brought up at the meeting. Additional Content \u00b6 Sometimes the case analyst may have additional images they would like to include on a one-off basis. If these do not correspond to a built-in section of the report they can be included here. The example below is showing read-support in IGV for a structural variant of interest","title":"Manual Curation"},{"location":"ipr/manual_curation/#manual-curation","text":"IPR supports manually curating/editing many of the sections in the report.","title":"Manual Curation"},{"location":"ipr/manual_curation/#analyst-comments","text":"This a free-text section of the report where the case analyst may summarize the findings of the report. Optionally Semi-Automated Comments can optionally be auto-populated by the report loader","title":"Analyst Comments"},{"location":"ipr/manual_curation/#therapeutic-options","text":"In this section tumour alterations are reviewed and those representing the most likely potential therapeutic targets are highlighted, with details on the associated therapy or general drug class, level of evidence, and any relevant clinical trials. Potential caveats are also specified. Alterations associated with potential resistance to relevant therapies are also documented. Optionally Semi-Automated Therapeutic options can optionally be auto-populated by the report loader Video Demo This section has a video demo on the demo page Clicking the \"Add row\" button will bring the user to a form which auto-completes from the GraphKB API.","title":"Therapeutic Options"},{"location":"ipr/manual_curation/#discussion","text":"There is a section of the report for recording comments made on the report when it is presented/discussed at the molecular tumour board. This may record the decisions made by the board or anything else of interest that was brought up at the meeting.","title":"Discussion"},{"location":"ipr/manual_curation/#additional-content","text":"Sometimes the case analyst may have additional images they would like to include on a one-off basis. If these do not correspond to a built-in section of the report they can be included here. The example below is showing read-support in IGV for a structural variant of interest","title":"Additional Content"},{"location":"ipr/templates/","text":"Templates \u00b6 There is a lot of optional content that can be included in a PORI report by default. However you may not have all of these different analyses depending on how your bioinformatics pipeline is set up. To faciliate this, IPR incorporates templates. { \"template\" : \"TEMPLATE NAME\" } These tell the client (and API) what sections to expect when a report is created or displayed. Templates can be configured and created through the administrator interface in IPR client. Editing a template allows the administrator to configure what sections should be displayed, what image should be used for the printed report header, and the name of the template. Individual sections can be excluded or included through the checklist. As new analyses are added to the report, this list will increase.","title":"Templates"},{"location":"ipr/templates/#templates","text":"There is a lot of optional content that can be included in a PORI report by default. However you may not have all of these different analyses depending on how your bioinformatics pipeline is set up. To faciliate this, IPR incorporates templates. { \"template\" : \"TEMPLATE NAME\" } These tell the client (and API) what sections to expect when a report is created or displayed. Templates can be configured and created through the administrator interface in IPR client. Editing a template allows the administrator to configure what sections should be displayed, what image should be used for the printed report header, and the name of the template. Individual sections can be excluded or included through the checklist. As new analyses are added to the report, this list will increase.","title":"Templates"},{"location":"ipr/upload/","text":"Uploading A Report \u00b6 Install \u00b6 Before you can generate and upload reports you will first need to install the package with pip pip install ipr This will require python 3.6 or greater. Use the --help / -h option to see a help menu with full options. ipr -h Then this can be used to upload a report from the command line. Users should use the --ipr_url argument to point the loader to their particular instance of IPR. A similar option exists for GraphKB. ipr -c /path/to/your/json/input/file.json --ipr_url https://youriprinstance-api.com/api or as part of a script (see the developer reference ) from ipr.main import create_report create_report ( ... ) The pre-generated content (ex. variant calls) of the report is passed to this function via a JSON object. The various sections of this object are desribed in the core variants and optional analyses sections. The full specification for the upload can be viewed/explored via the JSON schema explorer here Most content is optional with a few top-level elements required. JSON Examples \u00b6 Below are a couple of simplified examples of what the input JSON may look like No Variants \u00b6 It is possible to load a report where no variants were called. In such cases, only the 4 main top-level fields are required { \"project\" : \"string\" , \"patientId\" : \"PATIENT 0\" , \"template\" : \"genomic\" , \"kbDiseaseMatch\" : \"colorectal cancer\" } Only Small Mutations \u00b6 To include small mutations in the JSON, simply add the \"smallMutations\" property. This is a list of objects (dicts if you are more familiar with python). Any number of small mutations can be included. { \"patientId\" : \"PATIENT001\" , \"kbDiseaseMatch\" : \"colorectal cancer\" , \"project\" : \"TEST\" , \"template\" : \"genomic\" , \"smallMutations\" : [ { \"gene\" : \"APC\" , \"proteinChange\" : \"p.Thr1556fs\" , \"transcript\" : \"ENST00000457016\" , \"hgvsGenomic\" : \"5:g.112175951_112175952insA\" , \"hgvsProtein\" : \"APC:p.Thr1556fs\" , \"chromosome\" : \"5\" , \"startPosition\" : 112175951 , \"endPosition\" : 112175951 , \"refSeq\" : \"G\" , \"altSeq\" : \"GA\" }, { \"gene\" : \"XRCC1\" , \"proteinChange\" : \"p.Q399R\" , \"transcript\" : \"ENST00000543982\" , \"hgvsGenomic\" : \"19:g.44051039_44051040delCAinsAG\" , \"chromosome\" : \"19\" , \"startPosition\" : 44051039 , \"endPosition\" : 44051040 , \"refSeq\" : \"CAG\" , \"altSeq\" : \"AGG\" } ] } Small Mutations and Expression \u00b6 Expression variants can be included with or without small mutations. { \"patientId\" : \"PATIENT001\" , \"kbDiseaseMatch\" : \"colorectal cancer\" , \"project\" : \"TEST\" , \"template\" : \"genomic\" , \"smallMutations\" : [ { \"gene\" : \"APC\" , \"proteinChange\" : \"p.Thr1556fs\" , \"transcript\" : \"ENST00000457016\" , \"hgvsGenomic\" : \"5:g.112175951_112175952insA\" , \"hgvsProtein\" : \"APC:p.Thr1556fs\" , \"chromosome\" : \"5\" , \"startPosition\" : 112175951 , \"endPosition\" : 112175951 , \"refSeq\" : \"G\" , \"altSeq\" : \"GA\" } ], \"expressionVariants\" : [ { \"gene\" : \"APC\" , \"kbCategory\" : \"reduced expression\" } ] } Top-Level Fields Reference \u00b6 All top-level fields are listed in detail below Field Type Example Description kbDiseaseMatch (required) string \"colorectal cancer\" the disease name to used in matching to GraphKB. This will be used to populate the matchedCancer flag patientId (required) string project (required) string \"POG\" The name of the project that this report will be uploaded to template (required) string \"genomic\" the type of report the user is uploading. This must match the name of one of the template types in the database. These are configurable via the IPR client interface but the default values in the demo database are genomic and probe ageOfConsent number alternateIdentifier string biopsyDate string \"2021-06-04T16:36:37.279Z\" the date the biopsy/sample was taken/collected biopsyName string \"biop1\" ploidy string \"diploid\" The ploidy model used for calling copy variants and determining mutation affected alleles presentationDate string date this case is scheduled to be presented to the molecular tumour board subtyping string \"Luminal A\" tumourContent number 45 the tumour content or purity of the current sample","title":"Uploading A Report"},{"location":"ipr/upload/#uploading-a-report","text":"","title":"Uploading A Report"},{"location":"ipr/upload/#install","text":"Before you can generate and upload reports you will first need to install the package with pip pip install ipr This will require python 3.6 or greater. Use the --help / -h option to see a help menu with full options. ipr -h Then this can be used to upload a report from the command line. Users should use the --ipr_url argument to point the loader to their particular instance of IPR. A similar option exists for GraphKB. ipr -c /path/to/your/json/input/file.json --ipr_url https://youriprinstance-api.com/api or as part of a script (see the developer reference ) from ipr.main import create_report create_report ( ... ) The pre-generated content (ex. variant calls) of the report is passed to this function via a JSON object. The various sections of this object are desribed in the core variants and optional analyses sections. The full specification for the upload can be viewed/explored via the JSON schema explorer here Most content is optional with a few top-level elements required.","title":"Install"},{"location":"ipr/upload/#json-examples","text":"Below are a couple of simplified examples of what the input JSON may look like","title":"JSON Examples"},{"location":"ipr/upload/#no-variants","text":"It is possible to load a report where no variants were called. In such cases, only the 4 main top-level fields are required { \"project\" : \"string\" , \"patientId\" : \"PATIENT 0\" , \"template\" : \"genomic\" , \"kbDiseaseMatch\" : \"colorectal cancer\" }","title":"No Variants"},{"location":"ipr/upload/#only-small-mutations","text":"To include small mutations in the JSON, simply add the \"smallMutations\" property. This is a list of objects (dicts if you are more familiar with python). Any number of small mutations can be included. { \"patientId\" : \"PATIENT001\" , \"kbDiseaseMatch\" : \"colorectal cancer\" , \"project\" : \"TEST\" , \"template\" : \"genomic\" , \"smallMutations\" : [ { \"gene\" : \"APC\" , \"proteinChange\" : \"p.Thr1556fs\" , \"transcript\" : \"ENST00000457016\" , \"hgvsGenomic\" : \"5:g.112175951_112175952insA\" , \"hgvsProtein\" : \"APC:p.Thr1556fs\" , \"chromosome\" : \"5\" , \"startPosition\" : 112175951 , \"endPosition\" : 112175951 , \"refSeq\" : \"G\" , \"altSeq\" : \"GA\" }, { \"gene\" : \"XRCC1\" , \"proteinChange\" : \"p.Q399R\" , \"transcript\" : \"ENST00000543982\" , \"hgvsGenomic\" : \"19:g.44051039_44051040delCAinsAG\" , \"chromosome\" : \"19\" , \"startPosition\" : 44051039 , \"endPosition\" : 44051040 , \"refSeq\" : \"CAG\" , \"altSeq\" : \"AGG\" } ] }","title":"Only Small Mutations"},{"location":"ipr/upload/#small-mutations-and-expression","text":"Expression variants can be included with or without small mutations. { \"patientId\" : \"PATIENT001\" , \"kbDiseaseMatch\" : \"colorectal cancer\" , \"project\" : \"TEST\" , \"template\" : \"genomic\" , \"smallMutations\" : [ { \"gene\" : \"APC\" , \"proteinChange\" : \"p.Thr1556fs\" , \"transcript\" : \"ENST00000457016\" , \"hgvsGenomic\" : \"5:g.112175951_112175952insA\" , \"hgvsProtein\" : \"APC:p.Thr1556fs\" , \"chromosome\" : \"5\" , \"startPosition\" : 112175951 , \"endPosition\" : 112175951 , \"refSeq\" : \"G\" , \"altSeq\" : \"GA\" } ], \"expressionVariants\" : [ { \"gene\" : \"APC\" , \"kbCategory\" : \"reduced expression\" } ] }","title":"Small Mutations and Expression"},{"location":"ipr/upload/#top-level-fields-reference","text":"All top-level fields are listed in detail below Field Type Example Description kbDiseaseMatch (required) string \"colorectal cancer\" the disease name to used in matching to GraphKB. This will be used to populate the matchedCancer flag patientId (required) string project (required) string \"POG\" The name of the project that this report will be uploaded to template (required) string \"genomic\" the type of report the user is uploading. This must match the name of one of the template types in the database. These are configurable via the IPR client interface but the default values in the demo database are genomic and probe ageOfConsent number alternateIdentifier string biopsyDate string \"2021-06-04T16:36:37.279Z\" the date the biopsy/sample was taken/collected biopsyName string \"biop1\" ploidy string \"diploid\" The ploidy model used for calling copy variants and determining mutation affected alleles presentationDate string date this case is scheduled to be presented to the molecular tumour board subtyping string \"Luminal A\" tumourContent number 45 the tumour content or purity of the current sample","title":"Top-Level Fields Reference"},{"location":"ipr/core_variants/","text":"About \u00b6 The core variant types are: expression variants, copy number variants, structural variants, and small mutations. All of these variants are matched against GraphKB and annotated by the python IPR adapter during upload to IPR.","title":"About"},{"location":"ipr/core_variants/#about","text":"The core variant types are: expression variants, copy number variants, structural variants, and small mutations. All of these variants are matched against GraphKB and annotated by the python IPR adapter during upload to IPR.","title":"About"},{"location":"ipr/core_variants/copy/","text":"Copy Variants \u00b6 Copy variants should be passed to the IPR python adapter in the main report content JSON. { \"copyVariants\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields Field Type Example Description gene (required) string \"KRAS\" the gene name kbCategory (required) string? the graphkb copy variant vocabulary term this variant belongs to. By default only amplifications and deep deletions are matched chromosomeBand string \"X:p12.2\" cna number? 1.22 The copy number alteration (CNA) ratio copyChange integer? -2 the ploidy corrected copy change value end integer? the genomic end position of the copy segment this gene copy number was called from log2Cna number? lohState string \"HET\" the loss-of-heterozygosity category for this gene region start integer? the genomic start position of the copy segment this gene copy number was called from","title":"Copy Variants"},{"location":"ipr/core_variants/copy/#copy-variants","text":"Copy variants should be passed to the IPR python adapter in the main report content JSON. { \"copyVariants\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields Field Type Example Description gene (required) string \"KRAS\" the gene name kbCategory (required) string? the graphkb copy variant vocabulary term this variant belongs to. By default only amplifications and deep deletions are matched chromosomeBand string \"X:p12.2\" cna number? 1.22 The copy number alteration (CNA) ratio copyChange integer? -2 the ploidy corrected copy change value end integer? the genomic end position of the copy segment this gene copy number was called from log2Cna number? lohState string \"HET\" the loss-of-heterozygosity category for this gene region start integer? the genomic start position of the copy segment this gene copy number was called from","title":"Copy Variants"},{"location":"ipr/core_variants/expression/","text":"Expression Variants \u00b6 In an effort to be extensible and quick to use there are only two required fields for expression variants: the name of the gene (gene) and whether the expression of that gene is up-regulated or down-regulated (kbCategory). Field Type Example Description gene string KRAS the gene name (or source identifier) kbCategory string increased expression the graphkb expression variant vocabulary term this variant belongs to. One of: increased expression, reduced expression The kbCategory field is how IPR knows this row/entry should be treated as a variant/outlier or just expression information input for context. This way the thresholds and cut-off values used are determined by the users uploading the reports. Computing the various expression metrics is largely optional and done prior by the user prior to upload/report-creation. These metrics are displayed to the analyst reviewing the case along with the variant status. The standard fields we provide input for are listed below. As with the other variants, these should be passed to the IPR python adapter in the main report content JSON. { \"expressionVariants\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields (in addition to the required fields). Examples of how these fields are calculated can be found in the scripting examples section . Field Type Description biopsySiteFoldChange number? the fold change with respect to the median of the biopsy site expression comparator cohort biopsySitePercentile number? the percentile with respect to the biopsy site expression comparator cohort biopsySiteQC number? biopsySiteZScore number? the zscore with respect to the biopsy site expression comparator cohort biopsySitekIQR number? the kIQR with respect to the biopsy site expression comparator cohort diseaseFoldChange number? the fold change with respect to the median of the disease expression comparator cohort diseasePercentile number? the percentile with respect to the disease expression comparator cohort diseaseQC number? diseaseZScore number? the zscore with respect to the disease expression comparator cohort diseasekIQR number? the kIQR with respect to the disease expression comparator cohort expressionState string Overloads the kb-category just for display purposes (does not affect matching) histogramImage string? path to the expression density/histogram plot primarySiteFoldChange number? the fold change with respect to the median of the primary site expression comparator cohort primarySitePercentile number? the percentile with respect to the primary site expression comparator cohort primarySiteQC number? primarySiteZScore number? the zscore with respect to the primary site expression comparator cohort primarySitekIQR number? the kIQR with respect to the primary site expression comparator cohort rnaReads number? rpkm number? reads per kilobase of transcript, per million mapped reads tpm number? transcript per million Metrics \u00b6 Z-Score \u00b6 The z-score (A.K.A. standard score ) is a metric used to describe a data point relative to a distribution with respect to the variance within that distribution. Formally it is defined as \\[ z = \\frac{\\mu - x}{\\sigma} \\] k-IQR \u00b6 The k interquartile range is a used to compare a point against a distribution. It is defined as the distance of a given point from the median scaled by the interquartile range \\[ k = \\frac{Q_2 - x}{Q_3 - Q_1} \\] This metric is similar to the z-score but more robust to outliers. Percentile \u00b6 The percentile rank is a non-parametric way of measuring a given data point relative to the distribution. Comparators \u00b6 All of the standard expression metrics in IPR are expected to be calculated against a reference distribution of expression samples. To this end, IPR provides a number of fields to record which distributions were used. This ensures that the final result is interperable and reproducible. A complete list of comparators can be found in the comparators section of the user manual. Expression comparators fall into three main groups: disease, primary site, and biopsy site. Disease \u00b6 The reference distribution that most closely matches the diagnosis of the current sample Primary Site \u00b6 The reference distribution that most closely matches the non-diseased/normal expression of the primary site tissue Biopsy Site \u00b6 The reference distribution that most closely matches the non-diseased/normal expression of the biopsy site tissue. This is important for metastatic samples where the biopsy site and primary site differ. Images \u00b6 The use can optionally include expression density plots to allow the user to view the relative expression of the current sample compared to a specific distribution. Info These will be passed to the report upload function via the images section of the JSON input key: expDensity\\.(\\S+) In the above the pattern is expected to be expDensity.<gene name> where the gene name matches the gene name(s) used for the expression variant definitions. Where these plots are included for the genes listed as variants they will be shown along with the expression data in the expression variants section. In the interface these will appear in the actions tab where available. This will bring up the expression density plot in a popup","title":"Expression Variants"},{"location":"ipr/core_variants/expression/#expression-variants","text":"In an effort to be extensible and quick to use there are only two required fields for expression variants: the name of the gene (gene) and whether the expression of that gene is up-regulated or down-regulated (kbCategory). Field Type Example Description gene string KRAS the gene name (or source identifier) kbCategory string increased expression the graphkb expression variant vocabulary term this variant belongs to. One of: increased expression, reduced expression The kbCategory field is how IPR knows this row/entry should be treated as a variant/outlier or just expression information input for context. This way the thresholds and cut-off values used are determined by the users uploading the reports. Computing the various expression metrics is largely optional and done prior by the user prior to upload/report-creation. These metrics are displayed to the analyst reviewing the case along with the variant status. The standard fields we provide input for are listed below. As with the other variants, these should be passed to the IPR python adapter in the main report content JSON. { \"expressionVariants\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields (in addition to the required fields). Examples of how these fields are calculated can be found in the scripting examples section . Field Type Description biopsySiteFoldChange number? the fold change with respect to the median of the biopsy site expression comparator cohort biopsySitePercentile number? the percentile with respect to the biopsy site expression comparator cohort biopsySiteQC number? biopsySiteZScore number? the zscore with respect to the biopsy site expression comparator cohort biopsySitekIQR number? the kIQR with respect to the biopsy site expression comparator cohort diseaseFoldChange number? the fold change with respect to the median of the disease expression comparator cohort diseasePercentile number? the percentile with respect to the disease expression comparator cohort diseaseQC number? diseaseZScore number? the zscore with respect to the disease expression comparator cohort diseasekIQR number? the kIQR with respect to the disease expression comparator cohort expressionState string Overloads the kb-category just for display purposes (does not affect matching) histogramImage string? path to the expression density/histogram plot primarySiteFoldChange number? the fold change with respect to the median of the primary site expression comparator cohort primarySitePercentile number? the percentile with respect to the primary site expression comparator cohort primarySiteQC number? primarySiteZScore number? the zscore with respect to the primary site expression comparator cohort primarySitekIQR number? the kIQR with respect to the primary site expression comparator cohort rnaReads number? rpkm number? reads per kilobase of transcript, per million mapped reads tpm number? transcript per million","title":"Expression Variants"},{"location":"ipr/core_variants/expression/#metrics","text":"","title":"Metrics"},{"location":"ipr/core_variants/expression/#z-score","text":"The z-score (A.K.A. standard score ) is a metric used to describe a data point relative to a distribution with respect to the variance within that distribution. Formally it is defined as \\[ z = \\frac{\\mu - x}{\\sigma} \\]","title":"Z-Score"},{"location":"ipr/core_variants/expression/#k-iqr","text":"The k interquartile range is a used to compare a point against a distribution. It is defined as the distance of a given point from the median scaled by the interquartile range \\[ k = \\frac{Q_2 - x}{Q_3 - Q_1} \\] This metric is similar to the z-score but more robust to outliers.","title":"k-IQR"},{"location":"ipr/core_variants/expression/#percentile","text":"The percentile rank is a non-parametric way of measuring a given data point relative to the distribution.","title":"Percentile"},{"location":"ipr/core_variants/expression/#comparators","text":"All of the standard expression metrics in IPR are expected to be calculated against a reference distribution of expression samples. To this end, IPR provides a number of fields to record which distributions were used. This ensures that the final result is interperable and reproducible. A complete list of comparators can be found in the comparators section of the user manual. Expression comparators fall into three main groups: disease, primary site, and biopsy site.","title":"Comparators"},{"location":"ipr/core_variants/expression/#disease","text":"The reference distribution that most closely matches the diagnosis of the current sample","title":"Disease"},{"location":"ipr/core_variants/expression/#primary-site","text":"The reference distribution that most closely matches the non-diseased/normal expression of the primary site tissue","title":"Primary Site"},{"location":"ipr/core_variants/expression/#biopsy-site","text":"The reference distribution that most closely matches the non-diseased/normal expression of the biopsy site tissue. This is important for metastatic samples where the biopsy site and primary site differ.","title":"Biopsy Site"},{"location":"ipr/core_variants/expression/#images","text":"The use can optionally include expression density plots to allow the user to view the relative expression of the current sample compared to a specific distribution. Info These will be passed to the report upload function via the images section of the JSON input key: expDensity\\.(\\S+) In the above the pattern is expected to be expDensity.<gene name> where the gene name matches the gene name(s) used for the expression variant definitions. Where these plots are included for the genes listed as variants they will be shown along with the expression data in the expression variants section. In the interface these will appear in the actions tab where available. This will bring up the expression density plot in a popup","title":"Images"},{"location":"ipr/core_variants/mutations/","text":"Small Mutations \u00b6 Small mutations are composed of indels and single nucleotide variants. These should be passed to the IPR python adapter in the main report content JSON. { \"smallMutations\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields Field Type Example Description altSeq (required) string \"C\" the alternate sequence chromosome (required) string \"X\" the chromosome this mutation is located on endPosition (required) integer? 1234 the genomic end poition of this variant gene (required) string \"KRAS\" the gene name proteinChange (required) string? \"p.G12D\" the HGVS protein notation. Can also be the cds or genomic notation for variants where there is no equivalent protein notation. Protein notation is preferred. refSeq (required) string? \"A\" the reference sequence startPosition (required) integer? 1234 the genomic start position of this variant transcript (required) string? \"ENST00001.2\" the transcript name detectedIn string \"DNA/RNA\" the sample types this variant was detected in hgvsCds string? \"ENST0001:c.1234+3A>G\" HGVS coding sequence notation for this variant hgvsGenomic string? \"1:g.1234A>G\" HGVS genomic notation for this variant hgvsProtein string? \"KRAS:p.G12D\" HGVS protein notation for this variant ncbiBuild string? \"GRCh37\" the genome reference assembly build version normalAltCount integer? 1 the number of alternate reads in the normal genome supporting the mutation normalDepth integer? 1 the total number of reads at this position in the normal genome normalRefCount integer? 1 the number of reference reads in the normal genome rnaAltCount integer? 1 the number of alternate reads in the rna supporting the mutation rnaDepth integer? 2 the total number of reads at this position in the rna rnaRefCount integer? 1 the number of reference reads in the rna tumourAltCount integer? 1 the number of alternate reads in the tumour genome supporting the mutation tumourDepth integer? 2 the total number of reads at this position in the tumour genome, if not given this will be inferred based on the ref and alt count sum tumourRefCount integer? 1 the number of reference reads in the tumour genome zygosity string? \"het\"","title":"Small Mutations"},{"location":"ipr/core_variants/mutations/#small-mutations","text":"Small mutations are composed of indels and single nucleotide variants. These should be passed to the IPR python adapter in the main report content JSON. { \"smallMutations\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields Field Type Example Description altSeq (required) string \"C\" the alternate sequence chromosome (required) string \"X\" the chromosome this mutation is located on endPosition (required) integer? 1234 the genomic end poition of this variant gene (required) string \"KRAS\" the gene name proteinChange (required) string? \"p.G12D\" the HGVS protein notation. Can also be the cds or genomic notation for variants where there is no equivalent protein notation. Protein notation is preferred. refSeq (required) string? \"A\" the reference sequence startPosition (required) integer? 1234 the genomic start position of this variant transcript (required) string? \"ENST00001.2\" the transcript name detectedIn string \"DNA/RNA\" the sample types this variant was detected in hgvsCds string? \"ENST0001:c.1234+3A>G\" HGVS coding sequence notation for this variant hgvsGenomic string? \"1:g.1234A>G\" HGVS genomic notation for this variant hgvsProtein string? \"KRAS:p.G12D\" HGVS protein notation for this variant ncbiBuild string? \"GRCh37\" the genome reference assembly build version normalAltCount integer? 1 the number of alternate reads in the normal genome supporting the mutation normalDepth integer? 1 the total number of reads at this position in the normal genome normalRefCount integer? 1 the number of reference reads in the normal genome rnaAltCount integer? 1 the number of alternate reads in the rna supporting the mutation rnaDepth integer? 2 the total number of reads at this position in the rna rnaRefCount integer? 1 the number of reference reads in the rna tumourAltCount integer? 1 the number of alternate reads in the tumour genome supporting the mutation tumourDepth integer? 2 the total number of reads at this position in the tumour genome, if not given this will be inferred based on the ref and alt count sum tumourRefCount integer? 1 the number of reference reads in the tumour genome zygosity string? \"het\"","title":"Small Mutations"},{"location":"ipr/core_variants/structural/","text":"Structural Variants \u00b6 Structural variants should be passed to the IPR python adapter in the main report content JSON. { \"structuralVariants\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields Field Type Example Description breakpoint (required) string \"12:123456|14:1244662\" description of the breakpoints involved in this structural variant eventType (required) string \"deletion\" the type of underlying structural variant exon1 (required) integer? 1 the 5' (n-terminal) exon exon2 (required) integer? 2 the 3' (c-terminal) exon gene1 (required) string \"EWSR1\" the 5' (n-terminal) gene name gene2 (required) string \"FLI1\" the 3' (c-terminal) gene name cTermTranscript string? \"ENST0004.5\" the 5' transcript name conventionalName string cytogenetic descriptor detectedIn string \"DNA\" the sample type(s) this SV was detected in highQuality boolean? This structural variant has a high level of supporting evidence nTermTranscript string? \"ENST0001.2\" the 3' transcript name omicSupport boolean? flag to indicate this SV has supprt from both genome and transcriptome svg string? svg image file content for this SV svgTitle string? The title to accompany this SV Images \u00b6 When the svg field contains an SVG image string this image will be displayed by the report via the actions tab (see button circled in red below). This allows the user to bring up the visualization when they are reviewing the structural variants in the report. Clicking this button will bring the user to a pop up showing the visualization. The visualization shown below was created with MAVIS .","title":"Structural Variants"},{"location":"ipr/core_variants/structural/#structural-variants","text":"Structural variants should be passed to the IPR python adapter in the main report content JSON. { \"structuralVariants\" : [ // varia nts ] } Each variant is an object which may contain any of the following fields Field Type Example Description breakpoint (required) string \"12:123456|14:1244662\" description of the breakpoints involved in this structural variant eventType (required) string \"deletion\" the type of underlying structural variant exon1 (required) integer? 1 the 5' (n-terminal) exon exon2 (required) integer? 2 the 3' (c-terminal) exon gene1 (required) string \"EWSR1\" the 5' (n-terminal) gene name gene2 (required) string \"FLI1\" the 3' (c-terminal) gene name cTermTranscript string? \"ENST0004.5\" the 5' transcript name conventionalName string cytogenetic descriptor detectedIn string \"DNA\" the sample type(s) this SV was detected in highQuality boolean? This structural variant has a high level of supporting evidence nTermTranscript string? \"ENST0001.2\" the 3' transcript name omicSupport boolean? flag to indicate this SV has supprt from both genome and transcriptome svg string? svg image file content for this SV svgTitle string? The title to accompany this SV","title":"Structural Variants"},{"location":"ipr/core_variants/structural/#images","text":"When the svg field contains an SVG image string this image will be displayed by the report via the actions tab (see button circled in red below). This allows the user to bring up the visualization when they are reviewing the structural variants in the report. Clicking this button will bring the user to a pop up showing the visualization. The visualization shown below was created with MAVIS .","title":"Images"},{"location":"ipr/optional_analyses/burden/","text":"Mutation Burden \u00b6 Data \u00b6 Measure of the relative counts of various types of mutations compared to those from a given cohort of samples. The \"role\" determines with comparator these values are calculated in reference to { \"mutationBurden\" : [ { \"snv\" : 4 , \"snvTruncating\" : 0 , \"indels\" : 0 , \"indelsFrameshift\" : 0 , \"sv\" : 92 , \"svExpressed\" : 40 , \"snvPercentile\" : 4 , \"indelPercentile\" : 10 , \"svPercentile\" : 60 , \"role\" : \"primary\" } ], } Field Type Example Description role (required) string indelPercentile number 1 Percentile of the count of indels in the current sample relative to a reference distribution indels integer Absolute number of indels in the current sample indelsFrameshift integer Absolute number of indels which result in a frameshift in the current sample snv integer Absolute number of single nucleotide variants in the current sample snvPercentile number Percentile of the count of single nucleotide variants in the current sample relative to a reference distribution snvTruncating integer Absolute number of single nucleotide variants which are truncating in the current sample sv integer Absolute number of structural variants in the current sample svExpressed integer Absolute number of expressed (support in RNA) structural variants in the current sample svPercentile number Percentile of the count of structural variants in the current sample relative to a reference distribution Comparators and Roles \u00b6 The role used by the mutation burden data is linked to the mutation burden images in the report that is created by the comparators input . The images use the following key: mutationBurden\\.(barplot|density|legend)_(sv|snv|indel)\\.(primary|secondary|tertiary|quaternary) which maps to the comparators mutation burden (primary) mutation burden (secondary) mutation burden (tertiary) mutation burden (quaternary) Therefore for a complete mutation burden entry one might see the following { \"mutationBurden\" : [ { \"snv\" : 4 , \"snvTruncating\" : 0 , \"indels\" : 0 , \"indelsFrameshift\" : 0 , \"sv\" : 92 , \"svExpressed\" : 40 , \"snvPercentile\" : 4 , \"indelPercentile\" : 10 , \"svPercentile\" : 60 , \"role\" : \"primary\" } ], \"comparators\" : [ { \"analysisRole\" : \"mutation burden (primary)\" , \"name\" : \"TCGA COAD\" } ], \"images\" : [ { \"key\" : \"mutationBurden.barplot_snv.primary\" , \"path\" : \"/path/to/image/file.png\" }, { \"key\" : \"mutationBurden.legend_snv.primary\" , \"path\" : \"/path/to/other/image/file.png\" }, { \"key\" : \"mutationBurden.density_snv.primary\" , \"path\" : \"/path/to/other-other/image/file.png\" } ] } Note that the above only loaded images for the SNVs but similar images would be expected for SVs and indels. Images \u00b6 A number of images can optionally be included and will be displayed in the mutation burden section of the report. These are summary images which represent the count of a variant type in the current report relative to the counts of samples in the reference distribution (based on the comparators listed above). These images are generated by the user prior to creating the report. full pattern: mutationBurden\\.(barplot|density|legend)_(sv|snv|indel)\\.(primary|secondary|tertiary|quaternary) SNVs \u00b6 key: mutationBurden\\.density_snv\\.(primary|secondary|tertiary|quaternary) key: mutationBurden\\.barplot_snv\\.(primary|secondary|tertiary|quaternary) key: mutationBurden\\.density_indel\\.(primary|secondary|tertiary|quaternary) Indels \u00b6 key: mutationBurden\\.barplot_indel\\.(primary|secondary|tertiary|quaternary) Structural Variants \u00b6 key: mutationBurden\\.density_sv\\.(primary|secondary|tertiary|quaternary) SV-specific Comparator Overloading \u00b6 There are special overload comparators for stuctural variants since they often have a different comparator data set from the SNV and Indels. Specifying an SV specific comparator will overload the more general comparator for the SV types mutation burden SV (primary) mutation burden SV (secondary) mutation burden SV (tertiary) mutation burden SV (quaternary) This means that when the report client lists the comparator that corresponds to the images and data it will use the SV-specific value where it exists instead of the more general comparator name.","title":"Mutation Burden"},{"location":"ipr/optional_analyses/burden/#mutation-burden","text":"","title":"Mutation Burden"},{"location":"ipr/optional_analyses/burden/#data","text":"Measure of the relative counts of various types of mutations compared to those from a given cohort of samples. The \"role\" determines with comparator these values are calculated in reference to { \"mutationBurden\" : [ { \"snv\" : 4 , \"snvTruncating\" : 0 , \"indels\" : 0 , \"indelsFrameshift\" : 0 , \"sv\" : 92 , \"svExpressed\" : 40 , \"snvPercentile\" : 4 , \"indelPercentile\" : 10 , \"svPercentile\" : 60 , \"role\" : \"primary\" } ], } Field Type Example Description role (required) string indelPercentile number 1 Percentile of the count of indels in the current sample relative to a reference distribution indels integer Absolute number of indels in the current sample indelsFrameshift integer Absolute number of indels which result in a frameshift in the current sample snv integer Absolute number of single nucleotide variants in the current sample snvPercentile number Percentile of the count of single nucleotide variants in the current sample relative to a reference distribution snvTruncating integer Absolute number of single nucleotide variants which are truncating in the current sample sv integer Absolute number of structural variants in the current sample svExpressed integer Absolute number of expressed (support in RNA) structural variants in the current sample svPercentile number Percentile of the count of structural variants in the current sample relative to a reference distribution","title":"Data"},{"location":"ipr/optional_analyses/burden/#comparators-and-roles","text":"The role used by the mutation burden data is linked to the mutation burden images in the report that is created by the comparators input . The images use the following key: mutationBurden\\.(barplot|density|legend)_(sv|snv|indel)\\.(primary|secondary|tertiary|quaternary) which maps to the comparators mutation burden (primary) mutation burden (secondary) mutation burden (tertiary) mutation burden (quaternary) Therefore for a complete mutation burden entry one might see the following { \"mutationBurden\" : [ { \"snv\" : 4 , \"snvTruncating\" : 0 , \"indels\" : 0 , \"indelsFrameshift\" : 0 , \"sv\" : 92 , \"svExpressed\" : 40 , \"snvPercentile\" : 4 , \"indelPercentile\" : 10 , \"svPercentile\" : 60 , \"role\" : \"primary\" } ], \"comparators\" : [ { \"analysisRole\" : \"mutation burden (primary)\" , \"name\" : \"TCGA COAD\" } ], \"images\" : [ { \"key\" : \"mutationBurden.barplot_snv.primary\" , \"path\" : \"/path/to/image/file.png\" }, { \"key\" : \"mutationBurden.legend_snv.primary\" , \"path\" : \"/path/to/other/image/file.png\" }, { \"key\" : \"mutationBurden.density_snv.primary\" , \"path\" : \"/path/to/other-other/image/file.png\" } ] } Note that the above only loaded images for the SNVs but similar images would be expected for SVs and indels.","title":"Comparators and Roles"},{"location":"ipr/optional_analyses/burden/#images","text":"A number of images can optionally be included and will be displayed in the mutation burden section of the report. These are summary images which represent the count of a variant type in the current report relative to the counts of samples in the reference distribution (based on the comparators listed above). These images are generated by the user prior to creating the report. full pattern: mutationBurden\\.(barplot|density|legend)_(sv|snv|indel)\\.(primary|secondary|tertiary|quaternary)","title":"Images"},{"location":"ipr/optional_analyses/burden/#snvs","text":"key: mutationBurden\\.density_snv\\.(primary|secondary|tertiary|quaternary) key: mutationBurden\\.barplot_snv\\.(primary|secondary|tertiary|quaternary) key: mutationBurden\\.density_indel\\.(primary|secondary|tertiary|quaternary)","title":"SNVs"},{"location":"ipr/optional_analyses/burden/#indels","text":"key: mutationBurden\\.barplot_indel\\.(primary|secondary|tertiary|quaternary)","title":"Indels"},{"location":"ipr/optional_analyses/burden/#structural-variants","text":"key: mutationBurden\\.density_sv\\.(primary|secondary|tertiary|quaternary)","title":"Structural Variants"},{"location":"ipr/optional_analyses/burden/#sv-specific-comparator-overloading","text":"There are special overload comparators for stuctural variants since they often have a different comparator data set from the SNV and Indels. Specifying an SV specific comparator will overload the more general comparator for the SV types mutation burden SV (primary) mutation burden SV (secondary) mutation burden SV (tertiary) mutation burden SV (quaternary) This means that when the report client lists the comparator that corresponds to the images and data it will use the SV-specific value where it exists instead of the more general comparator name.","title":"SV-specific Comparator Overloading"},{"location":"ipr/optional_analyses/circos_plots/","text":"Circos Plots \u00b6 There are a number of fields for including circos plots in the report. Circos plots are a useful way to look at an overview of variants for a particular sample. Info These will be passed to the report upload function via the images section of the JSON input Copy Number Circos Plot \u00b6 key: cnvLoh.circos This plot will be included in the copy variants section of the report Structural Variant Circos Plots \u00b6 keys: circosSv.genome , circosSv.transcriptome These plots will be included in the structural variants section of the report Microbial Integration Circos Plots \u00b6 keys: microbial.circos.genome , microbial.circos.transcriptome This plot has its own section, along with the microbial integration fields. It is generally used to describe viral genome integration such as HPV16.","title":"Circos Plots"},{"location":"ipr/optional_analyses/circos_plots/#circos-plots","text":"There are a number of fields for including circos plots in the report. Circos plots are a useful way to look at an overview of variants for a particular sample. Info These will be passed to the report upload function via the images section of the JSON input","title":"Circos Plots"},{"location":"ipr/optional_analyses/circos_plots/#copy-number-circos-plot","text":"key: cnvLoh.circos This plot will be included in the copy variants section of the report","title":"Copy Number Circos Plot"},{"location":"ipr/optional_analyses/circos_plots/#structural-variant-circos-plots","text":"keys: circosSv.genome , circosSv.transcriptome These plots will be included in the structural variants section of the report","title":"Structural Variant Circos Plots"},{"location":"ipr/optional_analyses/circos_plots/#microbial-integration-circos-plots","text":"keys: microbial.circos.genome , microbial.circos.transcriptome This plot has its own section, along with the microbial integration fields. It is generally used to describe viral genome integration such as HPV16.","title":"Microbial Integration Circos Plots"},{"location":"ipr/optional_analyses/comparators/","text":"Comparators \u00b6 This is used to provide details on how outlier evaluations were performed by listing the cohorts that were used in the comparisons { \"comparators\" : [ { \"analysisRole\" : \"mutation burden (primary)\" , \"name\" : \"average\" }, { \"analysisRole\" : \"expression (disease QC)\" , \"name\" : \"qc_tcga_comp_TARGET_RHD_percentile_median_(6)\" , \"size\" : 6 }, { \"analysisRole\" : \"expression (primary site)\" , \"name\" : \"average\" , \"size\" : 1024 } ], } Field Type Example Description analysisRole (required) string key indicating which analysis this comparator was used for name (required) string \"TCGA BRCA\" comparator name size number the number of samples included in the cohort/reference distribution The field analysisRole can have the following values, each can only be used once per report cibersort (primary) cibersort (secondary) mixcr (primary) mixcr (secondary) HRD (primary) HRD (secondary) expression (disease) expression (disease QC) expression (primary site) expression (primary site QC) expression (biopsy site) expression (biopsy site QC) mutation burden (primary) mutation burden (secondary) mutation burden (tertiary) mutation burden (quaternary) mutation burden SV (primary) mutation burden SV (secondary) mutation burden SV (tertiary) mutation burden SV (quaternary) protein expression (primary) protein expression (secondary)","title":"Comparators"},{"location":"ipr/optional_analyses/comparators/#comparators","text":"This is used to provide details on how outlier evaluations were performed by listing the cohorts that were used in the comparisons { \"comparators\" : [ { \"analysisRole\" : \"mutation burden (primary)\" , \"name\" : \"average\" }, { \"analysisRole\" : \"expression (disease QC)\" , \"name\" : \"qc_tcga_comp_TARGET_RHD_percentile_median_(6)\" , \"size\" : 6 }, { \"analysisRole\" : \"expression (primary site)\" , \"name\" : \"average\" , \"size\" : 1024 } ], } Field Type Example Description analysisRole (required) string key indicating which analysis this comparator was used for name (required) string \"TCGA BRCA\" comparator name size number the number of samples included in the cohort/reference distribution The field analysisRole can have the following values, each can only be used once per report cibersort (primary) cibersort (secondary) mixcr (primary) mixcr (secondary) HRD (primary) HRD (secondary) expression (disease) expression (disease QC) expression (primary site) expression (primary site QC) expression (biopsy site) expression (biopsy site QC) mutation burden (primary) mutation burden (secondary) mutation burden (tertiary) mutation burden (quaternary) mutation burden SV (primary) mutation burden SV (secondary) mutation burden SV (tertiary) mutation burden SV (quaternary) protein expression (primary) protein expression (secondary)","title":"Comparators"},{"location":"ipr/optional_analyses/expression_correlation/","text":"Expression Correlation \u00b6 Comparator-Based Plot \u00b6 keys: expression.chart , expression.legend Info These will be passed to the report upload function via the images section of the JSON input This plot represents the pairwise correlation of the RNA expression of the current sample against samples from a variety of reference distributions. Often this is used as a sanity check of the diagnosis. It is expected that the sample should correlate most highly with other samples within the disease distribution that is most closely related to the diagnosis. It is also expected that samples with a lower tumour content/purity may show correlation with their biopsy site. An example of how this type of plot is created can be found in the scripting examples here . Subtyping Plots \u00b6 These plots are similar to the main comparator based plots but are generally smaller and include only a set of subtypes of a specific cancer type (ex. BRCA). key: subtypePlot\\.\\S+ Pairwise RNA Expression Correlation \u00b6 Provide a list of the most similar other samples with respect to the RNA expression profile. { \"pairwiseExpressionCorrelation\" : [ { \"patientId\" : \"UPLOADPAT02\" , \"library\" : \"LIB0002\" , \"correlation\" : 0.99 , \"tumourType\" : \"pancreatic cancer\" , \"tissueType\" : \"liver\" , \"tumourContent\" : 15 } ] } All values expect the correlation are attributes of the sample being compared to and not the sample the report is being generated for Field Type Example Description correlation number 0.99 The RNA correlation between this sample and the report sample library string \"LIB002\" The library name of this sample patientId string \"UPLOADPAT02\" The patient ID of this sample tissueType string \"liver\" tumourContent number 15 the tumour content or purity of this sample tumourType string \"pancreatic cancer\" the diagnosis of this sample","title":"Expression Correlation"},{"location":"ipr/optional_analyses/expression_correlation/#expression-correlation","text":"","title":"Expression Correlation"},{"location":"ipr/optional_analyses/expression_correlation/#comparator-based-plot","text":"keys: expression.chart , expression.legend Info These will be passed to the report upload function via the images section of the JSON input This plot represents the pairwise correlation of the RNA expression of the current sample against samples from a variety of reference distributions. Often this is used as a sanity check of the diagnosis. It is expected that the sample should correlate most highly with other samples within the disease distribution that is most closely related to the diagnosis. It is also expected that samples with a lower tumour content/purity may show correlation with their biopsy site. An example of how this type of plot is created can be found in the scripting examples here .","title":"Comparator-Based Plot"},{"location":"ipr/optional_analyses/expression_correlation/#subtyping-plots","text":"These plots are similar to the main comparator based plots but are generally smaller and include only a set of subtypes of a specific cancer type (ex. BRCA). key: subtypePlot\\.\\S+","title":"Subtyping Plots"},{"location":"ipr/optional_analyses/expression_correlation/#pairwise-rna-expression-correlation","text":"Provide a list of the most similar other samples with respect to the RNA expression profile. { \"pairwiseExpressionCorrelation\" : [ { \"patientId\" : \"UPLOADPAT02\" , \"library\" : \"LIB0002\" , \"correlation\" : 0.99 , \"tumourType\" : \"pancreatic cancer\" , \"tissueType\" : \"liver\" , \"tumourContent\" : 15 } ] } All values expect the correlation are attributes of the sample being compared to and not the sample the report is being generated for Field Type Example Description correlation number 0.99 The RNA correlation between this sample and the report sample library string \"LIB002\" The library name of this sample patientId string \"UPLOADPAT02\" The patient ID of this sample tissueType string \"liver\" tumourContent number 15 the tumour content or purity of this sample tumourType string \"pancreatic cancer\" the diagnosis of this sample","title":"Pairwise RNA Expression Correlation"},{"location":"ipr/optional_analyses/images/","text":"Images \u00b6 There are a number of images that can be uploaded to the report. Images require a path to the image and the key for the image. The image key is used to tell IPR how to place the image in the report. The following are examples with their expected format and image key. { \"images\" : [ { \"key\" : \"string\" , \"path\" : \"/path/to/image/file\" , \"title\" : \"\" , \"caption\" : \"\" } ] }","title":"Images"},{"location":"ipr/optional_analyses/images/#images","text":"There are a number of images that can be uploaded to the report. Images require a path to the image and the key for the image. The image key is used to tell IPR how to place the image in the report. The following are examples with their expected format and image key. { \"images\" : [ { \"key\" : \"string\" , \"path\" : \"/path/to/image/file\" , \"title\" : \"\" , \"caption\" : \"\" } ] }","title":"Images"},{"location":"ipr/optional_analyses/immune/","text":"Immune Profiling \u00b6 OptiType (HLA Types) \u00b6 OptiType publication { \"hlaTypes\" : [ { \"pathology\" : \"normal\" , \"protocol\" : \"DNA\" , \"a1\" : \"A*02:03\" , \"a2\" : \"A*11:01\" , \"b1\" : \"B*40:01\" , \"b2\" : \"B*38:02\" , \"c1\" : \"C*07:02\" , \"c2\" : \"C*07:02\" } ] } Field Type Example Description a1 string \"A*02:03\" a2 string \"A*11:01\" b1 string \"B*40:01\" b2 string \"B*38:02\" c1 string \"C*07:02\" c2 string \"C*07:02\" pathology string \"normal\" the disease state of this sample protocol string \"DNA\" the sequencing protocol used for ths sample Cibersort (Immune Cell Types) \u00b6 Cibersort publication { \"immuneCellTypes\" : { \"cellType\" : \"combined T cell\" , \"kbCategory\" : \"moderate\" , \"score\" : 76 , \"percentile\" : 50 } } Field Type Example Description cellType (required) string \"combined T cell\" kbCategory string \"moderate\" percentile number 50 score number 76 Example cell type values are B cells naive B cells memory Plasma cells T cells CD8 T cells CD4 naive T cells CD4 memory resting T cells CD4 memory activated T cells follicular helper T cells regulatory (Tregs) T cells gamma delta NK cells resting NK cells activated Monocytes Macrophages M0 Macrophages M1 Macrophages M2 Dendritic cells resting Dendritic cells activated Mast cells resting Mast cells activated Eosinophils Neutrophils T.cell.inflitration Cibersort Images \u00b6 Info These will be passed to the report upload function via the images section of the JSON input key: cibersort.cd8_positive_t-cell_scatter key: cibersort.combined_t-cell_scatter MiXCR \u00b6 Info These will be passed to the report upload function via the images section of the JSON input MiXCR Publication key: mixcr.circos_trb_vj_gene_usage key: mixcr.dominance_vs_alpha_beta_t-cells_scatter","title":"Immune Profiling"},{"location":"ipr/optional_analyses/immune/#immune-profiling","text":"","title":"Immune Profiling"},{"location":"ipr/optional_analyses/immune/#optitype-hla-types","text":"OptiType publication { \"hlaTypes\" : [ { \"pathology\" : \"normal\" , \"protocol\" : \"DNA\" , \"a1\" : \"A*02:03\" , \"a2\" : \"A*11:01\" , \"b1\" : \"B*40:01\" , \"b2\" : \"B*38:02\" , \"c1\" : \"C*07:02\" , \"c2\" : \"C*07:02\" } ] } Field Type Example Description a1 string \"A*02:03\" a2 string \"A*11:01\" b1 string \"B*40:01\" b2 string \"B*38:02\" c1 string \"C*07:02\" c2 string \"C*07:02\" pathology string \"normal\" the disease state of this sample protocol string \"DNA\" the sequencing protocol used for ths sample","title":"OptiType (HLA Types)"},{"location":"ipr/optional_analyses/immune/#cibersort-immune-cell-types","text":"Cibersort publication { \"immuneCellTypes\" : { \"cellType\" : \"combined T cell\" , \"kbCategory\" : \"moderate\" , \"score\" : 76 , \"percentile\" : 50 } } Field Type Example Description cellType (required) string \"combined T cell\" kbCategory string \"moderate\" percentile number 50 score number 76 Example cell type values are B cells naive B cells memory Plasma cells T cells CD8 T cells CD4 naive T cells CD4 memory resting T cells CD4 memory activated T cells follicular helper T cells regulatory (Tregs) T cells gamma delta NK cells resting NK cells activated Monocytes Macrophages M0 Macrophages M1 Macrophages M2 Dendritic cells resting Dendritic cells activated Mast cells resting Mast cells activated Eosinophils Neutrophils T.cell.inflitration","title":"Cibersort (Immune Cell Types)"},{"location":"ipr/optional_analyses/immune/#cibersort-images","text":"Info These will be passed to the report upload function via the images section of the JSON input key: cibersort.cd8_positive_t-cell_scatter key: cibersort.combined_t-cell_scatter","title":"Cibersort Images"},{"location":"ipr/optional_analyses/immune/#mixcr","text":"Info These will be passed to the report upload function via the images section of the JSON input MiXCR Publication key: mixcr.circos_trb_vj_gene_usage key: mixcr.dominance_vs_alpha_beta_t-cells_scatter","title":"MiXCR"},{"location":"ipr/optional_analyses/metadata/","text":"Patient Metadata \u00b6 { \"patientInformation\" : { \"age\" : \"\" , \"biopsySite\" : \"Description of biopsy site\" , \"caseType\" : \"Adult\" , \"constitutionalProtocol\" : \"WGS\" , \"constitutionalSample\" : \"Blood-Peripheral\" , \"diagnosis\" : \"patient disease diagnosis\" , \"gender\" : \"Male\" , \"physician\" : \"Dr. Who\" , \"tumourProtocol\" : \"WGS/RNA-Seq\" , \"tumourSample\" : \"Metastatic\" } } The patient information fields are listed in detail below Field Type Example Description age string biopsySite string description of the biopsy site location caseType string \"Adult\" constitutionalProtocol string \"WGS\" constitutionalSample string \"Blood-Peripheral\" diagnosis string The patient disease diagnosis gender string \"Male\" physician string \"Dr. Who\" the treating (or enrolling) physician for the current patient tumourProtocol string \"WGS/RNA-seq\" tumourSample string \"Metastatic\"","title":"Patient Metadata"},{"location":"ipr/optional_analyses/metadata/#patient-metadata","text":"{ \"patientInformation\" : { \"age\" : \"\" , \"biopsySite\" : \"Description of biopsy site\" , \"caseType\" : \"Adult\" , \"constitutionalProtocol\" : \"WGS\" , \"constitutionalSample\" : \"Blood-Peripheral\" , \"diagnosis\" : \"patient disease diagnosis\" , \"gender\" : \"Male\" , \"physician\" : \"Dr. Who\" , \"tumourProtocol\" : \"WGS/RNA-Seq\" , \"tumourSample\" : \"Metastatic\" } } The patient information fields are listed in detail below Field Type Example Description age string biopsySite string description of the biopsy site location caseType string \"Adult\" constitutionalProtocol string \"WGS\" constitutionalSample string \"Blood-Peripheral\" diagnosis string The patient disease diagnosis gender string \"Male\" physician string \"Dr. Who\" the treating (or enrolling) physician for the current patient tumourProtocol string \"WGS/RNA-seq\" tumourSample string \"Metastatic\"","title":"Patient Metadata"},{"location":"ipr/optional_analyses/signature/","text":"Mutation Signatures \u00b6 These are the scores of individual mutation signatures . These can include cosmic and/or custom signatures. The nnls field is the non-negative least squares contribution of the given signature { \"mutationSignature\" : [ { \"signature\" : \"SBS1\" , \"nnls\" : 0.344 , \"associations\" : \"Tobacco chewing\" , \"features\" : \"D,T\" , \"numCancerTypes\" : 1 , \"cancerTypes\" : \"stomach cancer\" , \"selected\" : false , \"kbCategory\" : \"strong signature\" } ] } Field Type Example Description signature (required) string \"SBS1\" name of the signature associations string \"Tobacco chewing\" known behaviours, processes, or phenotypes that are associated with the current signature cancerTypes string \"stomach cancer\" features string \"D,T\" kbCategory string \"strong signature\" The kb category will be used to create a categorical verion of the signature variant which can be matched and annotated against GraphKB nnls number 0.344 non-negative lease squares numCancerTypes integer 1 selected boolean false Flag used to determine if this signature should be highlight on the main summary page of the report The selected field indicates if this signature should be shown on the front page of the report or not. This field can be toggled via the client interface following upload. Images \u00b6 Info These will be passed to the report upload function via the images section of the JSON input key: mutSignature.barplot.sbs key: mutSignature.barplot.dbs key: mutSignature.barplot.indels","title":"Mutation Signatures"},{"location":"ipr/optional_analyses/signature/#mutation-signatures","text":"These are the scores of individual mutation signatures . These can include cosmic and/or custom signatures. The nnls field is the non-negative least squares contribution of the given signature { \"mutationSignature\" : [ { \"signature\" : \"SBS1\" , \"nnls\" : 0.344 , \"associations\" : \"Tobacco chewing\" , \"features\" : \"D,T\" , \"numCancerTypes\" : 1 , \"cancerTypes\" : \"stomach cancer\" , \"selected\" : false , \"kbCategory\" : \"strong signature\" } ] } Field Type Example Description signature (required) string \"SBS1\" name of the signature associations string \"Tobacco chewing\" known behaviours, processes, or phenotypes that are associated with the current signature cancerTypes string \"stomach cancer\" features string \"D,T\" kbCategory string \"strong signature\" The kb category will be used to create a categorical verion of the signature variant which can be matched and annotated against GraphKB nnls number 0.344 non-negative lease squares numCancerTypes integer 1 selected boolean false Flag used to determine if this signature should be highlight on the main summary page of the report The selected field indicates if this signature should be shown on the front page of the report or not. This field can be toggled via the client interface following upload.","title":"Mutation Signatures"},{"location":"ipr/optional_analyses/signature/#images","text":"Info These will be passed to the report upload function via the images section of the JSON input key: mutSignature.barplot.sbs key: mutSignature.barplot.dbs key: mutSignature.barplot.indels","title":"Images"},{"location":"ipr/scripting/RNA_Expression_Metrics/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Calculating Expression Outliers Against a Reference Data Set \u00b6 Download the Data \u00b6 First we need to download the data set we will use. We are going to use the TCGA data here since it is publically available and well known ( UCSC Xena TCGA PANCAN ). We will download the TPM matrix as well as the corresponding metadata file ! wget https : // toil - xena - hub . s3 . us - east - 1. amazonaws . com / download / tcga_RSEM_gene_tpm . gz ! wget https : // tcga - pancan - atlas - hub . s3 . us - east - 1. amazonaws . com / download / Survival_SupplementalTable_S1_20171025_xena_sp --2021-06-09 19:24:14-- https://toil-xena-hub.s3.us-east-1.amazonaws.com/download/tcga_RSEM_gene_tpm.gz Resolving toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)... 52.216.80.45 Connecting to toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)|52.216.80.45|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 740772247 (706M) [binary/octet-stream] Saving to: \u2018tcga_RSEM_gene_tpm.gz.1\u2019 tcga_RSEM_gene_tpm. 100%[===================>] 706.46M 25.4MB/s in 24s 2021-06-09 19:24:38 (30.0 MB/s) - \u2018tcga_RSEM_gene_tpm.gz.1\u2019 saved [740772247/740772247] --2021-06-09 19:24:38-- https://tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com/download/Survival_SupplementalTable_S1_20171025_xena_sp Resolving tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)... 52.217.93.16 Connecting to tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)|52.217.93.16|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2419504 (2.3M) [binary/octet-stream] Saving to: \u2018Survival_SupplementalTable_S1_20171025_xena_sp.1\u2019 Survival_Supplement 100%[===================>] 2.31M 7.80MB/s in 0.3s 2021-06-09 19:24:38 (7.80 MB/s) - \u2018Survival_SupplementalTable_S1_20171025_xena_sp.1\u2019 saved [2419504/2419504] The matrix we have downloaded is very large as it contains many different disease cohorts. For the purposes of this tutorial we want a smaller data set so we are going to choose the smallest TCGA cohort, CHOL. To do this we need to use the metadata file to subset the main matrix file Install Dependencies \u00b6 For the following tutorial we are going to use some common data processing and visualization libraries in python: seaborn and pandas. We need to install them before we proceed ! pip install pandas seaborn Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5) Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1) Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5) Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9) Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1) Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2) Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1) Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0) Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7) Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0) Create the Disease Matrix Subset \u00b6 First read the metadata file import json import seaborn as sns import pandas as pd from matplotlib import pyplot as plt import numpy as np sns . set_style ( 'whitegrid' ) meta_df = pd . read_csv ( 'Survival_SupplementalTable_S1_20171025_xena_sp' , sep = ' \\t ' ) meta_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample _PATIENT cancer type abbreviation age_at_initial_pathologic_diagnosis gender race ajcc_pathologic_tumor_stage clinical_stage histological_type histological_grade initial_pathologic_dx_year menopause_status birth_days_to vital_status tumor_status last_contact_days_to death_days_to cause_of_death new_tumor_event_type new_tumor_event_site new_tumor_event_site_other new_tumor_event_dx_days_to treatment_outcome_first_course margin_status residual_tumor OS OS.time DSS DSS.time DFI DFI.time PFI PFI.time Redaction 0 TCGA-OR-A5J1-01 TCGA-OR-A5J1 ACC 58.0 MALE WHITE Stage II NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -21496.0 Dead WITH TUMOR NaN 1355.0 NaN Distant Metastasis Peritoneal Surfaces NaN 754.0 Complete Remission/Response NaN NaN 1.0 1355.0 1.0 1355.0 1.0 754.0 1.0 754.0 NaN 1 TCGA-OR-A5J2-01 TCGA-OR-A5J2 ACC 44.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2004.0 NaN -16090.0 Dead WITH TUMOR NaN 1677.0 NaN Distant Metastasis Soft Tissue NaN 289.0 Progressive Disease NaN NaN 1.0 1677.0 1.0 1677.0 NaN NaN 1.0 289.0 NaN 2 TCGA-OR-A5J3-01 TCGA-OR-A5J3 ACC 23.0 FEMALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2008.0 NaN -8624.0 Alive WITH TUMOR 2091.0 NaN NaN Distant Metastasis Lung NaN 53.0 Complete Remission/Response NaN NaN 0.0 2091.0 0.0 2091.0 1.0 53.0 1.0 53.0 NaN 3 TCGA-OR-A5J4-01 TCGA-OR-A5J4 ACC 23.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -8451.0 Dead WITH TUMOR NaN 423.0 NaN Locoregional Recurrence Peritoneal Surfaces NaN 126.0 Progressive Disease NaN NaN 1.0 423.0 1.0 423.0 NaN NaN 1.0 126.0 NaN 4 TCGA-OR-A5J5-01 TCGA-OR-A5J5 ACC 30.0 MALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -11171.0 Dead WITH TUMOR NaN 365.0 NaN Locoregional Recurrence Other, specify vena cava thrombus 50.0 Progressive Disease NaN NaN 1.0 365.0 1.0 365.0 NaN NaN 1.0 50.0 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 12586 TCGA-YZ-A980-01 TCGA-YZ-A980 UVM 75.0 MALE WHITE Stage IIIA Stage IIIA Spindle Cell|Epithelioid Cell NaN 2010.0 NaN -27716.0 Alive TUMOR FREE 1862.0 NaN NaN New Primary Tumor Other, specify Scalp 1556.0 NaN NaN NaN 0.0 1862.0 0.0 1862.0 NaN NaN 1.0 1556.0 NaN 12587 TCGA-YZ-A982-01 TCGA-YZ-A982 UVM 79.0 FEMALE WHITE Stage IIIB Stage IIIB Spindle Cell NaN 2013.0 NaN -28938.0 Alive TUMOR FREE 495.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 495.0 0.0 495.0 NaN NaN 0.0 495.0 NaN 12588 TCGA-YZ-A983-01 TCGA-YZ-A983 UVM 51.0 FEMALE WHITE Stage IIB Stage IIB Epithelioid Cell NaN 2013.0 NaN -18769.0 Alive TUMOR FREE 798.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 798.0 0.0 798.0 NaN NaN 0.0 798.0 NaN 12589 TCGA-YZ-A984-01 TCGA-YZ-A984 UVM 50.0 FEMALE WHITE Stage IIB Stage IIIA Spindle Cell|Epithelioid Cell NaN 2011.0 NaN -18342.0 Dead WITH TUMOR NaN 1396.0 Metastatic Uveal Melanoma New Primary Tumor Other, specify Thyroid 154.0 NaN NaN NaN 1.0 1396.0 1.0 1396.0 NaN NaN 1.0 154.0 NaN 12590 TCGA-YZ-A985-01 TCGA-YZ-A985 UVM 41.0 FEMALE WHITE Stage IIIA Stage IIIA Spindle Cell NaN 2012.0 NaN -15164.0 Alive TUMOR FREE 1184.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 1184.0 0.0 1184.0 NaN NaN 0.0 1184.0 NaN 12591 rows \u00d7 34 columns Now select the rows which match the disease we are intereseted in, CHOL. Print out the number of rows after the selecton. There should be 45 chol_meta_df = meta_df [ meta_df [ 'cancer type abbreviation' ] == 'CHOL' ] chol_meta_df . shape [ 0 ] 45 Next we are going to read in the data matrix. We will use the metadata we just collected to only load the columns for the cohort of interest. This will save memory and speed up the process. This will still probably take a few seconds. columns_to_keep = [ 'sample' ] + chol_meta_df [ 'sample' ] . tolist () chol_matrix = pd . read_csv ( 'tcga_RSEM_gene_tpm.gz' , compression = 'gzip' , sep = ' \\t ' , usecols = columns_to_keep ) To make things less confusing we will rename the \"sample\" column as \"gene\" since that is what is actually in that column chol_matrix = chol_matrix . rename ( columns = { 'sample' : 'gene' }) chol_matrix = chol_matrix . set_index ( 'gene' ) chol_matrix .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-ZH-A8Y5-01 TCGA-4G-AAZT-01 TCGA-W5-AA2R-11 TCGA-W5-AA2I-01 TCGA-W5-AA34-01 TCGA-W5-AA2X-01 TCGA-W5-AA2H-01 TCGA-3X-AAVB-01 TCGA-3X-AAVA-01 TCGA-ZH-A8Y4-01 TCGA-W5-AA31-11 TCGA-W5-AA2U-01 TCGA-W5-AA2Q-01 TCGA-ZH-A8Y2-01 TCGA-W5-AA30-01 TCGA-WD-A7RX-01 TCGA-ZU-A8S4-11 TCGA-W5-AA2U-11 TCGA-3X-AAVE-01 TCGA-W5-AA2G-01 TCGA-W5-AA39-01 TCGA-4G-AAZO-01 TCGA-W5-AA2R-01 TCGA-W5-AA34-11 TCGA-W5-AA2I-11 TCGA-W6-AA0S-01 TCGA-W5-AA2W-01 TCGA-YR-A95A-01 TCGA-W5-AA33-01 TCGA-ZD-A8I3-01 TCGA-W5-AA2O-01 TCGA-W5-AA31-01 TCGA-W5-AA2Q-11 TCGA-W5-AA36-01 TCGA-W5-AA38-01 TCGA-ZU-A8S4-01 TCGA-W5-AA2Z-01 TCGA-3X-AAVC-01 TCGA-W5-AA30-11 TCGA-ZH-A8Y1-01 TCGA-3X-AAV9-01 TCGA-W5-AA2T-01 TCGA-ZH-A8Y6-01 TCGA-ZH-A8Y8-01 TCGA-W5-AA2X-11 gene ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.2934 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.0350 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.0350 -9.9658 -3.8160 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -6.5064 -6.5064 -9.9658 -9.9658 -1.9942 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.1714 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -6.5064 -9.9658 ENSG00000167578.16 4.0575 5.2430 3.1179 4.3716 4.6282 4.7203 6.7259 5.4233 4.4243 4.8105 3.2841 3.9892 3.8778 5.6244 4.7345 4.9175 3.3647 3.4277 4.8405 4.0046 5.7520 4.6955 5.0104 3.1393 3.2282 4.9855 5.9074 4.2958 4.6106 4.8510 4.5940 5.3035 3.8993 4.6525 5.6795 5.4216 4.2297 4.6101 3.7846 4.8802 4.8905 4.2025 5.7632 5.1611 3.8808 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ENSG00000273233.1 -9.9658 -1.9942 -9.9658 -1.5951 -3.3076 -9.9658 -3.4580 -3.0469 -3.1714 -0.6873 -9.9658 -2.2447 -3.1714 -9.9658 -0.1504 -3.4580 -9.9658 -9.9658 -9.9658 -3.0469 -2.2447 -9.9658 -9.9658 -9.9658 -3.6259 -3.4580 -2.7274 -9.9658 -3.0469 -1.9379 -9.9658 -9.9658 -9.9658 -1.2828 -9.9658 -1.9942 -3.1714 -9.9658 -3.3076 -9.9658 -9.9658 -0.9132 -3.1714 -3.4580 -9.9658 ENSG00000105063.18 5.1157 4.9901 3.5187 5.1277 4.6713 4.9322 6.0830 5.5604 5.1056 4.8445 3.2374 4.9275 4.7049 5.2327 4.9589 4.6910 2.9224 2.8462 5.4266 5.3005 4.3876 5.4654 5.0246 3.3842 2.8096 4.0207 5.8985 4.6944 5.4199 4.9741 5.1027 5.8483 3.5742 5.1211 5.4019 5.2114 4.7939 5.8783 2.9839 5.0747 5.0352 5.2250 5.6744 4.9978 3.4778 ENSG00000231119.2 -4.2934 -5.5735 -3.8160 -9.9658 -6.5064 -2.6349 -5.5735 -3.3076 -9.9658 -4.0350 -3.1714 -4.2934 -5.5735 -9.9658 -4.0350 -2.8262 -3.4580 -5.0116 -4.6082 -3.6259 -5.0116 -4.2934 -3.8160 -3.0469 -4.0350 -4.2934 -2.2447 -3.6259 -3.8160 -5.5735 -4.6082 -2.1140 -3.0469 -9.9658 -3.6259 -1.8314 -3.8160 -4.6082 -3.3076 -3.1714 -2.4659 -4.0350 -2.4659 -2.7274 -2.9324 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 60498 rows \u00d7 45 columns Now that we have our matrix we are ready to start calculating metrics Calculating Metrics \u00b6 The input for an analysis where a patient sample is being compared to the TCGA cohort of interest would typically be an expression matrix using the same normalization method as the comparator cohort. Note : Differences in library preparation, sequencing and bioinformatics pipelines can lead to variation in expression quantification. It is important to understand the impact these differences have on expression quantification before comparing expression values that are produced using different pipelines. For the purposes of this tutorial we are going to choose one of the CHOL samples from our expression matrix to use as our input. We arbitrarily chose the first sample. test_sample_id = chol_meta_df [ 'sample' ] . tolist ()[ 0 ] Percentile \u00b6 We will start by calculating the percentile rank percentiles = chol_matrix . copy () percentiles = percentiles . rank ( 1 , pct = True , numeric_only = True ) . apply ( lambda x : round ( x * 100 )) percentiles .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-ZH-A8Y5-01 TCGA-4G-AAZT-01 TCGA-W5-AA2R-11 TCGA-W5-AA2I-01 TCGA-W5-AA34-01 TCGA-W5-AA2X-01 TCGA-W5-AA2H-01 TCGA-3X-AAVB-01 TCGA-3X-AAVA-01 TCGA-ZH-A8Y4-01 TCGA-W5-AA31-11 TCGA-W5-AA2U-01 TCGA-W5-AA2Q-01 TCGA-ZH-A8Y2-01 TCGA-W5-AA30-01 TCGA-WD-A7RX-01 TCGA-ZU-A8S4-11 TCGA-W5-AA2U-11 TCGA-3X-AAVE-01 TCGA-W5-AA2G-01 TCGA-W5-AA39-01 TCGA-4G-AAZO-01 TCGA-W5-AA2R-01 TCGA-W5-AA34-11 TCGA-W5-AA2I-11 TCGA-W6-AA0S-01 TCGA-W5-AA2W-01 TCGA-YR-A95A-01 TCGA-W5-AA33-01 TCGA-ZD-A8I3-01 TCGA-W5-AA2O-01 TCGA-W5-AA31-01 TCGA-W5-AA2Q-11 TCGA-W5-AA36-01 TCGA-W5-AA38-01 TCGA-ZU-A8S4-01 TCGA-W5-AA2Z-01 TCGA-3X-AAVC-01 TCGA-W5-AA30-11 TCGA-ZH-A8Y1-01 TCGA-3X-AAV9-01 TCGA-W5-AA2T-01 TCGA-ZH-A8Y6-01 TCGA-ZH-A8Y8-01 TCGA-W5-AA2X-11 gene ENSG00000242268.2 46.0 46.0 46.0 46.0 46.0 46.0 46.0 92.0 46.0 92.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 97.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 97.0 46.0 100.0 46.0 46.0 46.0 46.0 46.0 ENSG00000259041.1 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 ENSG00000270112.3 44.0 44.0 44.0 92.0 92.0 44.0 44.0 100.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 98.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 92.0 92.0 44.0 ENSG00000167578.16 29.0 80.0 2.0 38.0 49.0 56.0 100.0 87.0 40.0 60.0 9.0 24.0 18.0 89.0 58.0 71.0 11.0 13.0 62.0 27.0 93.0 53.0 76.0 4.0 7.0 73.0 98.0 36.0 47.0 64.0 42.0 82.0 22.0 51.0 91.0 84.0 33.0 44.0 16.0 67.0 69.0 31.0 96.0 78.0 20.0 ENSG00000278814.1 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ENSG00000273233.1 23.0 86.0 23.0 91.0 59.0 23.0 52.0 73.0 66.0 98.0 23.0 81.0 66.0 23.0 100.0 52.0 23.0 23.0 23.0 73.0 81.0 23.0 23.0 23.0 47.0 52.0 78.0 23.0 73.0 89.0 23.0 23.0 23.0 93.0 23.0 86.0 66.0 23.0 59.0 23.0 23.0 96.0 66.0 52.0 23.0 ENSG00000105063.18 64.0 49.0 18.0 69.0 27.0 42.0 100.0 89.0 62.0 38.0 11.0 40.0 33.0 76.0 44.0 29.0 7.0 4.0 84.0 78.0 24.0 87.0 53.0 13.0 2.0 22.0 98.0 31.0 82.0 47.0 60.0 93.0 20.0 67.0 80.0 71.0 36.0 96.0 9.0 58.0 56.0 73.0 91.0 51.0 16.0 ENSG00000231119.2 37.0 17.0 54.0 6.0 11.0 89.0 17.0 70.0 6.0 46.0 74.0 37.0 17.0 6.0 46.0 84.0 67.0 23.0 29.0 62.0 23.0 37.0 54.0 79.0 46.0 37.0 96.0 62.0 54.0 17.0 29.0 98.0 79.0 6.0 62.0 100.0 54.0 29.0 70.0 74.0 92.0 46.0 92.0 87.0 82.0 ENSG00000280861.1 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 ENSG00000181518.3 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 60498 rows \u00d7 45 columns We can plot a couple of these as a sanity check. The line plots should never go up and then down again gene = 'ENSG00000105063.18' fig = sns . relplot ( kind = 'line' , x = chol_matrix . loc [ gene ], y = percentiles . loc [ gene ]) fig . set ( xlabel = 'TPM' , ylabel = 'Percentile Rank' ) <seaborn.axisgrid.FacetGrid at 0x7f6b96ba7f50> Now let's look at the percentiles for our test sample percentiles [[ test_sample_id ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-3X-AAV9-01 gene ENSG00000242268.2 46.0 ENSG00000259041.1 51.0 ENSG00000270112.3 44.0 ENSG00000167578.16 69.0 ENSG00000278814.1 51.0 ... ... ENSG00000273233.1 23.0 ENSG00000105063.18 56.0 ENSG00000231119.2 92.0 ENSG00000280861.1 51.0 ENSG00000181518.3 51.0 60498 rows \u00d7 1 columns We can select the highest and lowest percentiles as a way to look for possible outliers (arbitrarily selecting 95 and 5 as thresholds). percentiles [[ test_sample_id ]][( percentiles [ test_sample_id ] >= 95 ) | ( percentiles [ test_sample_id ] <= 5 )] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-3X-AAV9-01 gene ENSG00000280143.1 98.0 ENSG00000232001.1 98.0 ENSG00000206072.12 100.0 ENSG00000254102.1 100.0 ENSG00000165312.6 100.0 ... ... ENSG00000103241.6 100.0 ENSG00000237803.5 100.0 ENSG00000270987.1 98.0 ENSG00000186115.12 4.0 ENSG00000123685.8 96.0 3530 rows \u00d7 1 columns Calculating kIQR \u00b6 The next metric we are going to look at is the kIQR. This metric is different from percentile in that it takes into account the spread or variance of the distribution. To be able to calculate this we first need to calculate some parameters for each gene quantiles = pd . concat ([ chol_matrix [ test_sample_id ], chol_matrix . quantile ( 0.25 , 1 ), chol_matrix . quantile ( 0.5 , 1 ), chol_matrix . quantile ( 0.75 , 1 ), ], axis = 1 ) . rename ( columns = { 0.25 : 'q1' , 0.5 : 'q2' , 0.75 : 'q3' , test_sample_id : 'tpm' } ) . reset_index () quantiles [ 'iqr' ] = quantiles . q3 - quantiles . q1 quantiles .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene tpm q1 q2 q3 iqr 0 ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 1 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 2 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 3 ENSG00000167578.16 4.8905 4.0046 4.6525 5.0104 1.0058 4 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 ... ... ... ... ... ... ... 60493 ENSG00000273233.1 -9.9658 -9.9658 -3.4580 -3.0469 6.9189 60494 ENSG00000105063.18 5.0352 4.6713 4.9978 5.2327 0.5614 60495 ENSG00000231119.2 -2.4659 -4.6082 -3.8160 -3.1714 1.4368 60496 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 60497 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 60498 rows \u00d7 6 columns Now we are ready to calculate the kIQR for our sample quantiles [ 'kiqr' ] = quantiles [ quantiles . iqr > 0 ] . apply ( lambda row : ( row . tpm - row . q2 ) / row . iqr , axis = 1 ) Based on the newly calcuated kIQR we pick thresholds to select outliers. We can do these alone or with the percentile filters. We have arbitrarily chosen 3 for the purposes of this tutorial quantile_outliers = quantiles [( quantiles . kiqr >= 3 ) | ( quantiles . kiqr <= - 3 )] . reset_index () quantile_outliers .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } index gene tpm q1 q2 q3 iqr kiqr 0 245 ENSG00000259677.1 -9.9658 -4.6082 -3.6259 -2.8262 1.7820 -3.557744 1 481 ENSG00000223922.1 -9.9658 -4.2934 -3.4580 -2.3147 1.9787 -3.288927 2 598 ENSG00000255236.2 -9.9658 -3.3076 -2.1140 -1.3921 1.9155 -4.099086 3 652 ENSG00000057149.14 4.7464 -9.9658 -9.9658 -5.5735 4.3923 3.349544 4 1159 ENSG00000271916.1 -9.9658 -2.2447 -0.4719 0.4125 2.6572 -3.572896 ... ... ... ... ... ... ... ... ... 121 58758 ENSG00000253492.1 -9.9658 -0.5756 1.7702 2.6161 3.1917 -3.677037 122 58852 ENSG00000169562.9 4.1612 6.8178 7.3061 7.6176 0.7998 -3.932108 123 59675 ENSG00000270617.1 -9.9658 -2.9324 -2.4659 -0.7834 2.1490 -3.489949 124 59884 ENSG00000235298.1 -9.9658 -1.0862 -0.3201 0.6239 1.7101 -5.640430 125 59912 ENSG00000070526.14 4.1252 -2.7274 -1.8314 -1.0262 1.7012 3.501411 126 rows \u00d7 8 columns Now we pick some of these genes to plot outlier_gene = quantile_outliers . iloc [ 0 ] . gene outlier_gene 'ENSG00000259677.1' And create a histogram which highlights where the current sample lands relative to the other samples ax = sns . histplot ( chol_matrix . T [ outlier_gene ], kde = True ) ax . set_title ( outlier_gene ) ax . set_xlabel ( 'TPM' ) # add a marker over the bin the sample lands in current = quantile_outliers [ quantile_outliers . gene == outlier_gene ] . iloc [ 0 ] . tpm for p in ax . patches : if current >= p . get_x () and current <= p . get_x () + p . get_width (): p . set_color ( 'black' ) plt . text ( p . get_x () + ( p . get_width () / 2 ), p . get_height (), '*' , horizontalalignment = 'center' , verticalalignment = 'bottom' , ) Creating the Report Input \u00b6 Since the required input to the IPR python adapter is JSON we will format the output from this analysis to match that specification. Note this will only contain the expression relevant portions. We will start by combining the percentile, tpm, and kiqr into a single matrix metrics_df = pd . concat ([ quantiles . set_index ( 'gene' ), percentiles [[ test_sample_id ]] . rename ( columns = { test_sample_id : 'percentile' }) ], axis = 1 ) metrics_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tpm q1 q2 q3 iqr kiqr percentile gene ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 46.0 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 44.0 ENSG00000167578.16 4.8905 4.0046 4.6525 5.0104 1.0058 0.236628 69.0 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 ... ... ... ... ... ... ... ... ENSG00000273233.1 -9.9658 -9.9658 -3.4580 -3.0469 6.9189 -0.940583 23.0 ENSG00000105063.18 5.0352 4.6713 4.9978 5.2327 0.5614 0.066619 56.0 ENSG00000231119.2 -2.4659 -4.6082 -3.8160 -3.1714 1.4368 0.939658 92.0 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 60498 rows \u00d7 7 columns Next we are going to use our thresholds to assign labels percentile_threshold = 97.5 kiqr_threshold = 2.5 metrics_df . loc [( metrics_df . percentile >= percentile_threshold ) & ( metrics_df . kiqr >= kiqr_threshold ), 'kbCategory' ] = 'increased expression' metrics_df . loc [( metrics_df . percentile <= 100 - percentile_threshold ) & ( metrics_df . kiqr <= - 1 * kiqr_threshold ), 'kbCategory' ] = 'reduced expression' metrics_df [ ~ metrics_df . kbCategory . isnull ()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tpm q1 q2 q3 iqr kiqr percentile kbCategory gene ENSG00000057149.14 4.7464 -9.9658 -9.9658 -5.5735 4.3923 3.349544 100.0 increased expression ENSG00000140522.11 0.0580 -9.9658 -9.9658 -6.5064 3.4594 2.897554 100.0 increased expression ENSG00000089116.3 -0.0277 -9.9658 -9.9658 -6.5064 3.4594 2.872781 100.0 increased expression ENSG00000087495.16 4.8095 -3.0469 -2.0529 -0.4325 2.6144 2.624847 98.0 increased expression ENSG00000272702.1 -6.5064 -2.5479 -1.5951 -1.1488 1.3991 -3.510328 2.0 reduced expression ENSG00000254231.1 -2.2447 0.5955 1.2756 1.9527 1.3572 -2.593796 2.0 reduced expression ENSG00000073282.12 1.4652 -4.2934 -3.6259 -2.3884 1.9050 2.672493 100.0 increased expression ENSG00000142700.11 0.3796 -9.9658 -9.9658 -6.5064 3.4594 2.990519 100.0 increased expression ENSG00000077616.10 1.1641 -2.6349 -2.1779 -1.4699 1.1650 2.868670 100.0 increased expression ENSG00000227392.1 -9.9658 -1.3183 -0.2159 0.5568 1.8751 -5.199669 2.0 reduced expression ENSG00000147689.16 5.2694 -6.5064 -5.5735 -3.1714 3.3350 3.251244 100.0 increased expression ENSG00000174332.5 1.3846 -5.0116 -4.2934 -3.3076 1.7040 3.332160 100.0 increased expression ENSG00000163207.6 2.4008 -9.9658 -9.9658 -6.5064 3.4594 3.574782 100.0 increased expression ENSG00000158786.4 -0.6643 -9.9658 -9.9658 -6.5064 3.4594 2.688761 100.0 increased expression ENSG00000261857.6 7.6963 -2.7274 -1.2481 -0.2845 2.4429 3.661386 100.0 increased expression ENSG00000265179.6 -0.4325 -9.9658 -9.9658 -6.5064 3.4594 2.755767 98.0 increased expression ENSG00000198910.12 5.3948 -3.4580 -1.8836 -0.9406 2.5174 2.891237 100.0 increased expression ENSG00000196154.11 11.1159 5.3827 6.2565 7.3173 1.9346 2.511837 100.0 increased expression ENSG00000148704.12 -0.1828 -9.9658 -9.9658 -6.5064 3.4594 2.827947 100.0 increased expression ENSG00000171956.6 -0.2159 -9.9658 -9.9658 -6.5064 3.4594 2.818379 98.0 increased expression ENSG00000228630.5 0.9568 -9.9658 -9.9658 -6.5064 3.4594 3.157368 98.0 increased expression ENSG00000132361.16 3.7825 5.2987 5.4922 5.7616 0.4629 -3.693454 2.0 reduced expression ENSG00000113430.9 -0.1993 -9.9658 -9.9658 -6.5064 3.4594 2.823177 100.0 increased expression ENSG00000166869.2 -0.1504 -9.9658 -9.9658 -6.5064 3.4594 2.837313 98.0 increased expression ENSG00000198488.10 0.4967 -9.9658 -9.9658 -6.5064 3.4594 3.024368 98.0 increased expression ENSG00000101470.9 2.6510 -2.5479 -1.8836 -1.3183 1.2296 3.687866 100.0 increased expression ENSG00000099958.14 7.1647 1.5563 2.5238 3.2002 1.6439 2.823104 100.0 increased expression ENSG00000125820.5 2.4805 -9.9658 -9.9658 -6.5064 3.4594 3.597820 100.0 increased expression ENSG00000215115.6 0.7664 -9.9658 -9.9658 -6.5064 3.4594 3.102330 100.0 increased expression ENSG00000130035.6 1.9931 -4.0350 -3.4580 -2.3884 1.6466 3.310519 100.0 increased expression ENSG00000101160.13 8.6516 7.4139 7.6005 7.8323 0.4184 2.512189 98.0 increased expression ENSG00000204930.9 -3.8160 -6.5064 -6.5064 -5.5735 0.9329 2.883910 100.0 increased expression ENSG00000215113.6 0.7664 -9.9658 -9.9658 -6.5064 3.4594 3.102330 100.0 increased expression ENSG00000175928.5 3.2796 -2.8262 -1.9379 -0.7588 2.0674 2.523701 98.0 increased expression ENSG00000186081.11 6.5720 -3.6259 -2.3884 -0.1828 3.4431 2.602422 100.0 increased expression ENSG00000181690.7 0.9789 -4.0350 -3.3076 -2.6349 1.4001 3.061567 98.0 increased expression ENSG00000182103.4 -1.4305 -6.5064 -6.5064 -5.0116 1.4948 3.395705 100.0 increased expression ENSG00000271474.1 -0.9686 -4.6082 -3.8160 -3.6259 0.9823 2.898707 100.0 increased expression ENSG00000169962.4 1.3109 -2.7274 -2.1140 -1.4305 1.2969 2.640836 98.0 increased expression ENSG00000166105.15 -1.0262 -9.9658 -9.9658 -6.5064 3.4594 2.584148 100.0 increased expression ENSG00000143199.17 -6.5064 -1.6850 -0.4521 0.5763 2.2613 -2.677354 2.0 reduced expression ENSG00000180616.8 0.9191 -2.6349 -2.1140 -1.4305 1.2044 2.518349 100.0 increased expression ENSG00000230587.1 0.0990 -3.6259 -3.1714 -2.4659 1.1600 2.819310 100.0 increased expression ENSG00000256162.2 -9.9658 -1.0559 0.6880 3.1604 4.2163 -2.526813 2.0 reduced expression ENSG00000205209.7 -6.5064 -3.4580 -2.5479 -1.9942 1.4638 -2.704263 2.0 reduced expression ENSG00000204542.2 3.6382 -9.9658 -9.9658 -4.6082 5.3576 2.539197 98.0 increased expression ENSG00000166961.14 2.4359 -9.9658 -9.9658 -5.5735 4.3923 2.823509 100.0 increased expression ENSG00000102096.9 5.7455 2.5112 3.0393 3.5657 1.0545 2.566335 98.0 increased expression ENSG00000124191.17 5.1023 0.2522 0.9568 1.4911 1.2389 3.346113 98.0 increased expression ENSG00000107485.15 3.9175 -1.9379 -1.3921 0.0014 1.9393 2.737895 100.0 increased expression ENSG00000065618.16 5.4741 -4.6082 -2.9324 -1.4699 3.1383 2.678680 98.0 increased expression ENSG00000158816.15 -0.1828 -9.9658 -9.9658 -6.5064 3.4594 2.827947 100.0 increased expression ENSG00000135374.9 3.6077 -9.9658 -9.9658 -5.5735 4.3923 3.090294 100.0 increased expression ENSG00000145113.21 5.3618 -2.5479 -1.9942 -1.0262 1.5217 4.834067 100.0 increased expression ENSG00000162367.11 2.7847 -1.5522 -1.0559 -0.2328 1.3194 2.910869 100.0 increased expression ENSG00000105371.8 1.3735 -3.8160 -3.0469 -2.0529 1.7631 2.507175 98.0 increased expression ENSG00000070526.14 4.1252 -2.7274 -1.8314 -1.0262 1.7012 3.501411 98.0 increased expression Finally we can use this to create our output. The percentiles and kIQR values we have calculated above were for our disease comparator but a similar process would be used for normal and biopsy comparators metrics_df = metrics_df . rename ( columns = { 'kiqr' : 'diseasekIQR' , 'percentile' : 'diseasePercentile' }) . reset_index () We often leave non-variant expression records in to supplement the copy variant and structural variant information. For these records the kbCategory field is a null value since they are not an expression outlier expression_variants = metrics_df [[ 'tpm' , 'diseasekIQR' , 'diseasePercentile' , 'gene' , 'kbCategory' ]] . replace ({ np . nan : None }) . to_dict ( 'records' ) expression_variants [ 0 ] {'diseasePercentile': 46.0, 'diseasekIQR': None, 'gene': 'ENSG00000242268.2', 'kbCategory': None, 'tpm': -9.9658} We will also add the disease comparator information to the JSON output_json = { 'comparators' : [ { 'analysisRole' : 'expression (disease)' , 'name' : 'TCGA CHOL' , 'size' : chol_matrix . shape [ 0 ]} ], 'expressionVariants' : expression_variants } with open ( 'result.json' , 'w' ) as fh : json . dump ( output_json , fh )","title":"RNA Expression Metrics"},{"location":"ipr/scripting/RNA_Expression_Metrics/#calculating-expression-outliers-against-a-reference-data-set","text":"","title":"Calculating Expression Outliers Against a Reference Data Set"},{"location":"ipr/scripting/RNA_Expression_Metrics/#download-the-data","text":"First we need to download the data set we will use. We are going to use the TCGA data here since it is publically available and well known ( UCSC Xena TCGA PANCAN ). We will download the TPM matrix as well as the corresponding metadata file ! wget https : // toil - xena - hub . s3 . us - east - 1. amazonaws . com / download / tcga_RSEM_gene_tpm . gz ! wget https : // tcga - pancan - atlas - hub . s3 . us - east - 1. amazonaws . com / download / Survival_SupplementalTable_S1_20171025_xena_sp --2021-06-09 19:24:14-- https://toil-xena-hub.s3.us-east-1.amazonaws.com/download/tcga_RSEM_gene_tpm.gz Resolving toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)... 52.216.80.45 Connecting to toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)|52.216.80.45|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 740772247 (706M) [binary/octet-stream] Saving to: \u2018tcga_RSEM_gene_tpm.gz.1\u2019 tcga_RSEM_gene_tpm. 100%[===================>] 706.46M 25.4MB/s in 24s 2021-06-09 19:24:38 (30.0 MB/s) - \u2018tcga_RSEM_gene_tpm.gz.1\u2019 saved [740772247/740772247] --2021-06-09 19:24:38-- https://tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com/download/Survival_SupplementalTable_S1_20171025_xena_sp Resolving tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)... 52.217.93.16 Connecting to tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)|52.217.93.16|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2419504 (2.3M) [binary/octet-stream] Saving to: \u2018Survival_SupplementalTable_S1_20171025_xena_sp.1\u2019 Survival_Supplement 100%[===================>] 2.31M 7.80MB/s in 0.3s 2021-06-09 19:24:38 (7.80 MB/s) - \u2018Survival_SupplementalTable_S1_20171025_xena_sp.1\u2019 saved [2419504/2419504] The matrix we have downloaded is very large as it contains many different disease cohorts. For the purposes of this tutorial we want a smaller data set so we are going to choose the smallest TCGA cohort, CHOL. To do this we need to use the metadata file to subset the main matrix file","title":"Download the Data"},{"location":"ipr/scripting/RNA_Expression_Metrics/#install-dependencies","text":"For the following tutorial we are going to use some common data processing and visualization libraries in python: seaborn and pandas. We need to install them before we proceed ! pip install pandas seaborn Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5) Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1) Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5) Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9) Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1) Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2) Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1) Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0) Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7) Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)","title":"Install Dependencies"},{"location":"ipr/scripting/RNA_Expression_Metrics/#create-the-disease-matrix-subset","text":"First read the metadata file import json import seaborn as sns import pandas as pd from matplotlib import pyplot as plt import numpy as np sns . set_style ( 'whitegrid' ) meta_df = pd . read_csv ( 'Survival_SupplementalTable_S1_20171025_xena_sp' , sep = ' \\t ' ) meta_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample _PATIENT cancer type abbreviation age_at_initial_pathologic_diagnosis gender race ajcc_pathologic_tumor_stage clinical_stage histological_type histological_grade initial_pathologic_dx_year menopause_status birth_days_to vital_status tumor_status last_contact_days_to death_days_to cause_of_death new_tumor_event_type new_tumor_event_site new_tumor_event_site_other new_tumor_event_dx_days_to treatment_outcome_first_course margin_status residual_tumor OS OS.time DSS DSS.time DFI DFI.time PFI PFI.time Redaction 0 TCGA-OR-A5J1-01 TCGA-OR-A5J1 ACC 58.0 MALE WHITE Stage II NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -21496.0 Dead WITH TUMOR NaN 1355.0 NaN Distant Metastasis Peritoneal Surfaces NaN 754.0 Complete Remission/Response NaN NaN 1.0 1355.0 1.0 1355.0 1.0 754.0 1.0 754.0 NaN 1 TCGA-OR-A5J2-01 TCGA-OR-A5J2 ACC 44.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2004.0 NaN -16090.0 Dead WITH TUMOR NaN 1677.0 NaN Distant Metastasis Soft Tissue NaN 289.0 Progressive Disease NaN NaN 1.0 1677.0 1.0 1677.0 NaN NaN 1.0 289.0 NaN 2 TCGA-OR-A5J3-01 TCGA-OR-A5J3 ACC 23.0 FEMALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2008.0 NaN -8624.0 Alive WITH TUMOR 2091.0 NaN NaN Distant Metastasis Lung NaN 53.0 Complete Remission/Response NaN NaN 0.0 2091.0 0.0 2091.0 1.0 53.0 1.0 53.0 NaN 3 TCGA-OR-A5J4-01 TCGA-OR-A5J4 ACC 23.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -8451.0 Dead WITH TUMOR NaN 423.0 NaN Locoregional Recurrence Peritoneal Surfaces NaN 126.0 Progressive Disease NaN NaN 1.0 423.0 1.0 423.0 NaN NaN 1.0 126.0 NaN 4 TCGA-OR-A5J5-01 TCGA-OR-A5J5 ACC 30.0 MALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -11171.0 Dead WITH TUMOR NaN 365.0 NaN Locoregional Recurrence Other, specify vena cava thrombus 50.0 Progressive Disease NaN NaN 1.0 365.0 1.0 365.0 NaN NaN 1.0 50.0 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 12586 TCGA-YZ-A980-01 TCGA-YZ-A980 UVM 75.0 MALE WHITE Stage IIIA Stage IIIA Spindle Cell|Epithelioid Cell NaN 2010.0 NaN -27716.0 Alive TUMOR FREE 1862.0 NaN NaN New Primary Tumor Other, specify Scalp 1556.0 NaN NaN NaN 0.0 1862.0 0.0 1862.0 NaN NaN 1.0 1556.0 NaN 12587 TCGA-YZ-A982-01 TCGA-YZ-A982 UVM 79.0 FEMALE WHITE Stage IIIB Stage IIIB Spindle Cell NaN 2013.0 NaN -28938.0 Alive TUMOR FREE 495.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 495.0 0.0 495.0 NaN NaN 0.0 495.0 NaN 12588 TCGA-YZ-A983-01 TCGA-YZ-A983 UVM 51.0 FEMALE WHITE Stage IIB Stage IIB Epithelioid Cell NaN 2013.0 NaN -18769.0 Alive TUMOR FREE 798.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 798.0 0.0 798.0 NaN NaN 0.0 798.0 NaN 12589 TCGA-YZ-A984-01 TCGA-YZ-A984 UVM 50.0 FEMALE WHITE Stage IIB Stage IIIA Spindle Cell|Epithelioid Cell NaN 2011.0 NaN -18342.0 Dead WITH TUMOR NaN 1396.0 Metastatic Uveal Melanoma New Primary Tumor Other, specify Thyroid 154.0 NaN NaN NaN 1.0 1396.0 1.0 1396.0 NaN NaN 1.0 154.0 NaN 12590 TCGA-YZ-A985-01 TCGA-YZ-A985 UVM 41.0 FEMALE WHITE Stage IIIA Stage IIIA Spindle Cell NaN 2012.0 NaN -15164.0 Alive TUMOR FREE 1184.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 1184.0 0.0 1184.0 NaN NaN 0.0 1184.0 NaN 12591 rows \u00d7 34 columns Now select the rows which match the disease we are intereseted in, CHOL. Print out the number of rows after the selecton. There should be 45 chol_meta_df = meta_df [ meta_df [ 'cancer type abbreviation' ] == 'CHOL' ] chol_meta_df . shape [ 0 ] 45 Next we are going to read in the data matrix. We will use the metadata we just collected to only load the columns for the cohort of interest. This will save memory and speed up the process. This will still probably take a few seconds. columns_to_keep = [ 'sample' ] + chol_meta_df [ 'sample' ] . tolist () chol_matrix = pd . read_csv ( 'tcga_RSEM_gene_tpm.gz' , compression = 'gzip' , sep = ' \\t ' , usecols = columns_to_keep ) To make things less confusing we will rename the \"sample\" column as \"gene\" since that is what is actually in that column chol_matrix = chol_matrix . rename ( columns = { 'sample' : 'gene' }) chol_matrix = chol_matrix . set_index ( 'gene' ) chol_matrix .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-ZH-A8Y5-01 TCGA-4G-AAZT-01 TCGA-W5-AA2R-11 TCGA-W5-AA2I-01 TCGA-W5-AA34-01 TCGA-W5-AA2X-01 TCGA-W5-AA2H-01 TCGA-3X-AAVB-01 TCGA-3X-AAVA-01 TCGA-ZH-A8Y4-01 TCGA-W5-AA31-11 TCGA-W5-AA2U-01 TCGA-W5-AA2Q-01 TCGA-ZH-A8Y2-01 TCGA-W5-AA30-01 TCGA-WD-A7RX-01 TCGA-ZU-A8S4-11 TCGA-W5-AA2U-11 TCGA-3X-AAVE-01 TCGA-W5-AA2G-01 TCGA-W5-AA39-01 TCGA-4G-AAZO-01 TCGA-W5-AA2R-01 TCGA-W5-AA34-11 TCGA-W5-AA2I-11 TCGA-W6-AA0S-01 TCGA-W5-AA2W-01 TCGA-YR-A95A-01 TCGA-W5-AA33-01 TCGA-ZD-A8I3-01 TCGA-W5-AA2O-01 TCGA-W5-AA31-01 TCGA-W5-AA2Q-11 TCGA-W5-AA36-01 TCGA-W5-AA38-01 TCGA-ZU-A8S4-01 TCGA-W5-AA2Z-01 TCGA-3X-AAVC-01 TCGA-W5-AA30-11 TCGA-ZH-A8Y1-01 TCGA-3X-AAV9-01 TCGA-W5-AA2T-01 TCGA-ZH-A8Y6-01 TCGA-ZH-A8Y8-01 TCGA-W5-AA2X-11 gene ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.2934 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.0350 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.0350 -9.9658 -3.8160 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -6.5064 -6.5064 -9.9658 -9.9658 -1.9942 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.1714 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -6.5064 -9.9658 ENSG00000167578.16 4.0575 5.2430 3.1179 4.3716 4.6282 4.7203 6.7259 5.4233 4.4243 4.8105 3.2841 3.9892 3.8778 5.6244 4.7345 4.9175 3.3647 3.4277 4.8405 4.0046 5.7520 4.6955 5.0104 3.1393 3.2282 4.9855 5.9074 4.2958 4.6106 4.8510 4.5940 5.3035 3.8993 4.6525 5.6795 5.4216 4.2297 4.6101 3.7846 4.8802 4.8905 4.2025 5.7632 5.1611 3.8808 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ENSG00000273233.1 -9.9658 -1.9942 -9.9658 -1.5951 -3.3076 -9.9658 -3.4580 -3.0469 -3.1714 -0.6873 -9.9658 -2.2447 -3.1714 -9.9658 -0.1504 -3.4580 -9.9658 -9.9658 -9.9658 -3.0469 -2.2447 -9.9658 -9.9658 -9.9658 -3.6259 -3.4580 -2.7274 -9.9658 -3.0469 -1.9379 -9.9658 -9.9658 -9.9658 -1.2828 -9.9658 -1.9942 -3.1714 -9.9658 -3.3076 -9.9658 -9.9658 -0.9132 -3.1714 -3.4580 -9.9658 ENSG00000105063.18 5.1157 4.9901 3.5187 5.1277 4.6713 4.9322 6.0830 5.5604 5.1056 4.8445 3.2374 4.9275 4.7049 5.2327 4.9589 4.6910 2.9224 2.8462 5.4266 5.3005 4.3876 5.4654 5.0246 3.3842 2.8096 4.0207 5.8985 4.6944 5.4199 4.9741 5.1027 5.8483 3.5742 5.1211 5.4019 5.2114 4.7939 5.8783 2.9839 5.0747 5.0352 5.2250 5.6744 4.9978 3.4778 ENSG00000231119.2 -4.2934 -5.5735 -3.8160 -9.9658 -6.5064 -2.6349 -5.5735 -3.3076 -9.9658 -4.0350 -3.1714 -4.2934 -5.5735 -9.9658 -4.0350 -2.8262 -3.4580 -5.0116 -4.6082 -3.6259 -5.0116 -4.2934 -3.8160 -3.0469 -4.0350 -4.2934 -2.2447 -3.6259 -3.8160 -5.5735 -4.6082 -2.1140 -3.0469 -9.9658 -3.6259 -1.8314 -3.8160 -4.6082 -3.3076 -3.1714 -2.4659 -4.0350 -2.4659 -2.7274 -2.9324 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 60498 rows \u00d7 45 columns Now that we have our matrix we are ready to start calculating metrics","title":"Create the Disease Matrix Subset"},{"location":"ipr/scripting/RNA_Expression_Metrics/#calculating-metrics","text":"The input for an analysis where a patient sample is being compared to the TCGA cohort of interest would typically be an expression matrix using the same normalization method as the comparator cohort. Note : Differences in library preparation, sequencing and bioinformatics pipelines can lead to variation in expression quantification. It is important to understand the impact these differences have on expression quantification before comparing expression values that are produced using different pipelines. For the purposes of this tutorial we are going to choose one of the CHOL samples from our expression matrix to use as our input. We arbitrarily chose the first sample. test_sample_id = chol_meta_df [ 'sample' ] . tolist ()[ 0 ]","title":"Calculating Metrics"},{"location":"ipr/scripting/RNA_Expression_Metrics/#percentile","text":"We will start by calculating the percentile rank percentiles = chol_matrix . copy () percentiles = percentiles . rank ( 1 , pct = True , numeric_only = True ) . apply ( lambda x : round ( x * 100 )) percentiles .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-ZH-A8Y5-01 TCGA-4G-AAZT-01 TCGA-W5-AA2R-11 TCGA-W5-AA2I-01 TCGA-W5-AA34-01 TCGA-W5-AA2X-01 TCGA-W5-AA2H-01 TCGA-3X-AAVB-01 TCGA-3X-AAVA-01 TCGA-ZH-A8Y4-01 TCGA-W5-AA31-11 TCGA-W5-AA2U-01 TCGA-W5-AA2Q-01 TCGA-ZH-A8Y2-01 TCGA-W5-AA30-01 TCGA-WD-A7RX-01 TCGA-ZU-A8S4-11 TCGA-W5-AA2U-11 TCGA-3X-AAVE-01 TCGA-W5-AA2G-01 TCGA-W5-AA39-01 TCGA-4G-AAZO-01 TCGA-W5-AA2R-01 TCGA-W5-AA34-11 TCGA-W5-AA2I-11 TCGA-W6-AA0S-01 TCGA-W5-AA2W-01 TCGA-YR-A95A-01 TCGA-W5-AA33-01 TCGA-ZD-A8I3-01 TCGA-W5-AA2O-01 TCGA-W5-AA31-01 TCGA-W5-AA2Q-11 TCGA-W5-AA36-01 TCGA-W5-AA38-01 TCGA-ZU-A8S4-01 TCGA-W5-AA2Z-01 TCGA-3X-AAVC-01 TCGA-W5-AA30-11 TCGA-ZH-A8Y1-01 TCGA-3X-AAV9-01 TCGA-W5-AA2T-01 TCGA-ZH-A8Y6-01 TCGA-ZH-A8Y8-01 TCGA-W5-AA2X-11 gene ENSG00000242268.2 46.0 46.0 46.0 46.0 46.0 46.0 46.0 92.0 46.0 92.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 97.0 46.0 46.0 46.0 46.0 46.0 46.0 46.0 97.0 46.0 100.0 46.0 46.0 46.0 46.0 46.0 ENSG00000259041.1 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 ENSG00000270112.3 44.0 44.0 44.0 92.0 92.0 44.0 44.0 100.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 98.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 44.0 92.0 92.0 44.0 ENSG00000167578.16 29.0 80.0 2.0 38.0 49.0 56.0 100.0 87.0 40.0 60.0 9.0 24.0 18.0 89.0 58.0 71.0 11.0 13.0 62.0 27.0 93.0 53.0 76.0 4.0 7.0 73.0 98.0 36.0 47.0 64.0 42.0 82.0 22.0 51.0 91.0 84.0 33.0 44.0 16.0 67.0 69.0 31.0 96.0 78.0 20.0 ENSG00000278814.1 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ENSG00000273233.1 23.0 86.0 23.0 91.0 59.0 23.0 52.0 73.0 66.0 98.0 23.0 81.0 66.0 23.0 100.0 52.0 23.0 23.0 23.0 73.0 81.0 23.0 23.0 23.0 47.0 52.0 78.0 23.0 73.0 89.0 23.0 23.0 23.0 93.0 23.0 86.0 66.0 23.0 59.0 23.0 23.0 96.0 66.0 52.0 23.0 ENSG00000105063.18 64.0 49.0 18.0 69.0 27.0 42.0 100.0 89.0 62.0 38.0 11.0 40.0 33.0 76.0 44.0 29.0 7.0 4.0 84.0 78.0 24.0 87.0 53.0 13.0 2.0 22.0 98.0 31.0 82.0 47.0 60.0 93.0 20.0 67.0 80.0 71.0 36.0 96.0 9.0 58.0 56.0 73.0 91.0 51.0 16.0 ENSG00000231119.2 37.0 17.0 54.0 6.0 11.0 89.0 17.0 70.0 6.0 46.0 74.0 37.0 17.0 6.0 46.0 84.0 67.0 23.0 29.0 62.0 23.0 37.0 54.0 79.0 46.0 37.0 96.0 62.0 54.0 17.0 29.0 98.0 79.0 6.0 62.0 100.0 54.0 29.0 70.0 74.0 92.0 46.0 92.0 87.0 82.0 ENSG00000280861.1 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 ENSG00000181518.3 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 51.0 60498 rows \u00d7 45 columns We can plot a couple of these as a sanity check. The line plots should never go up and then down again gene = 'ENSG00000105063.18' fig = sns . relplot ( kind = 'line' , x = chol_matrix . loc [ gene ], y = percentiles . loc [ gene ]) fig . set ( xlabel = 'TPM' , ylabel = 'Percentile Rank' ) <seaborn.axisgrid.FacetGrid at 0x7f6b96ba7f50> Now let's look at the percentiles for our test sample percentiles [[ test_sample_id ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-3X-AAV9-01 gene ENSG00000242268.2 46.0 ENSG00000259041.1 51.0 ENSG00000270112.3 44.0 ENSG00000167578.16 69.0 ENSG00000278814.1 51.0 ... ... ENSG00000273233.1 23.0 ENSG00000105063.18 56.0 ENSG00000231119.2 92.0 ENSG00000280861.1 51.0 ENSG00000181518.3 51.0 60498 rows \u00d7 1 columns We can select the highest and lowest percentiles as a way to look for possible outliers (arbitrarily selecting 95 and 5 as thresholds). percentiles [[ test_sample_id ]][( percentiles [ test_sample_id ] >= 95 ) | ( percentiles [ test_sample_id ] <= 5 )] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-3X-AAV9-01 gene ENSG00000280143.1 98.0 ENSG00000232001.1 98.0 ENSG00000206072.12 100.0 ENSG00000254102.1 100.0 ENSG00000165312.6 100.0 ... ... ENSG00000103241.6 100.0 ENSG00000237803.5 100.0 ENSG00000270987.1 98.0 ENSG00000186115.12 4.0 ENSG00000123685.8 96.0 3530 rows \u00d7 1 columns","title":"Percentile"},{"location":"ipr/scripting/RNA_Expression_Metrics/#calculating-kiqr","text":"The next metric we are going to look at is the kIQR. This metric is different from percentile in that it takes into account the spread or variance of the distribution. To be able to calculate this we first need to calculate some parameters for each gene quantiles = pd . concat ([ chol_matrix [ test_sample_id ], chol_matrix . quantile ( 0.25 , 1 ), chol_matrix . quantile ( 0.5 , 1 ), chol_matrix . quantile ( 0.75 , 1 ), ], axis = 1 ) . rename ( columns = { 0.25 : 'q1' , 0.5 : 'q2' , 0.75 : 'q3' , test_sample_id : 'tpm' } ) . reset_index () quantiles [ 'iqr' ] = quantiles . q3 - quantiles . q1 quantiles .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene tpm q1 q2 q3 iqr 0 ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 1 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 2 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 3 ENSG00000167578.16 4.8905 4.0046 4.6525 5.0104 1.0058 4 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 ... ... ... ... ... ... ... 60493 ENSG00000273233.1 -9.9658 -9.9658 -3.4580 -3.0469 6.9189 60494 ENSG00000105063.18 5.0352 4.6713 4.9978 5.2327 0.5614 60495 ENSG00000231119.2 -2.4659 -4.6082 -3.8160 -3.1714 1.4368 60496 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 60497 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 60498 rows \u00d7 6 columns Now we are ready to calculate the kIQR for our sample quantiles [ 'kiqr' ] = quantiles [ quantiles . iqr > 0 ] . apply ( lambda row : ( row . tpm - row . q2 ) / row . iqr , axis = 1 ) Based on the newly calcuated kIQR we pick thresholds to select outliers. We can do these alone or with the percentile filters. We have arbitrarily chosen 3 for the purposes of this tutorial quantile_outliers = quantiles [( quantiles . kiqr >= 3 ) | ( quantiles . kiqr <= - 3 )] . reset_index () quantile_outliers .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } index gene tpm q1 q2 q3 iqr kiqr 0 245 ENSG00000259677.1 -9.9658 -4.6082 -3.6259 -2.8262 1.7820 -3.557744 1 481 ENSG00000223922.1 -9.9658 -4.2934 -3.4580 -2.3147 1.9787 -3.288927 2 598 ENSG00000255236.2 -9.9658 -3.3076 -2.1140 -1.3921 1.9155 -4.099086 3 652 ENSG00000057149.14 4.7464 -9.9658 -9.9658 -5.5735 4.3923 3.349544 4 1159 ENSG00000271916.1 -9.9658 -2.2447 -0.4719 0.4125 2.6572 -3.572896 ... ... ... ... ... ... ... ... ... 121 58758 ENSG00000253492.1 -9.9658 -0.5756 1.7702 2.6161 3.1917 -3.677037 122 58852 ENSG00000169562.9 4.1612 6.8178 7.3061 7.6176 0.7998 -3.932108 123 59675 ENSG00000270617.1 -9.9658 -2.9324 -2.4659 -0.7834 2.1490 -3.489949 124 59884 ENSG00000235298.1 -9.9658 -1.0862 -0.3201 0.6239 1.7101 -5.640430 125 59912 ENSG00000070526.14 4.1252 -2.7274 -1.8314 -1.0262 1.7012 3.501411 126 rows \u00d7 8 columns Now we pick some of these genes to plot outlier_gene = quantile_outliers . iloc [ 0 ] . gene outlier_gene 'ENSG00000259677.1' And create a histogram which highlights where the current sample lands relative to the other samples ax = sns . histplot ( chol_matrix . T [ outlier_gene ], kde = True ) ax . set_title ( outlier_gene ) ax . set_xlabel ( 'TPM' ) # add a marker over the bin the sample lands in current = quantile_outliers [ quantile_outliers . gene == outlier_gene ] . iloc [ 0 ] . tpm for p in ax . patches : if current >= p . get_x () and current <= p . get_x () + p . get_width (): p . set_color ( 'black' ) plt . text ( p . get_x () + ( p . get_width () / 2 ), p . get_height (), '*' , horizontalalignment = 'center' , verticalalignment = 'bottom' , )","title":"Calculating kIQR"},{"location":"ipr/scripting/RNA_Expression_Metrics/#creating-the-report-input","text":"Since the required input to the IPR python adapter is JSON we will format the output from this analysis to match that specification. Note this will only contain the expression relevant portions. We will start by combining the percentile, tpm, and kiqr into a single matrix metrics_df = pd . concat ([ quantiles . set_index ( 'gene' ), percentiles [[ test_sample_id ]] . rename ( columns = { test_sample_id : 'percentile' }) ], axis = 1 ) metrics_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tpm q1 q2 q3 iqr kiqr percentile gene ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 46.0 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 44.0 ENSG00000167578.16 4.8905 4.0046 4.6525 5.0104 1.0058 0.236628 69.0 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 ... ... ... ... ... ... ... ... ENSG00000273233.1 -9.9658 -9.9658 -3.4580 -3.0469 6.9189 -0.940583 23.0 ENSG00000105063.18 5.0352 4.6713 4.9978 5.2327 0.5614 0.066619 56.0 ENSG00000231119.2 -2.4659 -4.6082 -3.8160 -3.1714 1.4368 0.939658 92.0 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 0.0000 NaN 51.0 60498 rows \u00d7 7 columns Next we are going to use our thresholds to assign labels percentile_threshold = 97.5 kiqr_threshold = 2.5 metrics_df . loc [( metrics_df . percentile >= percentile_threshold ) & ( metrics_df . kiqr >= kiqr_threshold ), 'kbCategory' ] = 'increased expression' metrics_df . loc [( metrics_df . percentile <= 100 - percentile_threshold ) & ( metrics_df . kiqr <= - 1 * kiqr_threshold ), 'kbCategory' ] = 'reduced expression' metrics_df [ ~ metrics_df . kbCategory . isnull ()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tpm q1 q2 q3 iqr kiqr percentile kbCategory gene ENSG00000057149.14 4.7464 -9.9658 -9.9658 -5.5735 4.3923 3.349544 100.0 increased expression ENSG00000140522.11 0.0580 -9.9658 -9.9658 -6.5064 3.4594 2.897554 100.0 increased expression ENSG00000089116.3 -0.0277 -9.9658 -9.9658 -6.5064 3.4594 2.872781 100.0 increased expression ENSG00000087495.16 4.8095 -3.0469 -2.0529 -0.4325 2.6144 2.624847 98.0 increased expression ENSG00000272702.1 -6.5064 -2.5479 -1.5951 -1.1488 1.3991 -3.510328 2.0 reduced expression ENSG00000254231.1 -2.2447 0.5955 1.2756 1.9527 1.3572 -2.593796 2.0 reduced expression ENSG00000073282.12 1.4652 -4.2934 -3.6259 -2.3884 1.9050 2.672493 100.0 increased expression ENSG00000142700.11 0.3796 -9.9658 -9.9658 -6.5064 3.4594 2.990519 100.0 increased expression ENSG00000077616.10 1.1641 -2.6349 -2.1779 -1.4699 1.1650 2.868670 100.0 increased expression ENSG00000227392.1 -9.9658 -1.3183 -0.2159 0.5568 1.8751 -5.199669 2.0 reduced expression ENSG00000147689.16 5.2694 -6.5064 -5.5735 -3.1714 3.3350 3.251244 100.0 increased expression ENSG00000174332.5 1.3846 -5.0116 -4.2934 -3.3076 1.7040 3.332160 100.0 increased expression ENSG00000163207.6 2.4008 -9.9658 -9.9658 -6.5064 3.4594 3.574782 100.0 increased expression ENSG00000158786.4 -0.6643 -9.9658 -9.9658 -6.5064 3.4594 2.688761 100.0 increased expression ENSG00000261857.6 7.6963 -2.7274 -1.2481 -0.2845 2.4429 3.661386 100.0 increased expression ENSG00000265179.6 -0.4325 -9.9658 -9.9658 -6.5064 3.4594 2.755767 98.0 increased expression ENSG00000198910.12 5.3948 -3.4580 -1.8836 -0.9406 2.5174 2.891237 100.0 increased expression ENSG00000196154.11 11.1159 5.3827 6.2565 7.3173 1.9346 2.511837 100.0 increased expression ENSG00000148704.12 -0.1828 -9.9658 -9.9658 -6.5064 3.4594 2.827947 100.0 increased expression ENSG00000171956.6 -0.2159 -9.9658 -9.9658 -6.5064 3.4594 2.818379 98.0 increased expression ENSG00000228630.5 0.9568 -9.9658 -9.9658 -6.5064 3.4594 3.157368 98.0 increased expression ENSG00000132361.16 3.7825 5.2987 5.4922 5.7616 0.4629 -3.693454 2.0 reduced expression ENSG00000113430.9 -0.1993 -9.9658 -9.9658 -6.5064 3.4594 2.823177 100.0 increased expression ENSG00000166869.2 -0.1504 -9.9658 -9.9658 -6.5064 3.4594 2.837313 98.0 increased expression ENSG00000198488.10 0.4967 -9.9658 -9.9658 -6.5064 3.4594 3.024368 98.0 increased expression ENSG00000101470.9 2.6510 -2.5479 -1.8836 -1.3183 1.2296 3.687866 100.0 increased expression ENSG00000099958.14 7.1647 1.5563 2.5238 3.2002 1.6439 2.823104 100.0 increased expression ENSG00000125820.5 2.4805 -9.9658 -9.9658 -6.5064 3.4594 3.597820 100.0 increased expression ENSG00000215115.6 0.7664 -9.9658 -9.9658 -6.5064 3.4594 3.102330 100.0 increased expression ENSG00000130035.6 1.9931 -4.0350 -3.4580 -2.3884 1.6466 3.310519 100.0 increased expression ENSG00000101160.13 8.6516 7.4139 7.6005 7.8323 0.4184 2.512189 98.0 increased expression ENSG00000204930.9 -3.8160 -6.5064 -6.5064 -5.5735 0.9329 2.883910 100.0 increased expression ENSG00000215113.6 0.7664 -9.9658 -9.9658 -6.5064 3.4594 3.102330 100.0 increased expression ENSG00000175928.5 3.2796 -2.8262 -1.9379 -0.7588 2.0674 2.523701 98.0 increased expression ENSG00000186081.11 6.5720 -3.6259 -2.3884 -0.1828 3.4431 2.602422 100.0 increased expression ENSG00000181690.7 0.9789 -4.0350 -3.3076 -2.6349 1.4001 3.061567 98.0 increased expression ENSG00000182103.4 -1.4305 -6.5064 -6.5064 -5.0116 1.4948 3.395705 100.0 increased expression ENSG00000271474.1 -0.9686 -4.6082 -3.8160 -3.6259 0.9823 2.898707 100.0 increased expression ENSG00000169962.4 1.3109 -2.7274 -2.1140 -1.4305 1.2969 2.640836 98.0 increased expression ENSG00000166105.15 -1.0262 -9.9658 -9.9658 -6.5064 3.4594 2.584148 100.0 increased expression ENSG00000143199.17 -6.5064 -1.6850 -0.4521 0.5763 2.2613 -2.677354 2.0 reduced expression ENSG00000180616.8 0.9191 -2.6349 -2.1140 -1.4305 1.2044 2.518349 100.0 increased expression ENSG00000230587.1 0.0990 -3.6259 -3.1714 -2.4659 1.1600 2.819310 100.0 increased expression ENSG00000256162.2 -9.9658 -1.0559 0.6880 3.1604 4.2163 -2.526813 2.0 reduced expression ENSG00000205209.7 -6.5064 -3.4580 -2.5479 -1.9942 1.4638 -2.704263 2.0 reduced expression ENSG00000204542.2 3.6382 -9.9658 -9.9658 -4.6082 5.3576 2.539197 98.0 increased expression ENSG00000166961.14 2.4359 -9.9658 -9.9658 -5.5735 4.3923 2.823509 100.0 increased expression ENSG00000102096.9 5.7455 2.5112 3.0393 3.5657 1.0545 2.566335 98.0 increased expression ENSG00000124191.17 5.1023 0.2522 0.9568 1.4911 1.2389 3.346113 98.0 increased expression ENSG00000107485.15 3.9175 -1.9379 -1.3921 0.0014 1.9393 2.737895 100.0 increased expression ENSG00000065618.16 5.4741 -4.6082 -2.9324 -1.4699 3.1383 2.678680 98.0 increased expression ENSG00000158816.15 -0.1828 -9.9658 -9.9658 -6.5064 3.4594 2.827947 100.0 increased expression ENSG00000135374.9 3.6077 -9.9658 -9.9658 -5.5735 4.3923 3.090294 100.0 increased expression ENSG00000145113.21 5.3618 -2.5479 -1.9942 -1.0262 1.5217 4.834067 100.0 increased expression ENSG00000162367.11 2.7847 -1.5522 -1.0559 -0.2328 1.3194 2.910869 100.0 increased expression ENSG00000105371.8 1.3735 -3.8160 -3.0469 -2.0529 1.7631 2.507175 98.0 increased expression ENSG00000070526.14 4.1252 -2.7274 -1.8314 -1.0262 1.7012 3.501411 98.0 increased expression Finally we can use this to create our output. The percentiles and kIQR values we have calculated above were for our disease comparator but a similar process would be used for normal and biopsy comparators metrics_df = metrics_df . rename ( columns = { 'kiqr' : 'diseasekIQR' , 'percentile' : 'diseasePercentile' }) . reset_index () We often leave non-variant expression records in to supplement the copy variant and structural variant information. For these records the kbCategory field is a null value since they are not an expression outlier expression_variants = metrics_df [[ 'tpm' , 'diseasekIQR' , 'diseasePercentile' , 'gene' , 'kbCategory' ]] . replace ({ np . nan : None }) . to_dict ( 'records' ) expression_variants [ 0 ] {'diseasePercentile': 46.0, 'diseasekIQR': None, 'gene': 'ENSG00000242268.2', 'kbCategory': None, 'tpm': -9.9658} We will also add the disease comparator information to the JSON output_json = { 'comparators' : [ { 'analysisRole' : 'expression (disease)' , 'name' : 'TCGA CHOL' , 'size' : chol_matrix . shape [ 0 ]} ], 'expressionVariants' : expression_variants } with open ( 'result.json' , 'w' ) as fh : json . dump ( output_json , fh )","title":"Creating the Report Input"},{"location":"ipr/scripting/RNA_Expression_Similarity/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Computing RNA Expression Similarity \u00b6 Download the Data \u00b6 First we need to download the data set we will use. We are going to use the TCGA data here since it is publically available and well known ( UCSC Xena TCGA PANCAN ). We will download the TPM matrix as well as the corresponding metadata file ! wget https : // toil - xena - hub . s3 . us - east - 1. amazonaws . com / download / tcga_RSEM_gene_tpm . gz ! wget https : // tcga - pancan - atlas - hub . s3 . us - east - 1. amazonaws . com / download / Survival_SupplementalTable_S1_20171025_xena_sp --2021-06-10 17:34:56-- https://toil-xena-hub.s3.us-east-1.amazonaws.com/download/tcga_RSEM_gene_tpm.gz Resolving toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)... 52.216.136.30 Connecting to toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)|52.216.136.30|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 740772247 (706M) [binary/octet-stream] Saving to: \u2018tcga_RSEM_gene_tpm.gz\u2019 tcga_RSEM_gene_tpm. 100%[===================>] 706.46M 15.5MB/s in 49s 2021-06-10 17:35:46 (14.5 MB/s) - \u2018tcga_RSEM_gene_tpm.gz\u2019 saved [740772247/740772247] --2021-06-10 17:35:46-- https://tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com/download/Survival_SupplementalTable_S1_20171025_xena_sp Resolving tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)... 52.216.94.142 Connecting to tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)|52.216.94.142|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2419504 (2.3M) [binary/octet-stream] Saving to: \u2018Survival_SupplementalTable_S1_20171025_xena_sp\u2019 Survival_Supplement 100%[===================>] 2.31M 1.75MB/s in 1.3s 2021-06-10 17:35:48 (1.75 MB/s) - \u2018Survival_SupplementalTable_S1_20171025_xena_sp\u2019 saved [2419504/2419504] The matrix we have downloaded is very large as it contains many different disease cohorts. For the purposes of this tutorial we want a smaller data set so we are going to choose the smallest TCGA cohort, CHOL. To do this we need to use the metadata file to subset the main matrix file Install Dependencies \u00b6 For the following tutorial we are going to use some common data processing and visualization libraries in python: seaborn and pandas. We need to install them before we proceed ! pip install pandas seaborn Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5) Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1) Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9) Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1) Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5) Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2) Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1) Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7) Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0) Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1) Create the Disease Matrix \u00b6 First read the metadata file import json import seaborn as sns import pandas as pd from matplotlib import pyplot as plt import numpy as np sns . set_style ( 'whitegrid' ) meta_df = pd . read_csv ( 'Survival_SupplementalTable_S1_20171025_xena_sp' , sep = ' \\t ' ) meta_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample _PATIENT cancer type abbreviation age_at_initial_pathologic_diagnosis gender race ajcc_pathologic_tumor_stage clinical_stage histological_type histological_grade initial_pathologic_dx_year menopause_status birth_days_to vital_status tumor_status last_contact_days_to death_days_to cause_of_death new_tumor_event_type new_tumor_event_site new_tumor_event_site_other new_tumor_event_dx_days_to treatment_outcome_first_course margin_status residual_tumor OS OS.time DSS DSS.time DFI DFI.time PFI PFI.time Redaction 0 TCGA-OR-A5J1-01 TCGA-OR-A5J1 ACC 58.0 MALE WHITE Stage II NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -21496.0 Dead WITH TUMOR NaN 1355.0 NaN Distant Metastasis Peritoneal Surfaces NaN 754.0 Complete Remission/Response NaN NaN 1.0 1355.0 1.0 1355.0 1.0 754.0 1.0 754.0 NaN 1 TCGA-OR-A5J2-01 TCGA-OR-A5J2 ACC 44.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2004.0 NaN -16090.0 Dead WITH TUMOR NaN 1677.0 NaN Distant Metastasis Soft Tissue NaN 289.0 Progressive Disease NaN NaN 1.0 1677.0 1.0 1677.0 NaN NaN 1.0 289.0 NaN 2 TCGA-OR-A5J3-01 TCGA-OR-A5J3 ACC 23.0 FEMALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2008.0 NaN -8624.0 Alive WITH TUMOR 2091.0 NaN NaN Distant Metastasis Lung NaN 53.0 Complete Remission/Response NaN NaN 0.0 2091.0 0.0 2091.0 1.0 53.0 1.0 53.0 NaN 3 TCGA-OR-A5J4-01 TCGA-OR-A5J4 ACC 23.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -8451.0 Dead WITH TUMOR NaN 423.0 NaN Locoregional Recurrence Peritoneal Surfaces NaN 126.0 Progressive Disease NaN NaN 1.0 423.0 1.0 423.0 NaN NaN 1.0 126.0 NaN 4 TCGA-OR-A5J5-01 TCGA-OR-A5J5 ACC 30.0 MALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -11171.0 Dead WITH TUMOR NaN 365.0 NaN Locoregional Recurrence Other, specify vena cava thrombus 50.0 Progressive Disease NaN NaN 1.0 365.0 1.0 365.0 NaN NaN 1.0 50.0 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 12586 TCGA-YZ-A980-01 TCGA-YZ-A980 UVM 75.0 MALE WHITE Stage IIIA Stage IIIA Spindle Cell|Epithelioid Cell NaN 2010.0 NaN -27716.0 Alive TUMOR FREE 1862.0 NaN NaN New Primary Tumor Other, specify Scalp 1556.0 NaN NaN NaN 0.0 1862.0 0.0 1862.0 NaN NaN 1.0 1556.0 NaN 12587 TCGA-YZ-A982-01 TCGA-YZ-A982 UVM 79.0 FEMALE WHITE Stage IIIB Stage IIIB Spindle Cell NaN 2013.0 NaN -28938.0 Alive TUMOR FREE 495.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 495.0 0.0 495.0 NaN NaN 0.0 495.0 NaN 12588 TCGA-YZ-A983-01 TCGA-YZ-A983 UVM 51.0 FEMALE WHITE Stage IIB Stage IIB Epithelioid Cell NaN 2013.0 NaN -18769.0 Alive TUMOR FREE 798.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 798.0 0.0 798.0 NaN NaN 0.0 798.0 NaN 12589 TCGA-YZ-A984-01 TCGA-YZ-A984 UVM 50.0 FEMALE WHITE Stage IIB Stage IIIA Spindle Cell|Epithelioid Cell NaN 2011.0 NaN -18342.0 Dead WITH TUMOR NaN 1396.0 Metastatic Uveal Melanoma New Primary Tumor Other, specify Thyroid 154.0 NaN NaN NaN 1.0 1396.0 1.0 1396.0 NaN NaN 1.0 154.0 NaN 12590 TCGA-YZ-A985-01 TCGA-YZ-A985 UVM 41.0 FEMALE WHITE Stage IIIA Stage IIIA Spindle Cell NaN 2012.0 NaN -15164.0 Alive TUMOR FREE 1184.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 1184.0 0.0 1184.0 NaN NaN 0.0 1184.0 NaN 12591 rows \u00d7 34 columns To facilitate running this quickly and with low compute resource requirements we will use a subset of the total set of samples. In practice we would likely store this in a database to improve performance. If you would like to use the entire data set you can remove the \"usecols\" part of read_csv. Let's use the metadata file to see how many samples we have in each of the different cohorts meta_df . groupby ( 'cancer type abbreviation' ) . agg ({ 'sample' : 'nunique' }) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample cancer type abbreviation ACC 92 BLCA 436 BRCA 1236 CESC 312 CHOL 45 COAD 545 DLBC 48 ESCA 204 GBM 602 HNSC 604 KICH 91 KIRC 944 KIRP 352 LAML 200 LGG 529 LIHC 438 LUAD 641 LUSC 623 MESO 87 OV 604 PAAD 196 PCPG 187 PRAD 566 READ 183 SARC 271 SKCM 479 STAD 511 TGCT 139 THCA 580 THYM 126 UCEC 583 UCS 57 UVM 80 Now we will select a couple of cohorts - CHOL - LIHC - SKCM columns_to_keep = set ([ 'sample' ] + meta_df [ meta_df [ 'cancer type abbreviation' ] . isin ({ 'CHOL' , 'SKCM' , 'LIHC' })][ 'sample' ] . tolist ()) len ( columns_to_keep ) 963 Reading the data matrix is a lot of data and so this process is slow. This will still probably take a few minutes. In practice we likely store this in a database to improvement performance exp_matrix = pd . read_csv ( 'tcga_RSEM_gene_tpm.gz' , compression = 'gzip' , sep = ' \\t ' , usecols = lambda x : x in columns_to_keep ) To make things less confusing we will rename the \"sample\" column as \"gene\" since that is what is actually in that column exp_matrix = exp_matrix . rename ( columns = { 'sample' : 'gene' }) exp_matrix = exp_matrix . set_index ( 'gene' ) exp_matrix .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-G3-A3CH-11 TCGA-RP-A695-06 TCGA-DD-AAW0-01 TCGA-EE-A17X-06 TCGA-DD-AACA-02 TCGA-DD-AACA-01 TCGA-D3-A8GD-06 TCGA-DD-A3A6-11 TCGA-K7-AAU7-01 TCGA-FS-A1ZF-06 TCGA-EB-A41A-01 TCGA-RC-A7SH-01 TCGA-CC-A3MA-01 TCGA-DD-A3A5-11 TCGA-RC-A7SB-01 TCGA-D3-A3ML-06 TCGA-EE-A2GB-06 TCGA-DD-AAVZ-01 TCGA-DD-A116-11 TCGA-ED-A627-01 TCGA-ER-A19S-06 TCGA-EE-A3AB-06 TCGA-DD-AAVV-01 TCGA-XV-AAZW-01 TCGA-D3-A5GR-06 TCGA-BC-4073-01 TCGA-W3-AA1R-06 TCGA-QA-A7B7-01 TCGA-DA-A1IC-06 TCGA-D3-A51G-06 TCGA-BF-A5ER-01 TCGA-HP-A5N0-01 TCGA-D3-A5GU-06 TCGA-ZH-A8Y5-01 TCGA-FS-A1ZB-06 TCGA-DD-A114-11 TCGA-DD-A1EG-11 TCGA-DD-AAEI-01 TCGA-4G-AAZT-01 TCGA-DD-AACT-01 ... TCGA-BC-A112-01 TCGA-BW-A5NO-01 TCGA-FV-A3I1-11 TCGA-D3-A3MU-06 TCGA-ER-A2NB-01 TCGA-XV-A9W2-01 TCGA-UB-A7MF-01 TCGA-WX-AA44-01 TCGA-ER-A194-01 TCGA-DD-AACQ-01 TCGA-D3-A2JH-06 TCGA-EE-A2GR-06 TCGA-G3-A25U-01 TCGA-FS-A4F4-06 TCGA-DD-A1EK-01 TCGA-EB-A3XE-01 TCGA-DD-A11C-11 TCGA-BC-A10Q-11 TCGA-EE-A2GI-06 TCGA-EP-A12J-01 TCGA-W5-AA2X-11 TCGA-D9-A1JX-06 TCGA-D3-A2JL-06 TCGA-EE-A2MM-06 TCGA-DD-AAED-01 TCGA-DA-A95X-06 TCGA-DD-A1EG-01 TCGA-BC-A10R-01 TCGA-EE-A2MF-06 TCGA-G3-A3CG-01 TCGA-DD-A1ED-01 TCGA-2Y-A9H8-01 TCGA-2Y-A9GT-01 TCGA-3N-A9WD-06 TCGA-DA-A95W-06 TCGA-EE-A2GN-06 TCGA-D9-A4Z6-06 TCGA-EE-A29L-06 TCGA-DD-A115-01 TCGA-FV-A3I0-11 gene ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -3.1714 -9.9658 -9.9658 -4.6082 -9.9658 -9.9658 -9.9658 -5.0116 -3.8160 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.6082 -2.3884 -1.8314 -5.0116 -9.9658 -3.3076 -9.9658 -4.0350 -9.9658 -9.9658 -1.7322 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.8160 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.4580 -9.9658 -1.9942 -9.9658 -1.4699 -9.9658 -0.4325 -9.9658 -9.9658 -9.9658 -1.5105 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -5.0116 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -2.6349 -2.6349 -9.9658 -9.9658 -4.6082 -9.9658 -9.9658 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -1.6850 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.3076 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -0.9406 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -2.0529 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 0.9343 -9.9658 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -6.5064 -9.9658 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000167578.16 3.5572 5.2308 4.6077 5.5741 4.080749 3.2018 6.1010 3.1540 4.5098 5.6767 5.7337 5.8094 3.7367 3.4739 4.8125 3.8954 5.2972 4.1700 3.1028 4.8485 5.1223 5.2235 4.8440 6.3684 4.8299 4.3169 5.7307 4.7539 4.0636 6.1067 4.6916 3.9487 4.6854 4.0575 5.6186 4.1310 3.1129 2.9966 5.2430 4.5772 ... 4.5324 4.9294 3.2557 5.3917 5.1052 4.8033 5.5799 5.0009 5.6930 4.5367 5.5571 4.6759 3.2988 5.7052 4.3903 5.7391 3.5299 3.2174 4.8827 4.0488 3.8808 5.5568 5.8390 4.2943 4.4647 4.6764 4.4310 4.7735 5.5503 3.7475 4.2072 4.6960 4.4324 4.5311 4.3541 3.7730 5.6846 5.2817 4.0260 3.0876 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ENSG00000273233.1 -9.9658 -3.4580 -9.9658 -9.9658 -4.442233 -9.9658 -9.9658 -9.9658 -2.0529 -2.7274 -9.9658 -2.5479 -3.4580 -9.9658 -9.9658 -4.0350 -3.6259 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.6259 -3.4580 -9.9658 -3.6259 -2.8262 -9.9658 -1.9379 -9.9658 -3.3076 -3.3076 -9.9658 -2.7274 -9.9658 -9.9658 -9.9658 -1.9942 -9.9658 ... -9.9658 -9.9658 -9.9658 -2.4659 -9.9658 -2.3884 -4.0350 -2.9324 -9.9658 -9.9658 -3.4580 -9.9658 -9.9658 -3.1714 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.3076 -2.4659 -9.9658 -9.9658 -9.9658 -3.8160 -2.8262 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -2.5479 -9.9658 -2.6349 -9.9658 -9.9658 ENSG00000105063.18 3.4358 6.5907 4.6317 7.8058 5.034368 5.2365 6.0885 2.2175 4.9346 5.3906 5.1416 5.7926 4.9393 2.9356 4.5154 4.8832 7.1736 4.6247 2.8301 4.3855 5.7978 5.4300 5.2211 5.0879 5.6574 4.8435 6.5130 5.2825 5.7211 5.4050 6.0856 3.4277 5.0972 5.1157 5.9709 3.8591 2.8681 4.2366 4.9901 4.2699 ... 5.2169 3.9974 3.2677 6.4069 4.6236 4.7507 5.1930 5.1343 5.5236 4.5571 6.1048 5.5448 3.9289 5.7727 4.5820 4.9069 2.9857 2.7551 5.9905 4.6106 3.4778 5.8316 5.1575 6.0275 4.6053 5.5871 4.9141 4.6815 5.6848 4.2189 3.3549 5.0900 4.0884 4.5892 4.7735 5.7247 6.5297 6.0788 4.4647 3.2174 ENSG00000231119.2 -2.5479 -9.9658 -6.5064 -6.5064 -1.910505 -2.4659 -1.4305 -1.8836 -3.1714 -2.1779 -5.0116 -4.2934 -4.2934 -3.0469 -2.4659 -1.3548 -1.9942 -4.0350 -4.0350 -2.1779 -2.7274 -2.8262 -1.8314 -3.8160 -2.3147 -3.3076 -2.4659 -9.9658 -3.4580 -0.7108 -5.5735 -3.6259 -3.1714 -4.2934 -6.5064 -5.0116 -3.8160 -2.5479 -5.5735 -2.9324 ... -5.0116 -1.7809 -2.5479 -4.6082 -9.9658 -5.0116 -3.8160 -2.6349 -9.9658 -4.0350 -3.6259 -2.7274 -3.6259 -5.0116 -4.0350 -1.0559 -4.2934 -5.0116 -4.2934 -2.6349 -2.9324 -1.0862 -5.5735 -9.9658 -2.6349 -1.6850 -1.5522 -3.6259 -3.8160 -3.3076 -1.0262 -5.0116 -3.3076 -2.9324 -5.0116 -4.2934 -3.3076 -9.9658 -2.3884 -3.0469 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -5.5735 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 60498 rows \u00d7 936 columns Now that we have our matrix we are ready to start the correlation Spearman Correlation \u00b6 The input for an analysis where a patient sample is being compared to the TCGA cohort of interest would typically be an expression matrix using the same normalization method as the comparator cohort. Note that differences in library preparation, sequencing and bioinformatics pipelines can lead to variation in expression quantification. It is important to understand the impact these differences have on expression quantification before comparing expression values that are produced using different pipelines. For the purposes of this tutorial we are going to choose one of the CHOL samples from our expression matrix to use as our input. We arbitrarily choose the first sample. test_sample_id = str ( exp_matrix . iloc [ 0 ] . index [ 0 ]) meta_df [ meta_df [ 'sample' ] == test_sample_id ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample _PATIENT cancer type abbreviation age_at_initial_pathologic_diagnosis gender race ajcc_pathologic_tumor_stage clinical_stage histological_type histological_grade initial_pathologic_dx_year menopause_status birth_days_to vital_status tumor_status last_contact_days_to death_days_to cause_of_death new_tumor_event_type new_tumor_event_site new_tumor_event_site_other new_tumor_event_dx_days_to treatment_outcome_first_course margin_status residual_tumor OS OS.time DSS DSS.time DFI DFI.time PFI PFI.time Redaction 6583 TCGA-G3-A3CH-11 TCGA-G3-A3CH LIHC 53.0 MALE ASIAN Stage IIIA NaN Hepatocellular Carcinoma G2 2010.0 NaN -19473.0 Alive WITH TUMOR 780.0 NaN NaN Intrahepatic Recurrence Liver NaN 116.0 NaN NaN R0 0.0 780.0 0.0 780.0 1.0 116.0 1.0 116.0 NaN Now we compute the correlation of this sample with all other samples in the matrix excluding itself corr = exp_matrix [[ c for c in exp_matrix . columns . tolist () if c != test_sample_id ]] . corrwith ( exp_matrix [ test_sample_id ], method = 'spearman' ) . to_frame () corr = corr . rename ( columns = { corr . columns [ 0 ]: \"correlation\" }) . reset_index () . rename ( columns = { 'index' : 'sample' }) corr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample correlation 0 TCGA-RP-A695-06 0.840728 1 TCGA-DD-AAW0-01 0.901187 2 TCGA-EE-A17X-06 0.825520 3 TCGA-DD-AACA-02 0.871860 4 TCGA-DD-AACA-01 0.883324 ... ... ... 930 TCGA-EE-A2GN-06 0.838558 931 TCGA-D9-A4Z6-06 0.824104 932 TCGA-EE-A29L-06 0.817158 933 TCGA-DD-A115-01 0.885494 934 TCGA-FV-A3I0-11 0.908514 935 rows \u00d7 2 columns Merge that with the metadata to group the correlations into their respective cohorts for plotting corr = corr . merge ( meta_df [[ 'sample' , 'cancer type abbreviation' ]], on = [ 'sample' ], how = 'left' ) corr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample correlation cancer type abbreviation 0 TCGA-RP-A695-06 0.840728 SKCM 1 TCGA-DD-AAW0-01 0.901187 LIHC 2 TCGA-EE-A17X-06 0.825520 SKCM 3 TCGA-DD-AACA-02 0.871860 LIHC 4 TCGA-DD-AACA-01 0.883324 LIHC ... ... ... ... 930 TCGA-EE-A2GN-06 0.838558 SKCM 931 TCGA-D9-A4Z6-06 0.824104 SKCM 932 TCGA-EE-A29L-06 0.817158 SKCM 933 TCGA-DD-A115-01 0.885494 LIHC 934 TCGA-FV-A3I0-11 0.908514 LIHC 935 rows \u00d7 3 columns Now plot the correlations fig = sns . catplot ( kind = 'box' , data = corr , x = 'correlation' , y = 'cancer type abbreviation' ) title = test_sample_id + ' (' + meta_df [ meta_df [ 'sample' ] == test_sample_id ] . iloc [ 0 ][ 'cancer type abbreviation' ] + ')' fig . set ( xlabel = 'spearman correlation' , ylabel = '' , title = title ) <seaborn.axisgrid.FacetGrid at 0x7f3bc4d89350> As expected, the average pairwise correlation is highest within the same disease cohort as the sample Principle Component Analysis (PCA) \u00b6 The principal component analysis would serve a similar function to the pairwise spearman correlations plot above and could be included in place of said plot if preferred. For this we will need to install more python libraries ! pip install scikit - learn Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1) Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1) Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5) Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1) Now we are ready to set up the PCA model. from sklearn.decomposition import PCA pca = PCA () Our input to the PCA model is a matrix with each sample as a row. Since in our current matrix the genes are rows we need to transpose this X = exp_matrix . T X .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene ENSG00000242268.2 ENSG00000259041.1 ENSG00000270112.3 ENSG00000167578.16 ENSG00000278814.1 ENSG00000078237.5 ENSG00000269416.5 ENSG00000263642.1 ENSG00000146083.11 ENSG00000158486.13 ENSG00000273639.4 ENSG00000198242.13 ENSG00000231981.3 ENSG00000269475.2 ENSG00000134108.12 ENSG00000261030.1 ENSG00000172137.18 ENSG00000276644.4 ENSG00000240423.1 ENSG00000271616.1 ENSG00000234881.1 ENSG00000236040.1 ENSG00000231105.1 ENSG00000094963.13 ENSG00000182141.9 ENSG00000280143.1 ENSG00000251334.2 ENSG00000231112.1 ENSG00000258610.1 ENSG00000264981.1 ENSG00000275265.1 ENSG00000185105.4 ENSG00000233540.1 ENSG00000102174.8 ENSG00000166391.14 ENSG00000232001.1 ENSG00000270469.1 ENSG00000225275.4 ENSG00000234253.1 ENSG00000070087.13 ... ENSG00000279778.1 ENSG00000223671.2 ENSG00000263573.1 ENSG00000222213.1 ENSG00000214124.3 ENSG00000206836.1 ENSG00000233845.1 ENSG00000066044.13 ENSG00000264491.1 ENSG00000146587.17 ENSG00000278151.1 ENSG00000228658.1 ENSG00000173930.8 ENSG00000274396.1 ENSG00000107863.16 ENSG00000199892.2 ENSG00000221760.1 ENSG00000253333.1 ENSG00000213782.7 ENSG00000146707.14 ENSG00000212084.2 ENSG00000248838.2 ENSG00000255083.1 ENSG00000158417.10 ENSG00000223665.1 ENSG00000203729.8 ENSG00000238300.1 ENSG00000221756.1 ENSG00000089177.17 ENSG00000186115.12 ENSG00000009694.13 ENSG00000238244.3 ENSG00000216352.1 ENSG00000123685.8 ENSG00000267117.1 ENSG00000273233.1 ENSG00000105063.18 ENSG00000231119.2 ENSG00000280861.1 ENSG00000181518.3 TCGA-G3-A3CH-11 -9.9658 -9.9658 -9.9658 3.557200 -9.9658 0.099000 -9.965800 -9.9658 1.832300 -9.96580 -9.9658 8.372500 -9.9658 -9.9658 3.502200 -9.9658 -9.965800 -1.148800 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -1.086200 -1.117200 -1.214200 -9.9658 -9.9658 0.84880 -9.9658 -3.625900 -9.965800 -9.965800 -5.573500 5.737700 -9.9658 -9.9658 -9.9658 -9.9658 2.150900 ... -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 3.408800 -9.965800 0.099000 -9.9658 -9.9658 0.6969 -9.9658 2.111400 -9.9658 -9.9658 -9.9658 3.570600 0.566600 -9.9658 -9.9658 -9.9658 3.149100 -9.9658 -9.9658 -9.9658 -9.9658 1.590200 6.864000 -1.7809 -9.9658 -9.9658 0.264200 -3.6259 -9.965800 3.435800 -2.547900 -9.9658 -9.9658 TCGA-RP-A695-06 -9.9658 -9.9658 -9.9658 5.230800 -9.9658 3.092700 -9.965800 -9.9658 3.201800 -3.45800 -9.9658 10.228500 -9.9658 -9.9658 5.436700 -9.9658 -1.994200 -5.573500 -9.9658 -9.9658 -9.9658 -9.9658 -5.011600 -2.465900 -0.284500 0.566600 -9.9658 -9.9658 1.18330 -9.9658 -9.965800 -6.506400 -9.965800 -3.046900 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 6.128700 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 5.601400 -9.965800 1.580600 -9.9658 -9.9658 -4.6082 -9.9658 3.502200 -9.9658 -9.9658 -9.9658 4.384800 3.737800 -9.9658 -9.9658 -9.9658 4.073000 -9.9658 -9.9658 -9.9658 -9.9658 2.451800 -4.293400 -6.5064 -9.9658 -9.9658 1.316700 -9.9658 -3.458000 6.590700 -9.965800 -9.9658 -9.9658 TCGA-DD-AAW0-01 -9.9658 -9.9658 -9.9658 4.607700 -9.9658 2.646400 -4.293400 -9.9658 3.808500 -4.29340 -9.9658 8.705700 -9.9658 -9.9658 4.635200 -9.9658 -9.965800 -1.780900 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 0.783200 0.215400 0.444700 -9.9658 -9.9658 1.48590 -9.9658 -9.965800 -5.573500 -9.965800 -5.011600 5.382700 -9.9658 -9.9658 -9.9658 -9.9658 1.196000 ... -4.6082 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 4.635800 -9.965800 1.339700 -9.9658 -9.9658 -4.0350 -9.9658 3.489400 -9.9658 -9.9658 -9.9658 4.165200 1.566100 -9.9658 -9.9658 -4.6082 3.956100 -9.9658 -9.9658 -9.9658 -9.9658 2.186200 7.373500 -5.5735 -9.9658 -9.9658 0.001400 -9.9658 -9.965800 4.631700 -6.506400 -9.9658 -9.9658 TCGA-EE-A17X-06 -9.9658 -1.6850 -9.9658 5.574100 -9.9658 3.165300 -9.965800 -9.9658 2.582800 -6.50640 -9.9658 10.009000 -9.9658 -9.9658 4.784600 -9.9658 -2.314700 -4.608200 -9.9658 -9.9658 -9.9658 -9.9658 -5.011600 -2.314700 -0.338300 -0.249800 -9.9658 -9.9658 0.64250 -9.9658 -9.965800 -9.965800 -0.997100 -6.506400 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 5.923400 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 6.418900 -9.965800 1.322500 -9.9658 -9.9658 -5.5735 -9.9658 4.085800 -9.9658 -9.9658 -9.9658 5.278400 4.536100 -9.9658 -9.9658 -9.9658 5.495700 -9.9658 -9.9658 -9.9658 -9.9658 2.205100 -3.816000 -9.9658 -9.9658 -9.9658 -0.687300 -3.6259 -9.965800 7.805800 -6.506400 -9.9658 -9.9658 TCGA-DD-AACA-02 -9.9658 -9.9658 -9.9658 4.080749 -9.9658 -2.114057 0.407079 -9.9658 3.499608 -3.62591 -9.9658 10.322895 -9.9658 -9.9658 4.162807 -9.9658 -4.442233 -3.921375 -9.9658 -9.9658 -9.9658 -9.9658 -5.965822 -3.717877 0.276236 -0.619235 -9.9658 -9.9658 0.79993 -9.9658 -3.380826 -2.775961 -4.293386 -7.380866 1.543998 -9.9658 -9.9658 -9.9658 -9.9658 2.055201 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 4.657673 -3.625967 0.856772 -9.9658 -9.9658 -9.9658 -9.9658 3.205689 -9.9658 -9.9658 -9.9658 4.628535 2.168608 -9.9658 -9.9658 -9.9658 4.183576 -9.9658 -9.9658 -9.9658 -9.9658 1.331141 6.773435 -9.9658 -9.9658 -9.9658 -0.641625 -9.9658 -4.442233 5.034368 -1.910505 -9.9658 -9.9658 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... TCGA-EE-A2GN-06 -9.9658 -9.9658 -4.2934 3.773000 -9.9658 3.740000 -2.826200 -9.9658 4.802200 -2.46590 -9.9658 11.006800 -9.9658 -9.9658 5.737700 -9.9658 -2.314700 -3.046900 -9.9658 -9.9658 -9.9658 -9.9658 -3.307600 -1.469900 0.723300 0.888300 -9.9658 -9.9658 1.88790 -9.9658 -9.965800 -3.046900 -9.965800 -3.046900 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 4.970900 ... -3.4580 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 5.912400 -9.965800 2.694000 -9.9658 -9.9658 -6.5064 -9.9658 3.270700 -9.9658 -9.9658 -0.7108 5.218000 4.586200 -9.9658 -9.9658 -9.9658 5.684000 -9.9658 -3.8160 -9.9658 -9.9658 3.132700 -6.506400 -3.6259 -9.9658 -9.9658 1.526600 -3.6259 -2.547900 5.724700 -4.293400 -9.9658 -9.9658 TCGA-D9-A4Z6-06 -9.9658 -9.9658 -9.9658 5.684600 -9.9658 3.996500 -6.506400 -9.9658 4.482900 -2.05290 -9.9658 10.159600 -9.9658 -9.9658 4.879800 -9.9658 -0.284500 -2.932400 -9.9658 -9.9658 -9.9658 -9.9658 -4.293400 -1.639400 1.098300 -0.087700 -9.9658 -9.9658 1.26960 -9.9658 -2.177900 -5.011600 -9.965800 -3.307600 -9.965800 -9.9658 -4.2934 -9.9658 -9.9658 6.171300 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 6.079200 -9.965800 2.018300 -9.9658 -9.9658 -4.0350 -9.9658 2.912800 -9.9658 -9.9658 -1.0262 5.615300 3.476500 -9.9658 -9.9658 -9.9658 4.551600 -9.9658 -9.9658 -9.9658 -9.9658 2.498500 -9.965800 -9.9658 -9.9658 -9.9658 0.368500 -3.1714 -9.965800 6.529700 -3.307600 -9.9658 -9.9658 TCGA-EE-A29L-06 -4.6082 -9.9658 -9.9658 5.281700 -9.9658 4.370200 -6.506400 -9.9658 3.438400 -9.96580 -9.9658 10.427600 -9.9658 -9.9658 6.153200 -9.9658 -5.573500 -5.011600 -9.9658 -9.9658 -9.9658 -2.1779 -6.506400 -1.181100 2.046500 -1.430500 -9.9658 -9.9658 -0.43250 -9.9658 -2.727400 -4.035000 -2.388400 -6.506400 -9.965800 -9.9658 -5.0116 -9.9658 -9.9658 7.421200 ... -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 5.801700 -9.965800 3.513600 -9.9658 -9.9658 -5.5735 -9.9658 4.181200 -9.9658 -9.9658 -9.9658 5.083300 3.028700 -9.9658 -9.9658 -9.9658 6.211000 -9.9658 -9.9658 -9.9658 -9.9658 2.985700 -9.965800 -6.5064 -9.9658 -9.9658 2.070700 -9.9658 -2.634900 6.078800 -9.965800 -9.9658 -9.9658 TCGA-DD-A115-01 -9.9658 -9.9658 -9.9658 4.026000 -9.9658 2.154100 -1.318300 -9.9658 3.260200 -4.03500 -3.8160 9.137500 -9.9658 -4.6082 4.263100 -9.9658 -5.573500 -3.307600 -9.9658 -9.9658 -9.9658 -9.9658 -5.573500 -0.042500 -0.375200 0.240000 -9.9658 -9.9658 2.28130 -9.9658 -9.965800 -9.965800 -2.932400 -5.573500 2.899400 -9.9658 -9.9658 -9.9658 -9.9658 2.716100 ... -1.1172 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 4.764500 -9.965800 0.749300 -9.9658 -9.9658 -1.7322 -9.9658 3.411600 -9.9658 -9.9658 -9.9658 3.997400 1.164100 -9.9658 -9.9658 -9.9658 3.720400 -9.9658 -9.9658 -9.9658 -9.9658 1.820100 6.673000 -2.1779 -9.9658 -9.9658 0.311500 -9.9658 -9.965800 4.464700 -2.388400 -9.9658 -9.9658 TCGA-FV-A3I0-11 -9.9658 -9.9658 -9.9658 3.087600 -9.9658 -0.575600 -9.965800 -9.9658 1.692000 -9.96580 -9.9658 8.292000 -9.9658 -9.9658 3.569400 -9.9658 -5.011600 -2.388400 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -1.595100 -1.994200 -0.687300 -9.9658 -9.9658 -0.32010 -9.9658 -9.965800 -9.965800 -9.965800 -6.506400 5.202100 -9.9658 -9.9658 -9.9658 -9.9658 3.309000 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 3.577900 -9.965800 0.357300 -9.9658 -9.9658 0.0158 -9.9658 2.160600 -9.9658 -9.9658 -9.9658 3.577900 0.774800 -9.9658 -9.9658 -9.9658 3.082500 -9.9658 -9.9658 -9.9658 -9.9658 -0.249800 7.026400 -2.2447 -9.9658 -9.9658 0.614500 -9.9658 -9.965800 3.217400 -3.046900 -9.9658 -9.9658 936 rows \u00d7 60498 columns Now we are ready to fit the PCA fit = pca . fit ( X ) fit PCA(copy=True, iterated_power='auto', n_components=None, random_state=None, svd_solver='auto', tol=0.0, whiten=False) Plot the explained variance by the number of components for any components that explain at least 0.5% of the variance components_df = pd . DataFrame ( enumerate ( fit . explained_variance_ratio_ ), columns = [ 'component' , 'variance_explained' ]) components_df [ 'cum_var' ] = components_df . variance_explained . cumsum () components_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } component variance_explained cum_var 0 0 2.098103e-01 0.209810 1 1 4.941317e-02 0.259223 2 2 2.684464e-02 0.286068 3 3 2.096802e-02 0.307036 4 4 1.821842e-02 0.325255 ... ... ... ... 931 931 2.724521e-04 0.999199 932 932 2.708955e-04 0.999470 933 933 2.679152e-04 0.999738 934 934 2.619554e-04 1.000000 935 935 2.545080e-28 1.000000 936 rows \u00d7 3 columns fig = sns . relplot ( data = components_df [ components_df . variance_explained >= 0.005 ], x = 'component' , y = 'variance_explained' , kind = 'line' ) fig . set ( xlabel = 'Component #' , ylabel = 'Proportion of Variance Explained' ) <seaborn.axisgrid.FacetGrid at 0x7f3bc2ef49d0> If we want to see the variance explained as we keep X components we can plot that as well fig = sns . relplot ( data = components_df , x = 'component' , y = 'cum_var' , kind = 'line' ) fig . set ( xlabel = 'Number of Components' , ylabel = 'Proportion of Variance Explained' ) <seaborn.axisgrid.FacetGrid at 0x7f3bc2ec0450> To visualize this in 2-d we can only plot the first two components pca_xy = PCA ( n_components = 2 ) fit_xy = pd . DataFrame ( pca_xy . fit_transform ( X ), index = X . index , columns = [ 'component 1' , 'component 2' ]) fit_xy .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } component 1 component 2 TCGA-G3-A3CH-11 313.877223 58.038358 TCGA-RP-A695-06 -178.026704 152.348532 TCGA-DD-AAW0-01 205.633995 -104.460686 TCGA-EE-A17X-06 -185.690333 172.857407 TCGA-DD-AACA-02 226.342307 -60.439144 ... ... ... TCGA-EE-A2GN-06 -253.444806 21.297225 TCGA-D9-A4Z6-06 -243.644653 27.199689 TCGA-EE-A29L-06 -220.859424 123.556796 TCGA-DD-A115-01 250.808496 -44.392051 TCGA-FV-A3I0-11 375.594610 127.824032 936 rows \u00d7 2 columns Now join this back to the metadata to get the groupings fig_df = fit_xy . reset_index () . rename ( columns = { 'index' : 'sample' }) . merge ( meta_df , on = [ 'sample' ], how = 'left' ) fig_df [[ 'sample' , 'component 1' , 'component 2' , 'cancer type abbreviation' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample component 1 component 2 cancer type abbreviation 0 TCGA-G3-A3CH-11 313.877223 58.038358 LIHC 1 TCGA-RP-A695-06 -178.026704 152.348532 SKCM 2 TCGA-DD-AAW0-01 205.633995 -104.460686 LIHC 3 TCGA-EE-A17X-06 -185.690333 172.857407 SKCM 4 TCGA-DD-AACA-02 226.342307 -60.439144 LIHC ... ... ... ... ... 931 TCGA-EE-A2GN-06 -253.444806 21.297225 SKCM 932 TCGA-D9-A4Z6-06 -243.644653 27.199689 SKCM 933 TCGA-EE-A29L-06 -220.859424 123.556796 SKCM 934 TCGA-DD-A115-01 250.808496 -44.392051 LIHC 935 TCGA-FV-A3I0-11 375.594610 127.824032 LIHC 936 rows \u00d7 4 columns Add a flag column for our sample of interest fig_df . loc [ fig_df [ 'sample' ] == test_sample_id , 'target sample' ] = True fig_df [ 'target sample' ] = fig_df [ 'target sample' ] . fillna ( False ) fig_df [[ 'sample' , 'component 1' , 'component 2' , 'cancer type abbreviation' , 'target sample' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample component 1 component 2 cancer type abbreviation target sample 0 TCGA-G3-A3CH-11 313.877223 58.038358 LIHC True 1 TCGA-RP-A695-06 -178.026704 152.348532 SKCM False 2 TCGA-DD-AAW0-01 205.633995 -104.460686 LIHC False 3 TCGA-EE-A17X-06 -185.690333 172.857407 SKCM False 4 TCGA-DD-AACA-02 226.342307 -60.439144 LIHC False ... ... ... ... ... ... 931 TCGA-EE-A2GN-06 -253.444806 21.297225 SKCM False 932 TCGA-D9-A4Z6-06 -243.644653 27.199689 SKCM False 933 TCGA-EE-A29L-06 -220.859424 123.556796 SKCM False 934 TCGA-DD-A115-01 250.808496 -44.392051 LIHC False 935 TCGA-FV-A3I0-11 375.594610 127.824032 LIHC False 936 rows \u00d7 5 columns fig = sns . relplot ( kind = 'scatter' , data = fig_df , x = 'component 1' , y = 'component 2' , hue = 'cancer type abbreviation' ) Add the annotation to pick out our current sample in the PCA. We are going to plot overtop of the original plot to accomplish this ax = sns . scatterplot ( data = fig_df , x = 'component 1' , y = 'component 2' , hue = 'cancer type abbreviation' , alpha = 0.5 ) ax = sns . scatterplot ( data = fig_df [ fig_df [ 'sample' ] == test_sample_id ], x = 'component 1' , y = 'component 2' , marker = 'X' , alpha = 1 , ax = ax , color = 'black' , s = 300 ) As we saw with the correlation plot, the LIHC sample is grouped with its disease cohort","title":"RNA Expression Similarity"},{"location":"ipr/scripting/RNA_Expression_Similarity/#computing-rna-expression-similarity","text":"","title":"Computing RNA Expression Similarity"},{"location":"ipr/scripting/RNA_Expression_Similarity/#download-the-data","text":"First we need to download the data set we will use. We are going to use the TCGA data here since it is publically available and well known ( UCSC Xena TCGA PANCAN ). We will download the TPM matrix as well as the corresponding metadata file ! wget https : // toil - xena - hub . s3 . us - east - 1. amazonaws . com / download / tcga_RSEM_gene_tpm . gz ! wget https : // tcga - pancan - atlas - hub . s3 . us - east - 1. amazonaws . com / download / Survival_SupplementalTable_S1_20171025_xena_sp --2021-06-10 17:34:56-- https://toil-xena-hub.s3.us-east-1.amazonaws.com/download/tcga_RSEM_gene_tpm.gz Resolving toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)... 52.216.136.30 Connecting to toil-xena-hub.s3.us-east-1.amazonaws.com (toil-xena-hub.s3.us-east-1.amazonaws.com)|52.216.136.30|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 740772247 (706M) [binary/octet-stream] Saving to: \u2018tcga_RSEM_gene_tpm.gz\u2019 tcga_RSEM_gene_tpm. 100%[===================>] 706.46M 15.5MB/s in 49s 2021-06-10 17:35:46 (14.5 MB/s) - \u2018tcga_RSEM_gene_tpm.gz\u2019 saved [740772247/740772247] --2021-06-10 17:35:46-- https://tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com/download/Survival_SupplementalTable_S1_20171025_xena_sp Resolving tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)... 52.216.94.142 Connecting to tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)|52.216.94.142|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2419504 (2.3M) [binary/octet-stream] Saving to: \u2018Survival_SupplementalTable_S1_20171025_xena_sp\u2019 Survival_Supplement 100%[===================>] 2.31M 1.75MB/s in 1.3s 2021-06-10 17:35:48 (1.75 MB/s) - \u2018Survival_SupplementalTable_S1_20171025_xena_sp\u2019 saved [2419504/2419504] The matrix we have downloaded is very large as it contains many different disease cohorts. For the purposes of this tutorial we want a smaller data set so we are going to choose the smallest TCGA cohort, CHOL. To do this we need to use the metadata file to subset the main matrix file","title":"Download the Data"},{"location":"ipr/scripting/RNA_Expression_Similarity/#install-dependencies","text":"For the following tutorial we are going to use some common data processing and visualization libraries in python: seaborn and pandas. We need to install them before we proceed ! pip install pandas seaborn Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5) Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1) Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9) Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1) Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5) Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2) Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1) Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7) Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0) Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)","title":"Install Dependencies"},{"location":"ipr/scripting/RNA_Expression_Similarity/#create-the-disease-matrix","text":"First read the metadata file import json import seaborn as sns import pandas as pd from matplotlib import pyplot as plt import numpy as np sns . set_style ( 'whitegrid' ) meta_df = pd . read_csv ( 'Survival_SupplementalTable_S1_20171025_xena_sp' , sep = ' \\t ' ) meta_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample _PATIENT cancer type abbreviation age_at_initial_pathologic_diagnosis gender race ajcc_pathologic_tumor_stage clinical_stage histological_type histological_grade initial_pathologic_dx_year menopause_status birth_days_to vital_status tumor_status last_contact_days_to death_days_to cause_of_death new_tumor_event_type new_tumor_event_site new_tumor_event_site_other new_tumor_event_dx_days_to treatment_outcome_first_course margin_status residual_tumor OS OS.time DSS DSS.time DFI DFI.time PFI PFI.time Redaction 0 TCGA-OR-A5J1-01 TCGA-OR-A5J1 ACC 58.0 MALE WHITE Stage II NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -21496.0 Dead WITH TUMOR NaN 1355.0 NaN Distant Metastasis Peritoneal Surfaces NaN 754.0 Complete Remission/Response NaN NaN 1.0 1355.0 1.0 1355.0 1.0 754.0 1.0 754.0 NaN 1 TCGA-OR-A5J2-01 TCGA-OR-A5J2 ACC 44.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2004.0 NaN -16090.0 Dead WITH TUMOR NaN 1677.0 NaN Distant Metastasis Soft Tissue NaN 289.0 Progressive Disease NaN NaN 1.0 1677.0 1.0 1677.0 NaN NaN 1.0 289.0 NaN 2 TCGA-OR-A5J3-01 TCGA-OR-A5J3 ACC 23.0 FEMALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2008.0 NaN -8624.0 Alive WITH TUMOR 2091.0 NaN NaN Distant Metastasis Lung NaN 53.0 Complete Remission/Response NaN NaN 0.0 2091.0 0.0 2091.0 1.0 53.0 1.0 53.0 NaN 3 TCGA-OR-A5J4-01 TCGA-OR-A5J4 ACC 23.0 FEMALE WHITE Stage IV NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -8451.0 Dead WITH TUMOR NaN 423.0 NaN Locoregional Recurrence Peritoneal Surfaces NaN 126.0 Progressive Disease NaN NaN 1.0 423.0 1.0 423.0 NaN NaN 1.0 126.0 NaN 4 TCGA-OR-A5J5-01 TCGA-OR-A5J5 ACC 30.0 MALE WHITE Stage III NaN Adrenocortical carcinoma- Usual Type NaN 2000.0 NaN -11171.0 Dead WITH TUMOR NaN 365.0 NaN Locoregional Recurrence Other, specify vena cava thrombus 50.0 Progressive Disease NaN NaN 1.0 365.0 1.0 365.0 NaN NaN 1.0 50.0 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 12586 TCGA-YZ-A980-01 TCGA-YZ-A980 UVM 75.0 MALE WHITE Stage IIIA Stage IIIA Spindle Cell|Epithelioid Cell NaN 2010.0 NaN -27716.0 Alive TUMOR FREE 1862.0 NaN NaN New Primary Tumor Other, specify Scalp 1556.0 NaN NaN NaN 0.0 1862.0 0.0 1862.0 NaN NaN 1.0 1556.0 NaN 12587 TCGA-YZ-A982-01 TCGA-YZ-A982 UVM 79.0 FEMALE WHITE Stage IIIB Stage IIIB Spindle Cell NaN 2013.0 NaN -28938.0 Alive TUMOR FREE 495.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 495.0 0.0 495.0 NaN NaN 0.0 495.0 NaN 12588 TCGA-YZ-A983-01 TCGA-YZ-A983 UVM 51.0 FEMALE WHITE Stage IIB Stage IIB Epithelioid Cell NaN 2013.0 NaN -18769.0 Alive TUMOR FREE 798.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 798.0 0.0 798.0 NaN NaN 0.0 798.0 NaN 12589 TCGA-YZ-A984-01 TCGA-YZ-A984 UVM 50.0 FEMALE WHITE Stage IIB Stage IIIA Spindle Cell|Epithelioid Cell NaN 2011.0 NaN -18342.0 Dead WITH TUMOR NaN 1396.0 Metastatic Uveal Melanoma New Primary Tumor Other, specify Thyroid 154.0 NaN NaN NaN 1.0 1396.0 1.0 1396.0 NaN NaN 1.0 154.0 NaN 12590 TCGA-YZ-A985-01 TCGA-YZ-A985 UVM 41.0 FEMALE WHITE Stage IIIA Stage IIIA Spindle Cell NaN 2012.0 NaN -15164.0 Alive TUMOR FREE 1184.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN 0.0 1184.0 0.0 1184.0 NaN NaN 0.0 1184.0 NaN 12591 rows \u00d7 34 columns To facilitate running this quickly and with low compute resource requirements we will use a subset of the total set of samples. In practice we would likely store this in a database to improve performance. If you would like to use the entire data set you can remove the \"usecols\" part of read_csv. Let's use the metadata file to see how many samples we have in each of the different cohorts meta_df . groupby ( 'cancer type abbreviation' ) . agg ({ 'sample' : 'nunique' }) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample cancer type abbreviation ACC 92 BLCA 436 BRCA 1236 CESC 312 CHOL 45 COAD 545 DLBC 48 ESCA 204 GBM 602 HNSC 604 KICH 91 KIRC 944 KIRP 352 LAML 200 LGG 529 LIHC 438 LUAD 641 LUSC 623 MESO 87 OV 604 PAAD 196 PCPG 187 PRAD 566 READ 183 SARC 271 SKCM 479 STAD 511 TGCT 139 THCA 580 THYM 126 UCEC 583 UCS 57 UVM 80 Now we will select a couple of cohorts - CHOL - LIHC - SKCM columns_to_keep = set ([ 'sample' ] + meta_df [ meta_df [ 'cancer type abbreviation' ] . isin ({ 'CHOL' , 'SKCM' , 'LIHC' })][ 'sample' ] . tolist ()) len ( columns_to_keep ) 963 Reading the data matrix is a lot of data and so this process is slow. This will still probably take a few minutes. In practice we likely store this in a database to improvement performance exp_matrix = pd . read_csv ( 'tcga_RSEM_gene_tpm.gz' , compression = 'gzip' , sep = ' \\t ' , usecols = lambda x : x in columns_to_keep ) To make things less confusing we will rename the \"sample\" column as \"gene\" since that is what is actually in that column exp_matrix = exp_matrix . rename ( columns = { 'sample' : 'gene' }) exp_matrix = exp_matrix . set_index ( 'gene' ) exp_matrix .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TCGA-G3-A3CH-11 TCGA-RP-A695-06 TCGA-DD-AAW0-01 TCGA-EE-A17X-06 TCGA-DD-AACA-02 TCGA-DD-AACA-01 TCGA-D3-A8GD-06 TCGA-DD-A3A6-11 TCGA-K7-AAU7-01 TCGA-FS-A1ZF-06 TCGA-EB-A41A-01 TCGA-RC-A7SH-01 TCGA-CC-A3MA-01 TCGA-DD-A3A5-11 TCGA-RC-A7SB-01 TCGA-D3-A3ML-06 TCGA-EE-A2GB-06 TCGA-DD-AAVZ-01 TCGA-DD-A116-11 TCGA-ED-A627-01 TCGA-ER-A19S-06 TCGA-EE-A3AB-06 TCGA-DD-AAVV-01 TCGA-XV-AAZW-01 TCGA-D3-A5GR-06 TCGA-BC-4073-01 TCGA-W3-AA1R-06 TCGA-QA-A7B7-01 TCGA-DA-A1IC-06 TCGA-D3-A51G-06 TCGA-BF-A5ER-01 TCGA-HP-A5N0-01 TCGA-D3-A5GU-06 TCGA-ZH-A8Y5-01 TCGA-FS-A1ZB-06 TCGA-DD-A114-11 TCGA-DD-A1EG-11 TCGA-DD-AAEI-01 TCGA-4G-AAZT-01 TCGA-DD-AACT-01 ... TCGA-BC-A112-01 TCGA-BW-A5NO-01 TCGA-FV-A3I1-11 TCGA-D3-A3MU-06 TCGA-ER-A2NB-01 TCGA-XV-A9W2-01 TCGA-UB-A7MF-01 TCGA-WX-AA44-01 TCGA-ER-A194-01 TCGA-DD-AACQ-01 TCGA-D3-A2JH-06 TCGA-EE-A2GR-06 TCGA-G3-A25U-01 TCGA-FS-A4F4-06 TCGA-DD-A1EK-01 TCGA-EB-A3XE-01 TCGA-DD-A11C-11 TCGA-BC-A10Q-11 TCGA-EE-A2GI-06 TCGA-EP-A12J-01 TCGA-W5-AA2X-11 TCGA-D9-A1JX-06 TCGA-D3-A2JL-06 TCGA-EE-A2MM-06 TCGA-DD-AAED-01 TCGA-DA-A95X-06 TCGA-DD-A1EG-01 TCGA-BC-A10R-01 TCGA-EE-A2MF-06 TCGA-G3-A3CG-01 TCGA-DD-A1ED-01 TCGA-2Y-A9H8-01 TCGA-2Y-A9GT-01 TCGA-3N-A9WD-06 TCGA-DA-A95W-06 TCGA-EE-A2GN-06 TCGA-D9-A4Z6-06 TCGA-EE-A29L-06 TCGA-DD-A115-01 TCGA-FV-A3I0-11 gene ENSG00000242268.2 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -3.1714 -9.9658 -9.9658 -4.6082 -9.9658 -9.9658 -9.9658 -5.0116 -3.8160 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -4.6082 -2.3884 -1.8314 -5.0116 -9.9658 -3.3076 -9.9658 -4.0350 -9.9658 -9.9658 -1.7322 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.8160 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.4580 -9.9658 -1.9942 -9.9658 -1.4699 -9.9658 -0.4325 -9.9658 -9.9658 -9.9658 -1.5105 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -5.0116 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -2.6349 -2.6349 -9.9658 -9.9658 -4.6082 -9.9658 -9.9658 ENSG00000259041.1 -9.9658 -9.9658 -9.9658 -1.6850 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.3076 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -0.9406 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000270112.3 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -2.0529 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 0.9343 -9.9658 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -6.5064 -9.9658 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -6.5064 -9.9658 -9.9658 -4.2934 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000167578.16 3.5572 5.2308 4.6077 5.5741 4.080749 3.2018 6.1010 3.1540 4.5098 5.6767 5.7337 5.8094 3.7367 3.4739 4.8125 3.8954 5.2972 4.1700 3.1028 4.8485 5.1223 5.2235 4.8440 6.3684 4.8299 4.3169 5.7307 4.7539 4.0636 6.1067 4.6916 3.9487 4.6854 4.0575 5.6186 4.1310 3.1129 2.9966 5.2430 4.5772 ... 4.5324 4.9294 3.2557 5.3917 5.1052 4.8033 5.5799 5.0009 5.6930 4.5367 5.5571 4.6759 3.2988 5.7052 4.3903 5.7391 3.5299 3.2174 4.8827 4.0488 3.8808 5.5568 5.8390 4.2943 4.4647 4.6764 4.4310 4.7735 5.5503 3.7475 4.2072 4.6960 4.4324 4.5311 4.3541 3.7730 5.6846 5.2817 4.0260 3.0876 ENSG00000278814.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ENSG00000273233.1 -9.9658 -3.4580 -9.9658 -9.9658 -4.442233 -9.9658 -9.9658 -9.9658 -2.0529 -2.7274 -9.9658 -2.5479 -3.4580 -9.9658 -9.9658 -4.0350 -3.6259 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.6259 -3.4580 -9.9658 -3.6259 -2.8262 -9.9658 -1.9379 -9.9658 -3.3076 -3.3076 -9.9658 -2.7274 -9.9658 -9.9658 -9.9658 -1.9942 -9.9658 ... -9.9658 -9.9658 -9.9658 -2.4659 -9.9658 -2.3884 -4.0350 -2.9324 -9.9658 -9.9658 -3.4580 -9.9658 -9.9658 -3.1714 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -3.3076 -2.4659 -9.9658 -9.9658 -9.9658 -3.8160 -2.8262 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -2.5479 -9.9658 -2.6349 -9.9658 -9.9658 ENSG00000105063.18 3.4358 6.5907 4.6317 7.8058 5.034368 5.2365 6.0885 2.2175 4.9346 5.3906 5.1416 5.7926 4.9393 2.9356 4.5154 4.8832 7.1736 4.6247 2.8301 4.3855 5.7978 5.4300 5.2211 5.0879 5.6574 4.8435 6.5130 5.2825 5.7211 5.4050 6.0856 3.4277 5.0972 5.1157 5.9709 3.8591 2.8681 4.2366 4.9901 4.2699 ... 5.2169 3.9974 3.2677 6.4069 4.6236 4.7507 5.1930 5.1343 5.5236 4.5571 6.1048 5.5448 3.9289 5.7727 4.5820 4.9069 2.9857 2.7551 5.9905 4.6106 3.4778 5.8316 5.1575 6.0275 4.6053 5.5871 4.9141 4.6815 5.6848 4.2189 3.3549 5.0900 4.0884 4.5892 4.7735 5.7247 6.5297 6.0788 4.4647 3.2174 ENSG00000231119.2 -2.5479 -9.9658 -6.5064 -6.5064 -1.910505 -2.4659 -1.4305 -1.8836 -3.1714 -2.1779 -5.0116 -4.2934 -4.2934 -3.0469 -2.4659 -1.3548 -1.9942 -4.0350 -4.0350 -2.1779 -2.7274 -2.8262 -1.8314 -3.8160 -2.3147 -3.3076 -2.4659 -9.9658 -3.4580 -0.7108 -5.5735 -3.6259 -3.1714 -4.2934 -6.5064 -5.0116 -3.8160 -2.5479 -5.5735 -2.9324 ... -5.0116 -1.7809 -2.5479 -4.6082 -9.9658 -5.0116 -3.8160 -2.6349 -9.9658 -4.0350 -3.6259 -2.7274 -3.6259 -5.0116 -4.0350 -1.0559 -4.2934 -5.0116 -4.2934 -2.6349 -2.9324 -1.0862 -5.5735 -9.9658 -2.6349 -1.6850 -1.5522 -3.6259 -3.8160 -3.3076 -1.0262 -5.0116 -3.3076 -2.9324 -5.0116 -4.2934 -3.3076 -9.9658 -2.3884 -3.0469 ENSG00000280861.1 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ENSG00000181518.3 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -5.5735 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 60498 rows \u00d7 936 columns Now that we have our matrix we are ready to start the correlation","title":"Create the Disease Matrix"},{"location":"ipr/scripting/RNA_Expression_Similarity/#spearman-correlation","text":"The input for an analysis where a patient sample is being compared to the TCGA cohort of interest would typically be an expression matrix using the same normalization method as the comparator cohort. Note that differences in library preparation, sequencing and bioinformatics pipelines can lead to variation in expression quantification. It is important to understand the impact these differences have on expression quantification before comparing expression values that are produced using different pipelines. For the purposes of this tutorial we are going to choose one of the CHOL samples from our expression matrix to use as our input. We arbitrarily choose the first sample. test_sample_id = str ( exp_matrix . iloc [ 0 ] . index [ 0 ]) meta_df [ meta_df [ 'sample' ] == test_sample_id ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample _PATIENT cancer type abbreviation age_at_initial_pathologic_diagnosis gender race ajcc_pathologic_tumor_stage clinical_stage histological_type histological_grade initial_pathologic_dx_year menopause_status birth_days_to vital_status tumor_status last_contact_days_to death_days_to cause_of_death new_tumor_event_type new_tumor_event_site new_tumor_event_site_other new_tumor_event_dx_days_to treatment_outcome_first_course margin_status residual_tumor OS OS.time DSS DSS.time DFI DFI.time PFI PFI.time Redaction 6583 TCGA-G3-A3CH-11 TCGA-G3-A3CH LIHC 53.0 MALE ASIAN Stage IIIA NaN Hepatocellular Carcinoma G2 2010.0 NaN -19473.0 Alive WITH TUMOR 780.0 NaN NaN Intrahepatic Recurrence Liver NaN 116.0 NaN NaN R0 0.0 780.0 0.0 780.0 1.0 116.0 1.0 116.0 NaN Now we compute the correlation of this sample with all other samples in the matrix excluding itself corr = exp_matrix [[ c for c in exp_matrix . columns . tolist () if c != test_sample_id ]] . corrwith ( exp_matrix [ test_sample_id ], method = 'spearman' ) . to_frame () corr = corr . rename ( columns = { corr . columns [ 0 ]: \"correlation\" }) . reset_index () . rename ( columns = { 'index' : 'sample' }) corr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample correlation 0 TCGA-RP-A695-06 0.840728 1 TCGA-DD-AAW0-01 0.901187 2 TCGA-EE-A17X-06 0.825520 3 TCGA-DD-AACA-02 0.871860 4 TCGA-DD-AACA-01 0.883324 ... ... ... 930 TCGA-EE-A2GN-06 0.838558 931 TCGA-D9-A4Z6-06 0.824104 932 TCGA-EE-A29L-06 0.817158 933 TCGA-DD-A115-01 0.885494 934 TCGA-FV-A3I0-11 0.908514 935 rows \u00d7 2 columns Merge that with the metadata to group the correlations into their respective cohorts for plotting corr = corr . merge ( meta_df [[ 'sample' , 'cancer type abbreviation' ]], on = [ 'sample' ], how = 'left' ) corr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample correlation cancer type abbreviation 0 TCGA-RP-A695-06 0.840728 SKCM 1 TCGA-DD-AAW0-01 0.901187 LIHC 2 TCGA-EE-A17X-06 0.825520 SKCM 3 TCGA-DD-AACA-02 0.871860 LIHC 4 TCGA-DD-AACA-01 0.883324 LIHC ... ... ... ... 930 TCGA-EE-A2GN-06 0.838558 SKCM 931 TCGA-D9-A4Z6-06 0.824104 SKCM 932 TCGA-EE-A29L-06 0.817158 SKCM 933 TCGA-DD-A115-01 0.885494 LIHC 934 TCGA-FV-A3I0-11 0.908514 LIHC 935 rows \u00d7 3 columns Now plot the correlations fig = sns . catplot ( kind = 'box' , data = corr , x = 'correlation' , y = 'cancer type abbreviation' ) title = test_sample_id + ' (' + meta_df [ meta_df [ 'sample' ] == test_sample_id ] . iloc [ 0 ][ 'cancer type abbreviation' ] + ')' fig . set ( xlabel = 'spearman correlation' , ylabel = '' , title = title ) <seaborn.axisgrid.FacetGrid at 0x7f3bc4d89350> As expected, the average pairwise correlation is highest within the same disease cohort as the sample","title":"Spearman Correlation"},{"location":"ipr/scripting/RNA_Expression_Similarity/#principle-component-analysis-pca","text":"The principal component analysis would serve a similar function to the pairwise spearman correlations plot above and could be included in place of said plot if preferred. For this we will need to install more python libraries ! pip install scikit - learn Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1) Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1) Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5) Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1) Now we are ready to set up the PCA model. from sklearn.decomposition import PCA pca = PCA () Our input to the PCA model is a matrix with each sample as a row. Since in our current matrix the genes are rows we need to transpose this X = exp_matrix . T X .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gene ENSG00000242268.2 ENSG00000259041.1 ENSG00000270112.3 ENSG00000167578.16 ENSG00000278814.1 ENSG00000078237.5 ENSG00000269416.5 ENSG00000263642.1 ENSG00000146083.11 ENSG00000158486.13 ENSG00000273639.4 ENSG00000198242.13 ENSG00000231981.3 ENSG00000269475.2 ENSG00000134108.12 ENSG00000261030.1 ENSG00000172137.18 ENSG00000276644.4 ENSG00000240423.1 ENSG00000271616.1 ENSG00000234881.1 ENSG00000236040.1 ENSG00000231105.1 ENSG00000094963.13 ENSG00000182141.9 ENSG00000280143.1 ENSG00000251334.2 ENSG00000231112.1 ENSG00000258610.1 ENSG00000264981.1 ENSG00000275265.1 ENSG00000185105.4 ENSG00000233540.1 ENSG00000102174.8 ENSG00000166391.14 ENSG00000232001.1 ENSG00000270469.1 ENSG00000225275.4 ENSG00000234253.1 ENSG00000070087.13 ... ENSG00000279778.1 ENSG00000223671.2 ENSG00000263573.1 ENSG00000222213.1 ENSG00000214124.3 ENSG00000206836.1 ENSG00000233845.1 ENSG00000066044.13 ENSG00000264491.1 ENSG00000146587.17 ENSG00000278151.1 ENSG00000228658.1 ENSG00000173930.8 ENSG00000274396.1 ENSG00000107863.16 ENSG00000199892.2 ENSG00000221760.1 ENSG00000253333.1 ENSG00000213782.7 ENSG00000146707.14 ENSG00000212084.2 ENSG00000248838.2 ENSG00000255083.1 ENSG00000158417.10 ENSG00000223665.1 ENSG00000203729.8 ENSG00000238300.1 ENSG00000221756.1 ENSG00000089177.17 ENSG00000186115.12 ENSG00000009694.13 ENSG00000238244.3 ENSG00000216352.1 ENSG00000123685.8 ENSG00000267117.1 ENSG00000273233.1 ENSG00000105063.18 ENSG00000231119.2 ENSG00000280861.1 ENSG00000181518.3 TCGA-G3-A3CH-11 -9.9658 -9.9658 -9.9658 3.557200 -9.9658 0.099000 -9.965800 -9.9658 1.832300 -9.96580 -9.9658 8.372500 -9.9658 -9.9658 3.502200 -9.9658 -9.965800 -1.148800 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -1.086200 -1.117200 -1.214200 -9.9658 -9.9658 0.84880 -9.9658 -3.625900 -9.965800 -9.965800 -5.573500 5.737700 -9.9658 -9.9658 -9.9658 -9.9658 2.150900 ... -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 3.408800 -9.965800 0.099000 -9.9658 -9.9658 0.6969 -9.9658 2.111400 -9.9658 -9.9658 -9.9658 3.570600 0.566600 -9.9658 -9.9658 -9.9658 3.149100 -9.9658 -9.9658 -9.9658 -9.9658 1.590200 6.864000 -1.7809 -9.9658 -9.9658 0.264200 -3.6259 -9.965800 3.435800 -2.547900 -9.9658 -9.9658 TCGA-RP-A695-06 -9.9658 -9.9658 -9.9658 5.230800 -9.9658 3.092700 -9.965800 -9.9658 3.201800 -3.45800 -9.9658 10.228500 -9.9658 -9.9658 5.436700 -9.9658 -1.994200 -5.573500 -9.9658 -9.9658 -9.9658 -9.9658 -5.011600 -2.465900 -0.284500 0.566600 -9.9658 -9.9658 1.18330 -9.9658 -9.965800 -6.506400 -9.965800 -3.046900 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 6.128700 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 5.601400 -9.965800 1.580600 -9.9658 -9.9658 -4.6082 -9.9658 3.502200 -9.9658 -9.9658 -9.9658 4.384800 3.737800 -9.9658 -9.9658 -9.9658 4.073000 -9.9658 -9.9658 -9.9658 -9.9658 2.451800 -4.293400 -6.5064 -9.9658 -9.9658 1.316700 -9.9658 -3.458000 6.590700 -9.965800 -9.9658 -9.9658 TCGA-DD-AAW0-01 -9.9658 -9.9658 -9.9658 4.607700 -9.9658 2.646400 -4.293400 -9.9658 3.808500 -4.29340 -9.9658 8.705700 -9.9658 -9.9658 4.635200 -9.9658 -9.965800 -1.780900 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 0.783200 0.215400 0.444700 -9.9658 -9.9658 1.48590 -9.9658 -9.965800 -5.573500 -9.965800 -5.011600 5.382700 -9.9658 -9.9658 -9.9658 -9.9658 1.196000 ... -4.6082 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 4.635800 -9.965800 1.339700 -9.9658 -9.9658 -4.0350 -9.9658 3.489400 -9.9658 -9.9658 -9.9658 4.165200 1.566100 -9.9658 -9.9658 -4.6082 3.956100 -9.9658 -9.9658 -9.9658 -9.9658 2.186200 7.373500 -5.5735 -9.9658 -9.9658 0.001400 -9.9658 -9.965800 4.631700 -6.506400 -9.9658 -9.9658 TCGA-EE-A17X-06 -9.9658 -1.6850 -9.9658 5.574100 -9.9658 3.165300 -9.965800 -9.9658 2.582800 -6.50640 -9.9658 10.009000 -9.9658 -9.9658 4.784600 -9.9658 -2.314700 -4.608200 -9.9658 -9.9658 -9.9658 -9.9658 -5.011600 -2.314700 -0.338300 -0.249800 -9.9658 -9.9658 0.64250 -9.9658 -9.965800 -9.965800 -0.997100 -6.506400 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 5.923400 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 6.418900 -9.965800 1.322500 -9.9658 -9.9658 -5.5735 -9.9658 4.085800 -9.9658 -9.9658 -9.9658 5.278400 4.536100 -9.9658 -9.9658 -9.9658 5.495700 -9.9658 -9.9658 -9.9658 -9.9658 2.205100 -3.816000 -9.9658 -9.9658 -9.9658 -0.687300 -3.6259 -9.965800 7.805800 -6.506400 -9.9658 -9.9658 TCGA-DD-AACA-02 -9.9658 -9.9658 -9.9658 4.080749 -9.9658 -2.114057 0.407079 -9.9658 3.499608 -3.62591 -9.9658 10.322895 -9.9658 -9.9658 4.162807 -9.9658 -4.442233 -3.921375 -9.9658 -9.9658 -9.9658 -9.9658 -5.965822 -3.717877 0.276236 -0.619235 -9.9658 -9.9658 0.79993 -9.9658 -3.380826 -2.775961 -4.293386 -7.380866 1.543998 -9.9658 -9.9658 -9.9658 -9.9658 2.055201 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 4.657673 -3.625967 0.856772 -9.9658 -9.9658 -9.9658 -9.9658 3.205689 -9.9658 -9.9658 -9.9658 4.628535 2.168608 -9.9658 -9.9658 -9.9658 4.183576 -9.9658 -9.9658 -9.9658 -9.9658 1.331141 6.773435 -9.9658 -9.9658 -9.9658 -0.641625 -9.9658 -4.442233 5.034368 -1.910505 -9.9658 -9.9658 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... TCGA-EE-A2GN-06 -9.9658 -9.9658 -4.2934 3.773000 -9.9658 3.740000 -2.826200 -9.9658 4.802200 -2.46590 -9.9658 11.006800 -9.9658 -9.9658 5.737700 -9.9658 -2.314700 -3.046900 -9.9658 -9.9658 -9.9658 -9.9658 -3.307600 -1.469900 0.723300 0.888300 -9.9658 -9.9658 1.88790 -9.9658 -9.965800 -3.046900 -9.965800 -3.046900 -9.965800 -9.9658 -9.9658 -9.9658 -9.9658 4.970900 ... -3.4580 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 5.912400 -9.965800 2.694000 -9.9658 -9.9658 -6.5064 -9.9658 3.270700 -9.9658 -9.9658 -0.7108 5.218000 4.586200 -9.9658 -9.9658 -9.9658 5.684000 -9.9658 -3.8160 -9.9658 -9.9658 3.132700 -6.506400 -3.6259 -9.9658 -9.9658 1.526600 -3.6259 -2.547900 5.724700 -4.293400 -9.9658 -9.9658 TCGA-D9-A4Z6-06 -9.9658 -9.9658 -9.9658 5.684600 -9.9658 3.996500 -6.506400 -9.9658 4.482900 -2.05290 -9.9658 10.159600 -9.9658 -9.9658 4.879800 -9.9658 -0.284500 -2.932400 -9.9658 -9.9658 -9.9658 -9.9658 -4.293400 -1.639400 1.098300 -0.087700 -9.9658 -9.9658 1.26960 -9.9658 -2.177900 -5.011600 -9.965800 -3.307600 -9.965800 -9.9658 -4.2934 -9.9658 -9.9658 6.171300 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 6.079200 -9.965800 2.018300 -9.9658 -9.9658 -4.0350 -9.9658 2.912800 -9.9658 -9.9658 -1.0262 5.615300 3.476500 -9.9658 -9.9658 -9.9658 4.551600 -9.9658 -9.9658 -9.9658 -9.9658 2.498500 -9.965800 -9.9658 -9.9658 -9.9658 0.368500 -3.1714 -9.965800 6.529700 -3.307600 -9.9658 -9.9658 TCGA-EE-A29L-06 -4.6082 -9.9658 -9.9658 5.281700 -9.9658 4.370200 -6.506400 -9.9658 3.438400 -9.96580 -9.9658 10.427600 -9.9658 -9.9658 6.153200 -9.9658 -5.573500 -5.011600 -9.9658 -9.9658 -9.9658 -2.1779 -6.506400 -1.181100 2.046500 -1.430500 -9.9658 -9.9658 -0.43250 -9.9658 -2.727400 -4.035000 -2.388400 -6.506400 -9.965800 -9.9658 -5.0116 -9.9658 -9.9658 7.421200 ... -6.5064 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 5.801700 -9.965800 3.513600 -9.9658 -9.9658 -5.5735 -9.9658 4.181200 -9.9658 -9.9658 -9.9658 5.083300 3.028700 -9.9658 -9.9658 -9.9658 6.211000 -9.9658 -9.9658 -9.9658 -9.9658 2.985700 -9.965800 -6.5064 -9.9658 -9.9658 2.070700 -9.9658 -2.634900 6.078800 -9.965800 -9.9658 -9.9658 TCGA-DD-A115-01 -9.9658 -9.9658 -9.9658 4.026000 -9.9658 2.154100 -1.318300 -9.9658 3.260200 -4.03500 -3.8160 9.137500 -9.9658 -4.6082 4.263100 -9.9658 -5.573500 -3.307600 -9.9658 -9.9658 -9.9658 -9.9658 -5.573500 -0.042500 -0.375200 0.240000 -9.9658 -9.9658 2.28130 -9.9658 -9.965800 -9.965800 -2.932400 -5.573500 2.899400 -9.9658 -9.9658 -9.9658 -9.9658 2.716100 ... -1.1172 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 4.764500 -9.965800 0.749300 -9.9658 -9.9658 -1.7322 -9.9658 3.411600 -9.9658 -9.9658 -9.9658 3.997400 1.164100 -9.9658 -9.9658 -9.9658 3.720400 -9.9658 -9.9658 -9.9658 -9.9658 1.820100 6.673000 -2.1779 -9.9658 -9.9658 0.311500 -9.9658 -9.965800 4.464700 -2.388400 -9.9658 -9.9658 TCGA-FV-A3I0-11 -9.9658 -9.9658 -9.9658 3.087600 -9.9658 -0.575600 -9.965800 -9.9658 1.692000 -9.96580 -9.9658 8.292000 -9.9658 -9.9658 3.569400 -9.9658 -5.011600 -2.388400 -9.9658 -9.9658 -9.9658 -9.9658 -9.965800 -1.595100 -1.994200 -0.687300 -9.9658 -9.9658 -0.32010 -9.9658 -9.965800 -9.965800 -9.965800 -6.506400 5.202100 -9.9658 -9.9658 -9.9658 -9.9658 3.309000 ... -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 -9.9658 3.577900 -9.965800 0.357300 -9.9658 -9.9658 0.0158 -9.9658 2.160600 -9.9658 -9.9658 -9.9658 3.577900 0.774800 -9.9658 -9.9658 -9.9658 3.082500 -9.9658 -9.9658 -9.9658 -9.9658 -0.249800 7.026400 -2.2447 -9.9658 -9.9658 0.614500 -9.9658 -9.965800 3.217400 -3.046900 -9.9658 -9.9658 936 rows \u00d7 60498 columns Now we are ready to fit the PCA fit = pca . fit ( X ) fit PCA(copy=True, iterated_power='auto', n_components=None, random_state=None, svd_solver='auto', tol=0.0, whiten=False) Plot the explained variance by the number of components for any components that explain at least 0.5% of the variance components_df = pd . DataFrame ( enumerate ( fit . explained_variance_ratio_ ), columns = [ 'component' , 'variance_explained' ]) components_df [ 'cum_var' ] = components_df . variance_explained . cumsum () components_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } component variance_explained cum_var 0 0 2.098103e-01 0.209810 1 1 4.941317e-02 0.259223 2 2 2.684464e-02 0.286068 3 3 2.096802e-02 0.307036 4 4 1.821842e-02 0.325255 ... ... ... ... 931 931 2.724521e-04 0.999199 932 932 2.708955e-04 0.999470 933 933 2.679152e-04 0.999738 934 934 2.619554e-04 1.000000 935 935 2.545080e-28 1.000000 936 rows \u00d7 3 columns fig = sns . relplot ( data = components_df [ components_df . variance_explained >= 0.005 ], x = 'component' , y = 'variance_explained' , kind = 'line' ) fig . set ( xlabel = 'Component #' , ylabel = 'Proportion of Variance Explained' ) <seaborn.axisgrid.FacetGrid at 0x7f3bc2ef49d0> If we want to see the variance explained as we keep X components we can plot that as well fig = sns . relplot ( data = components_df , x = 'component' , y = 'cum_var' , kind = 'line' ) fig . set ( xlabel = 'Number of Components' , ylabel = 'Proportion of Variance Explained' ) <seaborn.axisgrid.FacetGrid at 0x7f3bc2ec0450> To visualize this in 2-d we can only plot the first two components pca_xy = PCA ( n_components = 2 ) fit_xy = pd . DataFrame ( pca_xy . fit_transform ( X ), index = X . index , columns = [ 'component 1' , 'component 2' ]) fit_xy .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } component 1 component 2 TCGA-G3-A3CH-11 313.877223 58.038358 TCGA-RP-A695-06 -178.026704 152.348532 TCGA-DD-AAW0-01 205.633995 -104.460686 TCGA-EE-A17X-06 -185.690333 172.857407 TCGA-DD-AACA-02 226.342307 -60.439144 ... ... ... TCGA-EE-A2GN-06 -253.444806 21.297225 TCGA-D9-A4Z6-06 -243.644653 27.199689 TCGA-EE-A29L-06 -220.859424 123.556796 TCGA-DD-A115-01 250.808496 -44.392051 TCGA-FV-A3I0-11 375.594610 127.824032 936 rows \u00d7 2 columns Now join this back to the metadata to get the groupings fig_df = fit_xy . reset_index () . rename ( columns = { 'index' : 'sample' }) . merge ( meta_df , on = [ 'sample' ], how = 'left' ) fig_df [[ 'sample' , 'component 1' , 'component 2' , 'cancer type abbreviation' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample component 1 component 2 cancer type abbreviation 0 TCGA-G3-A3CH-11 313.877223 58.038358 LIHC 1 TCGA-RP-A695-06 -178.026704 152.348532 SKCM 2 TCGA-DD-AAW0-01 205.633995 -104.460686 LIHC 3 TCGA-EE-A17X-06 -185.690333 172.857407 SKCM 4 TCGA-DD-AACA-02 226.342307 -60.439144 LIHC ... ... ... ... ... 931 TCGA-EE-A2GN-06 -253.444806 21.297225 SKCM 932 TCGA-D9-A4Z6-06 -243.644653 27.199689 SKCM 933 TCGA-EE-A29L-06 -220.859424 123.556796 SKCM 934 TCGA-DD-A115-01 250.808496 -44.392051 LIHC 935 TCGA-FV-A3I0-11 375.594610 127.824032 LIHC 936 rows \u00d7 4 columns Add a flag column for our sample of interest fig_df . loc [ fig_df [ 'sample' ] == test_sample_id , 'target sample' ] = True fig_df [ 'target sample' ] = fig_df [ 'target sample' ] . fillna ( False ) fig_df [[ 'sample' , 'component 1' , 'component 2' , 'cancer type abbreviation' , 'target sample' ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sample component 1 component 2 cancer type abbreviation target sample 0 TCGA-G3-A3CH-11 313.877223 58.038358 LIHC True 1 TCGA-RP-A695-06 -178.026704 152.348532 SKCM False 2 TCGA-DD-AAW0-01 205.633995 -104.460686 LIHC False 3 TCGA-EE-A17X-06 -185.690333 172.857407 SKCM False 4 TCGA-DD-AACA-02 226.342307 -60.439144 LIHC False ... ... ... ... ... ... 931 TCGA-EE-A2GN-06 -253.444806 21.297225 SKCM False 932 TCGA-D9-A4Z6-06 -243.644653 27.199689 SKCM False 933 TCGA-EE-A29L-06 -220.859424 123.556796 SKCM False 934 TCGA-DD-A115-01 250.808496 -44.392051 LIHC False 935 TCGA-FV-A3I0-11 375.594610 127.824032 LIHC False 936 rows \u00d7 5 columns fig = sns . relplot ( kind = 'scatter' , data = fig_df , x = 'component 1' , y = 'component 2' , hue = 'cancer type abbreviation' ) Add the annotation to pick out our current sample in the PCA. We are going to plot overtop of the original plot to accomplish this ax = sns . scatterplot ( data = fig_df , x = 'component 1' , y = 'component 2' , hue = 'cancer type abbreviation' , alpha = 0.5 ) ax = sns . scatterplot ( data = fig_df [ fig_df [ 'sample' ] == test_sample_id ], x = 'component 1' , y = 'component 2' , marker = 'X' , alpha = 1 , ax = ax , color = 'black' , s = 300 ) As we saw with the correlation plot, the LIHC sample is grouped with its disease cohort","title":"Principle Component Analysis (PCA)"},{"location":"variant_notation/","text":"About Variant Notation \u00b6 The variant notation is a shorthand to make it faster to enter/display variants. It is made up of two forms: continuous , and multi-feature . Most people will be more familiar with the continuous notation. It is based on HGVS v15.11 and can be used to describe any variant that has only a single reference feature (i.e. KRAS). Multi-feature notation is required when one needs to describe any variant involving multiple reference features. This could be something like a gene fusion where the reference features might be EWSR1, and FLI1. Warning The notation examples included in this documentation do not necessarily represent actual mutations. While they are all valid syntax, no attempt has been made to check that the sequences given are correct To make this more transparent to end users, we have provided a notation parser view as part of the GraphKB Client where any input notation may be tested to see how it would be decomposed by the GraphKB parser General Notation \u00b6 Prefixes \u00b6 Both forms of notation can be described as two breakpoints and an event type. Some may also include reference sequence and untemplated sequence descriptions. Additionally both forms will use a common prefix notation. These prefixes are described under coordinate systems Variant Types \u00b6 The expected variant types are given below. Some types are only applicable to certain coordinate systems (i.e. frameshifts are protein only). Variant Type Description Standard HGVS Prefix Specific > substitutions \u2714 g / c / r / n del deletions \u2714 delins indels \u2714 dup duplications \u2714 fs frameshifts \u2714 p ext extensions \u2714 p ins insertions \u2714 inv inversions \u2714 fusion gene fusion trans translocation itrans inverted translocation mut non-specific mutation spl splice site mutation p mis missense mutation p Unsupported HGVS Features \u00b6 There are a few elements of the HGVS v15.11 notation that are not yet supported ( contributions are welcome! ). These include: mosacism chimerism RNA variants conversions alleles v20 Complex Variants","title":"About Variant Notation"},{"location":"variant_notation/#about-variant-notation","text":"The variant notation is a shorthand to make it faster to enter/display variants. It is made up of two forms: continuous , and multi-feature . Most people will be more familiar with the continuous notation. It is based on HGVS v15.11 and can be used to describe any variant that has only a single reference feature (i.e. KRAS). Multi-feature notation is required when one needs to describe any variant involving multiple reference features. This could be something like a gene fusion where the reference features might be EWSR1, and FLI1. Warning The notation examples included in this documentation do not necessarily represent actual mutations. While they are all valid syntax, no attempt has been made to check that the sequences given are correct To make this more transparent to end users, we have provided a notation parser view as part of the GraphKB Client where any input notation may be tested to see how it would be decomposed by the GraphKB parser","title":"About Variant Notation"},{"location":"variant_notation/#general-notation","text":"","title":"General Notation"},{"location":"variant_notation/#prefixes","text":"Both forms of notation can be described as two breakpoints and an event type. Some may also include reference sequence and untemplated sequence descriptions. Additionally both forms will use a common prefix notation. These prefixes are described under coordinate systems","title":"Prefixes"},{"location":"variant_notation/#variant-types","text":"The expected variant types are given below. Some types are only applicable to certain coordinate systems (i.e. frameshifts are protein only). Variant Type Description Standard HGVS Prefix Specific > substitutions \u2714 g / c / r / n del deletions \u2714 delins indels \u2714 dup duplications \u2714 fs frameshifts \u2714 p ext extensions \u2714 p ins insertions \u2714 inv inversions \u2714 fusion gene fusion trans translocation itrans inverted translocation mut non-specific mutation spl splice site mutation p mis missense mutation p","title":"Variant Types"},{"location":"variant_notation/#unsupported-hgvs-features","text":"There are a few elements of the HGVS v15.11 notation that are not yet supported ( contributions are welcome! ). These include: mosacism chimerism RNA variants conversions alleles v20 Complex Variants","title":"Unsupported HGVS Features"},{"location":"variant_notation/continuous/","text":"Continuous Notation \u00b6 All continuous notation follows a similar pattern that is loosely defined as: <feature>:<prefix>.<pos><type><seq> The reference feature would be the gene (chromosome, transcript, etc.) name that the variant occurs on. The prefix denotes the coordinate type (see prefixes ). The range is the position or positions of the variant. For a deletion, this is the range that is deleted. For an insertion, this is the two positions the sequence is inserted between. The sequence element will depend on the type of variant being described, but often this is the untemplated/inserted sequence. The sequence element is often optional. For all notation types there are general and more specific versions of notating the same event. Where possible more specificity is preferred. But it is recognized that notation coming from outside sources may not always provide all information. For each variant, the different equivalent notation options are shown below in order of increasing specificity. Examples \u00b6 Substitution \u00b6 Genomic/CDS substitution variants differ from protein substitution variants . Therefore examples of both will be given. A protein missense mutation where G is replaced with D KRAS:p.G12D A genomic substitution from A to C chr11:g.1234A>C Indel \u00b6 A protein deletion of amino acids GH and insertion of three amino acids TTA EGFR:p.G512_H513delins EGFR:p.G512_H513delins3 EGFR:p.G512_H513delGHins EGFR:p.G512_H513delGHins3 EGFR:p.G512_H513delinsTTA EGFR:p.G512_H513delGHinsTTA Insertion \u00b6 Insertions must be a range to specify between which two coordinates the insertion occurs. This avoids the problem when only a single coordinate is given of which side it is inserted on. An protein insertion of four amino acids between G123 and H124. The sequence element here is optional and can also be described as a number if the number of bases inserted is known but the sequence is not given. EGFR:p.G123_H124ins EGFR:p.G123_H124ins4 EGFR:p.G123_H124insCCST Deletion \u00b6 The reference sequence is optional when denoting a deletion. For example the same deletion could be notated both ways as shown below. EGFR:p.R10_G14del EGFR:p.R10_G14del5 EGFR:p.R10_G14delRSTGG If the reference sequence is known, it is always better to provide more information than less. Duplication \u00b6 Four amino acids are duplicated. Once again, the sequence element is optional EGFR:p.R10_G14dup EGFR:p.R10_G14dup5 EGFR:p.R10_G14dupRSTGG Frameshift \u00b6 Frameshifts are only applicable to variants denoted with protein coordinates. Frameshift notation follows the pattern below <feature>:p.<pos><first alternate AA>fs*<position of next truncating AA> The first alternate AA , and position of next truncating AA are both optional elements. For example the protein frameshift variant might be noted multiple ways PTEN:p.G123fs PTEN:p.G123fs*10 PTEN:p.G123Afs PTEN:p.G123Afs*10","title":"Continuous Notation"},{"location":"variant_notation/continuous/#continuous-notation","text":"All continuous notation follows a similar pattern that is loosely defined as: <feature>:<prefix>.<pos><type><seq> The reference feature would be the gene (chromosome, transcript, etc.) name that the variant occurs on. The prefix denotes the coordinate type (see prefixes ). The range is the position or positions of the variant. For a deletion, this is the range that is deleted. For an insertion, this is the two positions the sequence is inserted between. The sequence element will depend on the type of variant being described, but often this is the untemplated/inserted sequence. The sequence element is often optional. For all notation types there are general and more specific versions of notating the same event. Where possible more specificity is preferred. But it is recognized that notation coming from outside sources may not always provide all information. For each variant, the different equivalent notation options are shown below in order of increasing specificity.","title":"Continuous Notation"},{"location":"variant_notation/continuous/#examples","text":"","title":"Examples"},{"location":"variant_notation/continuous/#substitution","text":"Genomic/CDS substitution variants differ from protein substitution variants . Therefore examples of both will be given. A protein missense mutation where G is replaced with D KRAS:p.G12D A genomic substitution from A to C chr11:g.1234A>C","title":"Substitution"},{"location":"variant_notation/continuous/#indel","text":"A protein deletion of amino acids GH and insertion of three amino acids TTA EGFR:p.G512_H513delins EGFR:p.G512_H513delins3 EGFR:p.G512_H513delGHins EGFR:p.G512_H513delGHins3 EGFR:p.G512_H513delinsTTA EGFR:p.G512_H513delGHinsTTA","title":"Indel"},{"location":"variant_notation/continuous/#insertion","text":"Insertions must be a range to specify between which two coordinates the insertion occurs. This avoids the problem when only a single coordinate is given of which side it is inserted on. An protein insertion of four amino acids between G123 and H124. The sequence element here is optional and can also be described as a number if the number of bases inserted is known but the sequence is not given. EGFR:p.G123_H124ins EGFR:p.G123_H124ins4 EGFR:p.G123_H124insCCST","title":"Insertion"},{"location":"variant_notation/continuous/#deletion","text":"The reference sequence is optional when denoting a deletion. For example the same deletion could be notated both ways as shown below. EGFR:p.R10_G14del EGFR:p.R10_G14del5 EGFR:p.R10_G14delRSTGG If the reference sequence is known, it is always better to provide more information than less.","title":"Deletion"},{"location":"variant_notation/continuous/#duplication","text":"Four amino acids are duplicated. Once again, the sequence element is optional EGFR:p.R10_G14dup EGFR:p.R10_G14dup5 EGFR:p.R10_G14dupRSTGG","title":"Duplication"},{"location":"variant_notation/continuous/#frameshift","text":"Frameshifts are only applicable to variants denoted with protein coordinates. Frameshift notation follows the pattern below <feature>:p.<pos><first alternate AA>fs*<position of next truncating AA> The first alternate AA , and position of next truncating AA are both optional elements. For example the protein frameshift variant might be noted multiple ways PTEN:p.G123fs PTEN:p.G123fs*10 PTEN:p.G123Afs PTEN:p.G123Afs*10","title":"Frameshift"},{"location":"variant_notation/split/","text":"Multi-Feature (Split) Notation \u00b6 Multi-feature notation is a novel feature of GraphKB-HGVS and not part of standard HGVS. It is based on the original form for cytogenetic descriptions of translocations (as previously reccommended by HGVS) but this form is generalized to allow other coordinate systems. Multi-Feature notation will use the same positions and coordinate systems as continuous notation. However parentheses are used to divide features and positions. All multi-feature variants should following the pattern below (<feature>,<feature>):<type>(<prefix>.<pos>,<prefix>.<pos>)<seq> Untemplated sequence should only be included for sequence specific coordinate types such as genomic, CDS, and protein. Where possible, continuous notation is preferred to multi-feature. Examples \u00b6 Gene Fusion \u00b6 Using exon coordinates we could describe a gene fusion of exon 4 of EWSR1 to exon 7 of FLI1 as follows (EWSR1,FLI1):fusion(e.4,e.7) A range can also be used here. When a range of positions is given it indicates uncertainty. Since the range is already separated by a comma it is not necessary to enclose the uncertainty in parentheses (as you would for continuous notation). For example, if we wanted to express a fusion of any exon from 4-6 of EWSR1 to any exon from 7-10 of FLI1 (ESWR1,FLI1):fusion(e.4_6,e.7_10) Genomic Translocation \u00b6 Multi-feature variants can also be described using the genomic coordinate system ( g ). For example a translocation might be described (chr8,chr7):trans(g.1234,g.4567) (chr8,chr7):trans(g.1234,g.4567)AAT Above we are describing a translocation from chr8:1234 to chr7:4567 where AAT is the untemplated sequence inserted between the breakpoints.","title":"Multi-Feature (Split) Notation"},{"location":"variant_notation/split/#multi-feature-split-notation","text":"Multi-feature notation is a novel feature of GraphKB-HGVS and not part of standard HGVS. It is based on the original form for cytogenetic descriptions of translocations (as previously reccommended by HGVS) but this form is generalized to allow other coordinate systems. Multi-Feature notation will use the same positions and coordinate systems as continuous notation. However parentheses are used to divide features and positions. All multi-feature variants should following the pattern below (<feature>,<feature>):<type>(<prefix>.<pos>,<prefix>.<pos>)<seq> Untemplated sequence should only be included for sequence specific coordinate types such as genomic, CDS, and protein. Where possible, continuous notation is preferred to multi-feature.","title":"Multi-Feature (Split) Notation"},{"location":"variant_notation/split/#examples","text":"","title":"Examples"},{"location":"variant_notation/split/#gene-fusion","text":"Using exon coordinates we could describe a gene fusion of exon 4 of EWSR1 to exon 7 of FLI1 as follows (EWSR1,FLI1):fusion(e.4,e.7) A range can also be used here. When a range of positions is given it indicates uncertainty. Since the range is already separated by a comma it is not necessary to enclose the uncertainty in parentheses (as you would for continuous notation). For example, if we wanted to express a fusion of any exon from 4-6 of EWSR1 to any exon from 7-10 of FLI1 (ESWR1,FLI1):fusion(e.4_6,e.7_10)","title":"Gene Fusion"},{"location":"variant_notation/split/#genomic-translocation","text":"Multi-feature variants can also be described using the genomic coordinate system ( g ). For example a translocation might be described (chr8,chr7):trans(g.1234,g.4567) (chr8,chr7):trans(g.1234,g.4567)AAT Above we are describing a translocation from chr8:1234 to chr7:4567 where AAT is the untemplated sequence inserted between the breakpoints.","title":"Genomic Translocation"},{"location":"variant_notation/coordinate_systems/","text":"About \u00b6 Notation forms will use a common prefix notation. These describe the units of any positions given in the variant description. For example, protein notation ( p. ) would have amino acids as units. Prefix Coordinate Type Standard HGVS g Genomic \u2714 c Coding reference sequence (CDS) \u2714 p Protein \u2714 e Exon y CytoBand/Cytogenic i Intronic position r RNA position \u2714 n non-coding DNA reference sequence \u2714","title":"About"},{"location":"variant_notation/coordinate_systems/#about","text":"Notation forms will use a common prefix notation. These describe the units of any positions given in the variant description. For example, protein notation ( p. ) would have amino acids as units. Prefix Coordinate Type Standard HGVS g Genomic \u2714 c Coding reference sequence (CDS) \u2714 p Protein \u2714 e Exon y CytoBand/Cytogenic i Intronic position r RNA position \u2714 n non-coding DNA reference sequence \u2714","title":"About"},{"location":"variant_notation/coordinate_systems/cytoband/","text":"CytoBand Coordinates \u00b6 CytoBand notation is included in GraphKB-HGVS to increase compatibility with variant notation in older publications and knowledge bases. CytoBand coordinates ( y ) are not a feature of HGVS, however variants using this system follow much the same patterns as the other types. Since this coordinate system is not very specific, the types of variants one can describe is more limited. Generally only duplications/gains, deletions/losses, inversions, and translocations can be described. Additionally sequence is never included. Any position in the CytoBand coordinate system is described by the pattern <arm><majorBand>.<minorBand> The minor band number is optional. Deletion Example \u00b6 A deletion spanning p11.1 to p12. chr1:y.p11.1_p12del","title":"CytoBand Coordinates"},{"location":"variant_notation/coordinate_systems/cytoband/#cytoband-coordinates","text":"CytoBand notation is included in GraphKB-HGVS to increase compatibility with variant notation in older publications and knowledge bases. CytoBand coordinates ( y ) are not a feature of HGVS, however variants using this system follow much the same patterns as the other types. Since this coordinate system is not very specific, the types of variants one can describe is more limited. Generally only duplications/gains, deletions/losses, inversions, and translocations can be described. Additionally sequence is never included. Any position in the CytoBand coordinate system is described by the pattern <arm><majorBand>.<minorBand> The minor band number is optional.","title":"CytoBand Coordinates"},{"location":"variant_notation/coordinate_systems/cytoband/#deletion-example","text":"A deletion spanning p11.1 to p12. chr1:y.p11.1_p12del","title":"Deletion Example"}]}